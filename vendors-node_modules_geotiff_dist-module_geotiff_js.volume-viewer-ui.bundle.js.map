{"version":3,"file":"vendors-node_modules_geotiff_dist-module_geotiff_js.volume-viewer-ui.bundle.js","mappings":";;;;;;;;AAAA;AACA;AACA;AACA;AACA;;AAEA;AACA,yBAAsB;;;;;;;;;;;ACPtB,qBAAqB,mBAAO,CAAC,uEAAqB;AAClD,wBAAwB,mBAAO,CAAC,+EAAyB;AACzD,uBAAuB,mBAAO,CAAC,yEAAsB;;AAErD;AACA;AACA;;AAEA;;AAEA;;AAEA,uCAAuC,QAAQ;AAC/C;AACA;;AAEA;;AAEA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,IAAI;AACJ;AACA;;AAEA,WAAW;AACX;;AAEA;AACA,yBAAsB;;;;;;;;;;;AC5DtB,sBAAsB,mBAAO,CAAC,2EAAuB;;AAErD;AACA;AACA;AACA;AACA;AACA;AACA,8CAA8C,mBAAmB;AACjE;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,yBAAsB;;;;;;;;;;;ACrBtB;AACA;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA,kBAAkB,uBAAuB;AACzC;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,yBAAsB;;;;;;;;;;;ACvBtB;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,yBAAsB;;;;;;;;;;;ACRtB;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,yBAAsB;;;;;;;;;;;;;;;;;;;;ACRmC;AACmB;AAI3C;;AAEjC;AACA;AACA;AACA,WAAW,UAAU;AACrB,WAAW,QAAQ;AACnB,WAAW,WAAW;AACtB,aAAa;AACb;AACO;AACP,SAAS,oEAAe;AACxB,IAAI,iFAA0B,0BAA0B,qEAAY;AACpE;AACA;;AAEA;AACA;AACA;AACA,WAAW,UAAU;AACrB,WAAW,QAAQ;AACnB,WAAW,QAAQ;AACnB,WAAW,WAAW;AACtB;AACO;AACP,SAAS,iFAA0B;AACnC;AACA;AACA,IAAI,uEAAkB;AACtB,OAAO,qEAAY;AACnB;AACA;;;;;;;;;;;;;;;;;;ACrB2B;;AAE3B,WAAW,UAAU,0BAA0B;AAC/C,2BAA2B,2DAAa;;AAExC,8BAA8B,8DAAY;AAC1C;AACA;AACA,4BAA4B,qEAAmB;AAC/C,aAAa,4EAA0B;AACvC,KAAK;AACL,GAAG;;AAEH,GAAG,4DAAc;AACjB;AACA;AACA,KAAK;AACL,GAAG;AACH,CAAC;;AAED;AACA;AACA;AACA,UAAU;AACV;AACO;AACP;AACA,UAAU,4DAAc,MAAM,gFAAkC;AAChE,IAAI,oEAAsB,UAAU,wEAA0B;AAC9D;AACA;AACA;;AAEA,eAAe,8DAAY;AAC3B,EAAE,qEAAmB,uBAAuB,8EAA4B;AACxE;AACA;;AAEA,WAAW,UAAU,mBAAmB;AACxC,uBAAuB,2DAAa;;AAEpC;AACA,oCAAoC,8DAAY,CAAC,+DAAiB;AAClE;AACA;AACA,wBAAwB,qEAAmB;AAC3C,aAAa,wEAAsB;AACnC,KAAK;AACL;AACA;AACA,GAAG;AACH,CAAC;;AAED,kBAAkB,gEAAc,CAAC,oEAAsB;AACvD;AACA;AACA;AACA;;AAEA;AACA,EAAE,sEAAoB,mCAAmC,iFAA+B,CAAC,oEAAsB;AAC/G;;AAEA;AACA;AACA;AACA,UAAU;AACV;AACO;AACP,gBAAgB,8DAAY;AAC5B,EAAE,qEAAmB;AACrB;AACA;;;;;;;;;;;;;;;;;;ACvFA;;AAM2B;;AAE3B,mBAAmB,+DAAiB;AACpC,sBAAsB,gEAAkB;AACxC,uBAAuB,+DAAiB;;AAExC,sBAAsB,+DAAiB;AACvC,uBAAuB,+DAAiB;;AAExC,gBAAgB,SAAS;AACzB;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,IAAI;AACJ;AACA;AACA;AACA;;AAEA;AACA,IAAI;AACJ;AACA;AACA;AACA;;AAEA;AACA,IAAI;AACJ;AACA;AACA;AACA;;AAEA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,WAAW,SAAS;AACpB,aAAa,QAAQ;AACrB;AACO;AACP,4BAA4B,KAAK;AACjC;AACA;AACA;AACA;;AAEA,0BAA0B,+DAAiB;AAC3C,0BAA0B,+DAAiB;AAC3C,wBAAwB,+DAAiB;;AAEzC,gBAAgB,UAAU;AAC1B,sBAAsB;AACtB,sBAAsB;;AAEtB;AACA;AACA;AACA,sBAAsB;AACtB;;AAEA,sBAAsB;AACtB,sBAAsB;;AAEtB;AACA;AACA,mBAAmB,UAAU;AAC7B;AACA;;AAEA,gBAAgB,QAAQ;AACxB;AACA;AACA;AACA;AACA,iBAAiB,QAAQ;AACzB;AACA;AACA;;AAEA,gBAAgB,QAAQ;AACxB;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,WAAW,QAAQ;AACnB,aAAa,QAAQ;AACrB;AACO;AACP;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACrHO;AACA;AACA;AACP;AACO;AACP;AACO;AACP;AACO;AACP;AACO;AACP;AACO;AACP;AACO;AACP;AACO;AACA;AACP;AACO;AACP;AACO;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACrBP;AACA;;AAE4E;;AAE5E,WAAW,+FAA+F;AAC1G;AACA;AACA;AACA;AACA;;AAEA,WAAW,8EAA8E;AACzF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,EAAE;;AAEF;AACO;;AAEP;AACO;AACP;AACA;AACA;AACA,EAAE;;AAEF;AACO;AACP;AACA;AACA;AACA;AACA,EAAE;;AAEF;AACO;AACA;AACP;AACA;AACA;AACA;AACA,EAAE;AACF;AACA,WAAW,4DAA4D;AAChE,mDAAmD,KAAK;AAC/D,2BAA2B,KAAK;AAChC;AACA;AACA;AACA,QAAQ,qFAA0C;AAClD;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,MAAM;AACN;AACA,WAAW,+CAA+C;AACnD,gCAAgC,KAAK;AAC5C;;AAEA;AACA;AACO;AACP;AACA,WAAW,2DAA2D;AAC/D;AACP,WAAW,0CAA0C;AAC9C;AACP,WAAW,uDAAuD;AAC3D;AACP;AACA;AACO;AACP,WAAW,wCAAwC;AAC5C;;AAEP;AACO;;AAEP;AACO;AACA;AACP;AACA,WAAW,+DAA+D;AACnE;AACP,WAAW,sCAAsC;AAC1C;;AAEP;AACO;AACP,WAAW,kDAAkD;AACtD;AACP;;AAEA;AACA,cAAc,6IAA6I;AAC3J,WAAW,KAAK;AACT;AACP;AACO;AACA;AACP,WAAW,sDAAsD;AAC1D;AACP,WAAW,sDAAsD;AAC1D;AACP;AACA;AACA,WAAW,gEAAgE;AACpE;AACP;AACA;AACA,WAAW,6EAA6E;AACjF;AACP,WAAW,4CAA4C;AAChD;AACP;AACA;AACA,WAAW,yFAAyF;AAC7F;AACP,WAAW,yFAAyF;AAC7F;AACP;AACA;AACA,WAAW,0FAA0F;AAC9F;AACP,WAAW,0EAA0E;AAC9E;AACP,WAAW,0EAA0E;AAC9E;AACP;AACA;AACA,WAAW,2CAA2C;AAC/C;AACP;AACA;AACA;AACA,WAAW,sCAAsC;AAC1C;AACP;AACA;AACA;AACA,WAAW,sCAAsC;AAC1C;AACP;AACA;AACA;AACA,WAAW,6BAA6B;AACjC;AACP;AACA;AACA;;AAEA;AACO;AACP,WAAW,gCAAgC;AACpC;AACP;AACA;;AAEA;AACO;;AAEP;AACO;;AAEP;AACA,WAAW,KAAK;AACT;AACP,WAAW,8DAA8D;AAClE;;AAEP;AACA,WAAW,4GAA4G;AAChH,2DAA2D;;AAElE;AACO;;AAEP;AACA;AACA,WAAW,4EAA4E;AAChF;AACP;AACA;AACA,WAAW,yFAAyF;AAC7F;AACP;AACA;;AAEA;AACO;AACA;;AAEP;AACA;AACA;AACA;AACA,WAAW,iBAAiB;AAC5B;AACO;AACP;AACA,WAAW,aAAa,wCAAwC;AACzD;AACP,WAAW,aAAa,yCAAyC;AAC1D;;AAEP;AACA;AACA;AACA;AACA,WAAW,iBAAiB;AAC5B;AACO;AACP;AACA,WAAW,aAAa,2CAA2C;AAC5D;AACP,WAAW,aAAa,iDAAiD;AAClE;AACP,WAAW,aAAa,2DAA2D;AAC5E;;;;;;;;;;;;;;;;;ACxP0C;;AAElC;AACf;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa,6DAAc;AAC3B;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;ACnBA;;AAEO;AACP;AACA,qBAAqB;AACrB;AACA;AACA;;AAEO;AACP;AACA;AACA,8DAA8D,0BAA0B;AACxF;AACA;AACA;AACA;;AAEA;AACA,iCAAiC,yNAAkB;AACnD,oBAAoB,yNAAkB;AACtC;AACA;AACA,CAAC;AACD,oBAAoB,oOAAmB;AACvC,6BAA6B,yTAAsB;AACnD,wBAAwB,wOAAuB;AAC/C,wBAAwB,wTAAmB;AAC3C,wBAAwB,wOAAuB;;;;;;;;;;;;;;;;AC5BhC;AACf;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa,UAAU;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,UAAU;AACrB;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,OAAO;AAC3B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,UAAU;AACV;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;AC3IkD;;AAEnC;AACf;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa,UAAU;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,UAAU;AACrB;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,oBAAoB,OAAO;AAC3B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,UAAU;AACV;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA,WAAW,gEAAU;AACrB;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AChGA;AAC6C;AACJ;AACF;AACV;;AAEyB;AACK;AACG;AACZ;;AAEiC;AACjC;AACV;AACR;AACgC;AACvB;;AAEtB;AACJ;AACuD;AACpC;AACb;;AAErB;AACA,aAAa;AACb;AACA;;AAEA;AACA,eAAe,gCAAgC;AAC/C;;AAEA;AACA;AACA;AACA,mBAAmB,gBAAgB,cAAc;AACjD,aAAa,yBAAyB;AACtC;;AAEA;AACA;AACA;AACA,qBAAqB,gBAAgB,cAAc;AACnD,aAAa,2BAA2B;AACxC;;AAEA;AACA;AACA;AACA,oCAAoC,gBAAgB,cAAc;AAClE,aAAa,0DAA0D;AACvE;;AAEA;AACA;AACA,SAAS,mDAAU,YAAY,mDAAU,aAAa,mDAAU,aAAa,mDAAU;AACvF;AACA,SAAS,mDAAU,aAAa,mDAAU;AAC1C;AACA,SAAS,mDAAU,YAAY,mDAAU,aAAa,mDAAU,aAAa,mDAAU;AACvF;AACA,SAAS,mDAAU,gBAAgB,mDAAU,iBAAiB,mDAAU;AACxE,SAAS,mDAAU,aAAa,mDAAU,cAAc,mDAAU;AAClE;AACA;AACA,kDAAkD,UAAU;AAC5D;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA,kBAAkB,gCAAgC;AAClD,gBAAgB,oDAAW;AAC3B;AACA,SAAS,sDAAa;AACtB;AACA;;AAEA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,0DAA0D,IAAI;AAC9D,QAAQ;AACR;AACA,QAAQ;AACR;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA,SAAS,mDAAU,YAAY,mDAAU,aAAa,mDAAU;AAChE,sCAAsC;AACtC;AACA,SAAS,mDAAU;AACnB,qCAAqC;AACrC;AACA,SAAS,mDAAU;AACnB,uCAAuC;AACvC;AACA,SAAS,mDAAU;AACnB,sCAAsC;AACtC;AACA,SAAS,mDAAU,YAAY,mDAAU;AACzC,uCAAuC;AACvC;AACA,SAAS,mDAAU;AACnB,sCAAsC;AACtC;AACA,SAAS,mDAAU,aAAa,mDAAU;AAC1C,iCAAiC;AACjC;AACA,SAAS,mDAAU;AACnB,iCAAiC;AACjC;AACA,SAAS,mDAAU;AACnB,2CAA2C;AAC3C;AACA,SAAS,mDAAU;AACnB,0CAA0C;AAC1C;AACA,SAAS,mDAAU;AACnB,wCAAwC;AACxC;AACA,SAAS,mDAAU;AACnB,wCAAwC;AACxC;AACA;AACA,kDAAkD,UAAU;AAC5D;;AAEA;AACA,sBAAsB,mDAAU,2BAA2B,mDAAU;AACrE,oBAAoB,WAAW;AAC/B;AACA;AACA;AACA;AACA,IAAI,OAAO;AACX,oBAAoB,WAAW;AAC/B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,oBAAoB,mDAAU;AAC9B;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,+BAA+B,MAAM;AACrC;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,gCAAgC;AAC7D;AACA;AACA,aAAa,4CAA4C,WAAW;AACpE,eAAe,2BAA2B;AAC1C;AACA,gCAAgC;AAChC,YAAY,qCAAqC;AACjD,UAAU,mBAAmB;;AAE7B;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,sBAAsB,gBAAgB;AACtC;AACA,gBAAgB,2DAA2D;AAC3E;AACA;AACA;AACA;;AAEA;AACA,sBAAsB,sBAAsB;AAC5C;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,mCAAmC,yBAAyB;AAC5D;AACA;;AAEA;AACA,aAAa,QAAQ;AACrB,cAAc,SAAS;AACvB;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa,GAAG;AAChB,aAAa,SAAS;AACtB,aAAa,SAAS;AACtB,aAAa,QAAQ;AACrB;AACA,aAAa,gBAAgB;AAC7B;AACA,yEAAyE;AACzE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,eAAe,qDAAS;AACxB;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,aAAa,QAAQ;AACrB,eAAe,6BAA6B;AAC5C;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA,6BAA6B,4BAA4B;AACzD;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,QAAQ;AACR;AACA;AACA;;AAEA,uEAAuE;AACvE;AACA;AACA;AACA,UAAU;AACV;AACA;AACA;AACA;;AAEA;AACA,6BAA6B,oDAAW;AACxC,2BAA2B,mDAAU,2BAA2B,mDAAU;AAC1E;AACA,QAAQ;AACR;AACA;;AAEA;AACA,oBAAoB,sDAAa;AACjC;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,QAAQ;AACR;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;;AAEA;AACA;AACA;AACA,aAAa,QAAQ;AACrB,eAAe,uBAAuB;AACtC;AACA;AACA;AACA,eAAe,wDAAY;AAC3B;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,eAAe,iBAAiB;AAChC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ;AACR;AACA;AACA,UAAU;AACV;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,eAAe,iBAAiB;AAChC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6CAA6C,mDAAU;AACvD,4CAA4C,mDAAU;AACtD;AACA;AACA;AACA;AACA;AACA,0CAA0C,mDAAU;AACpD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;;AAEA;AACA;AACA;AACA,aAAa,GAAG;AAChB,aAAa,gBAAgB;AAC7B,aAAa,aAAa;AAC1B;AACA;AACA;AACA,8CAA8C,yBAAyB;AACvE,yBAAyB,sDAAU;;AAEnC;AACA;AACA;AACA;AACA,MAAM;AACN;AACA,MAAM;AACN;AACA;;AAEA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEmB;AACnB,iEAAe,OAAO,EAAC;;AAEvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa,SAAS;AACtB,aAAa,WAAW;AACxB;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,aAAa,QAAQ;AACrB,eAAe,uBAAuB;AACtC;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,4BAA4B;AAChD;AACA,uBAAuB,0BAA0B;AACjD;AACA;AACA,qBAAqB,wDAAY;AACjC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA,eAAe,iBAAiB;AAChC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEwB;;AAExB;AACA;AACA,WAAW,QAAQ;AACnB,WAAW,QAAQ;AACnB,kCAAkC,wBAAwB;AAC1D,WAAW,aAAa;AACxB;AACA,aAAa,kBAAkB;AAC/B;AACO,wCAAwC;AAC/C,4BAA4B,mEAAgB;AAC5C;;AAEA;AACA;AACA,iBAAiB,mGAAmG;AACpH,WAAW,aAAa;AACxB,WAAW,aAAa;AACxB;AACA,aAAa,kBAAkB;AAC/B;AACO;AACP,4BAA4B,wEAAgB;AAC5C;;AAEA;AACA;AACA,oBAAoB,sCAAsC;AAC1D;AACA;AACA;AACA;AACA,WAAW,QAAQ;AACnB,WAAW,aAAa;AACxB;AACA,aAAa,kBAAkB;AAC/B;AACO;AACP,4BAA4B,gEAAc;AAC1C;;AAEA;AACA;AACA,UAAU,6DAA6D;AACvE,UAAU;AACV;AACA,WAAW,WAAW;AACtB,WAAW,aAAa;AACxB;AACA,aAAa,kBAAkB;AAC/B;AACO;AACP,4BAA4B,4EAAoB;AAChD;;AAEA;AACA;AACA,WAAW,QAAQ;AACnB,WAAW,UAAU;AACrB,WAAW,QAAQ;AACnB,oDAAoD;AACpD;AACA,WAAW,aAAa;AACxB;AACA,aAAa,uBAAuB;AACpC;AACO,gEAAgE;AACvE,4CAA4C,mEAAgB;AAC5D;AACA,iDAAiD,mEAAgB;AACjE;;AAEA;AACA;;AAEA;AACA;AACA,WAAW,SAAS;AACpB,aAAa,UAAU;AACvB;AACO;AACP,SAAS,gEAAY;AACrB;;AAEgB;AACQ;;;;;;;;;;;;;;;;;;;;;;;ACtvBxB;AACkD;AACI;AACM;;AAEkB;AAC4B;AACtD;AACU;;AAE9D;AACA,aAAa,QAAQ;AACrB,cAAc,eAAe;AAC7B,cAAc,eAAe;AAC7B;AACA,cAAc,eAAe;AAC7B,cAAc,SAAS;AACvB;AACA;AACA,cAAc,MAAM;AACpB,cAAc,QAAQ;AACtB;AACA,cAAc,QAAQ;AACtB;AACA,cAAc,QAAQ;AACtB,cAAc,aAAa;AAC3B;AACA,cAAc,iBAAiB;AAC/B;AACA;AACA;AACA;;AAEA,cAAc,mCAAmC;AACjD,cAAc,yCAAyC;;AAEvD;AACA;AACA,sBAAsB,SAAS;AAC/B;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,QAAQ;AACR;AACA,QAAQ;AACR;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ;AACR;AACA,QAAQ;AACR;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA,sBAAsB;AACtB;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA,oBAAoB,gBAAgB;AACpC;AACA,sBAAsB,eAAe;AACrC;AACA,wBAAwB,uBAAuB;AAC/C;AACA;;AAEA;AACA;AACA;AACA;AACA,YAAY;AACZ;AACA,YAAY;AACZ;AACA;AACA,YAAY;AACZ;AACA;;AAEA;AACA,+BAA+B,qBAAqB;AACpD;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI,yBAAyB;AAC7B;AACA;AACA;AACA;AACA,0CAA0C,4BAA4B;AACtE;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa,QAAQ;AACrB,aAAa,QAAQ;AACrB,aAAa,UAAU;AACvB,aAAa,SAAS;AACtB,aAAa,SAAS;AACtB,aAAa,0CAA0C;AACvD;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B;AAC5B;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA,eAAe,QAAQ;AACvB;AACA;AACA;AACA;;AAEA;AACA;AACA,eAAe,QAAQ;AACvB;AACA;AACA;AACA;;AAEA;AACA;AACA,eAAe,QAAQ;AACvB;AACA;AACA;AACA;;AAEA;AACA;AACA,eAAe,QAAQ;AACvB;AACA;AACA;AACA;;AAEA;AACA;AACA,eAAe,QAAQ;AACvB;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,eAAe,QAAQ;AACvB;AACA;AACA;AACA;;AAEA;AACA;AACA,eAAe,QAAQ;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;;AAEA;AACA;AACA;AACA,eAAe,QAAQ;AACvB;AACA;AACA;AACA,oBAAoB,6CAA6C;AACjE;AACA;AACA;AACA;;AAEA;AACA;AACA,2CAA2C,GAAG;AAC9C;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,UAAU;AACV;AACA,UAAU;AACV;AACA;AACA;AACA;AACA;AACA;AACA,UAAU;AACV;AACA,UAAU;AACV;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB,gEAAU;AAC/B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,aAAa,QAAQ;AACrB,aAAa,QAAQ;AACrB,aAAa,QAAQ;AACrB,aAAa,0DAA0D;AACvE,aAAa,aAAa;AAC1B;AACA,eAAe;AACf;AACA;AACA;AACA;AACA;AACA,YAAY,QAAQ;AACpB;AACA;AACA,MAAM;AACN;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,8CAA8C,2BAA2B;;AAEzE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;;AAEP;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;;AAEA;AACA,aAAa;AACb;;AAEA;AACA;AACA;AACA,aAAa,OAAO;AACpB,aAAa,OAAO;AACpB,aAAa,yBAAyB;AACtC,aAAa,SAAS;AACtB,aAAa,0CAA0C;AACvD,aAAa,QAAQ;AACrB,aAAa,QAAQ;AACrB,aAAa,QAAQ;AACrB,aAAa,aAAa;AAC1B;AACA,eAAe;AACf;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA,oBAAoB,oBAAoB;AACxC;AACA;AACA,QAAQ;AACR;AACA;AACA;AACA;;AAEA;AACA,YAAY,eAAe;;AAE3B,+BAA+B,kBAAkB;AACjD,iCAAiC,kBAAkB;AACnD,kCAAkC,8BAA8B;AAChE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA,kEAAkE,UAAU;AAC5E,mEAAmE,UAAU;AAC7E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB;AAClB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,oBAAoB,iEAAmB;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ;AACR,oBAAoB,sDAAQ;AAC5B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa,mBAAmB,WAAW;AAC3C,eAAe,2BAA2B;AAC1C;AACA;AACA;AACA;AACA,IAAI,IAAI;AACR;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA,sBAAsB,qBAAqB;AAC3C;AACA;AACA,MAAM;AACN,sBAAsB,oBAAoB;AAC1C;AACA,wEAAwE,WAAW;AACnF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA,sBAAsB,oBAAoB;AAC1C;AACA;AACA;AACA,UAAU;AACV;AACA;AACA;AACA;AACA;;AAEA,wCAAwC,iEAAU;;AAElD;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa,QAAQ;AACrB,aAAa,eAAe;AAC5B,aAAa,SAAS;AACtB;AACA;AACA,aAAa,0BAA0B;AACvC,aAAa,QAAQ;AACrB;AACA,aAAa,QAAQ;AACrB;AACA,aAAa,QAAQ;AACrB,aAAa,SAAS;AACtB,aAAa,aAAa;AAC1B;AACA,eAAe,2BAA2B;AAC1C;AACA,kBAAkB;AAClB,kDAAkD,IAAI;AACtD;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA,eAAe,mEAA0B;AACzC;AACA,iDAAiD,2DAAkB;AACnE;AACA,wBAAwB,6CAA6C;AACrE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;;AAEA;AACA;AACA,WAAW,mEAA0B;AACrC,WAAW,mEAA0B;AACrC,WAAW,mEAA0B;AACrC;AACA;AACA,WAAW,mEAA0B;AACrC;AACA;AACA,WAAW,mEAA0B;AACrC,WAAW,mEAA0B;AACrC;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,gBAAgB;AAC5B;;AAEA;AACA;AACA;AACA,WAAW,mEAA0B;AACrC,eAAe,wDAAe;AAC9B;AACA,WAAW,mEAA0B;AACrC,eAAe,wDAAe;AAC9B;AACA,WAAW,mEAA0B;AACrC,eAAe,oDAAW;AAC1B;AACA,WAAW,mEAA0B;AACrC,eAAe,iDAAQ;AACvB;AACA,WAAW,mEAA0B;AACrC,eAAe,kDAAS;AACxB;AACA,WAAW,mEAA0B;AACrC,eAAe,mDAAU;AACzB;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,iBAAiB;AAC9C;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA,eAAe;AACf;AACA;AACA;AACA;AACA;;AAEA;AACA,oBAAoB,6CAA6C;AACjE;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa,QAAQ;AACrB,eAAe;AACf;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,gBAAgB,2DAAc;;AAE9B;AACA,qCAAqC,uDAAY;AACjD,MAAM;AACN,4CAA4C,uDAAY;AACxD;;AAEA,oBAAoB,kBAAkB;AACtC;AACA,eAAe,uDAAY;AAC3B;AACA;AACA;;AAEA;AACA;AACA,eAAe;AACf;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,eAAe,eAAe;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,aAAa,cAAc;AAC3B;AACA;AACA,eAAe,eAAe;AAC9B;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA,eAAe,SAAS;AACxB;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,eAAe,eAAe;AAC9B;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,iEAAe,YAAY,EAAC;;;;;;;;;;;;;;;;;;AC74B5B;AACA;AACA;AACA;AACA;AACA;AACyF;AACnB;;AAEtE,qBAAqB,iDAAM,CAAC,sDAAa;AACzC,wBAAwB,iDAAM,CAAC,oDAAW;AAC1C;AACA,iDAAM;AACN,iDAAM;AACN,sBAAsB,iDAAM,CAAC,uDAAc;;AAE3C;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA,GAAG;AACH;AACA;AACA,IAAI,gDAAK;AACT;AACA,KAAK;AACL;AACA,GAAG;AACH;AACA;AACA,IAAI,gDAAK;AACT;AACA,KAAK;AACL;AACA,GAAG;AACH;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA,IAAI,gDAAK;AACT;AACA,KAAK;AACL,GAAG;AACH;AACA;;AAEA;;AAEA;AACA;AACA,EAAE,gDAAK;AACP;AACA,GAAG;AACH;;AAEA;AACA;;AAEA;AACA;AACA,GAAG;;AAEH;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;;AAEA,qBAAqB,sDAAa;AAClC;;AAEA;AACA,8CAA8C,IAAI;AAClD;;AAEA;;AAEA;AACA,qDAAqD,IAAI;AACzD;;AAEA;AACA;AACA;AACA,2DAA2D,mDAAQ;AACnE;AACA;;AAEA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA,MAAM;AACN,MAAM,gDAAK;AACX;AACA,OAAO;AACP,MAAM;AACN,MAAM,gDAAK;AACX;AACA,OAAO;AACP,MAAM;AACN,MAAM,gDAAK;AACX;AACA;AACA,OAAO;AACP,MAAM;AACN,MAAM,gDAAK;AACX;AACA,OAAO;AACP;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;;AAEH;AACA;AACA;;AAEA;AACA;AACA,kBAAkB,UAAU;AAC5B;AACA;AACA;AACA;;AAEA;AACA;AACA,mEAAmE,OAAO;AAC1E;;AAEA;AACA,mEAAmE,MAAM;AACzE;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;;AAEA;;AAEA;AACA,EAAE,gDAAK;AACP;AACA,GAAG;AACH,EAAE,kDAAO;AACT;AACA,GAAG;;AAEH;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEO;AACP;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA,IAAI,gDAAK;AACT,MAAM,gDAAK;AACX,QAAQ,gDAAK;AACb;AACA,SAAS;AACT,OAAO;AACP,KAAK;AACL;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;AACA,6BAA6B,gDAAK;AAClC;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;;AAEH;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA,4BAA4B,gDAAK;AACjC;;AAEA;AACA;AACA;AACA,qDAAqD;AACrD;AACA;AACA;;AAEA;AACA,qBAAqB,mDAAQ;AAC7B;;AAEA;AACA;AACA;AACA;AACA,sBAAsB,sDAAa;AACnC;AACA,6BAA6B,0BAA0B;AACvD;AACA,KAAK;AACL;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,UAAU,sDAAa;AACvB;AACA;AACA;AACA,QAAQ;AACR;AACA;AACA;AACA,QAAQ;AACR,qEAAqE,OAAO;AAC5E;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;;AAEH;;AAEA;;AAEA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;ACvcO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEO;AACP;AACA;AACA;AACA;AACA;;AAEO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEO;AACP;AACA;AACA;AACA;AACA;;AAEO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEO;AACP;AACA;AACA;AACA;;AAEO;AACP;AACA;AACA;;AAEO;AACP;AACA;AACA;;AAEO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEO;AACP;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;ACpSA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;;AAEA;;AAEA;;AAEA;;AAEA;AACA;;AAEA;;AAEA;AACA;AACA,WAAW,QAAQ;AACnB;AACO;AACP;AACA;;AAEO;AACP;AACA;;AAEO;AACP;AACA;;AAEO;AACP;AACA;;AAEO;AACP;AACA;;AAEO;AACP;AACA;;AAEO;AACP;AACA;;AAEO;AACP;AACA;;;;;;;;;;;;;;;;;ACvDoD;;AAEpD;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa,QAAQ;AACrB;AACA;AACA,aAAa,oBAAoB;AACjC;AACA;AACA;AACA;AACA;AACA;AACA,cAAc,yBAAyB;AACvC;AACA;AACA,eAAe,4BAA4B;AAC3C;AACA;AACA,0BAA0B,aAAa;AACvC,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,0OAA6B;AACrC;AACA,SAAS;AACT,OAAO;AACP;AACA;AACA;AACA,wBAAwB,UAAU;AAClC,8BAA8B,8BAA8B;AAC5D;AACA,OAAO;AACP;AACA;;AAEA;AACA;AACA,aAAa,aAAa;AAC1B,eAAe,sBAAsB;AACrC;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,iEAAU;AAClB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oCAAoC,2BAA2B;AAC/D,OAAO;AACP;;AAEA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;;AAEA,iEAAe,IAAI,EAAC;;;;;;;;;;;;;;;;ACpGpB;AACA;AACA;AACA;AACA,yBAAyB,OAAO;AAChC;AACA;AACA;;AAEA;AACA,IAAI;AACJ;;AAEA;AACA;AACA;AACA;;AAEA;AACA,yBAAyB,OAAO;AAChC;AACA;AACA;AACA;AACA;;AAEA;AACA,kBAAkB,QAAQ;AAC1B,oBAAoB,oBAAoB;AACxC;AACA;AACA;AACA;;AAEO;AACP;AACA;AACA;AACA;;AAEA,kBAAkB,0BAA0B;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA,kBAAkB,YAAY;AAC9B;AACA;AACA;AACA;AACA;AACA,2BAA2B;AAC3B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0DAA0D,kBAAkB;AAC5E;AACA;AACA,MAAM,4BAA4B;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;ACvFA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA,WAAW,cAAc;AACzB,WAAW,QAAQ;AACnB,WAAW,QAAQ;AACnB,WAAW,QAAQ;AACnB,WAAW,QAAQ;AACnB,aAAa,cAAc;AAC3B;AACO;AACP;AACA;AACA;AACA;AACA,oBAAoB,eAAe;AACnC;AACA,sBAAsB,cAAc;AACpC;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,WAAW,cAAc;AACzB,WAAW,QAAQ;AACnB,WAAW,QAAQ;AACnB,WAAW,QAAQ;AACnB,WAAW,QAAQ;AACnB,aAAa,cAAc;AAC3B;AACO;AACP;AACA;;AAEA;AACA;AACA,oBAAoB,eAAe;AACnC;;AAEA;AACA;;AAEA,sBAAsB,cAAc;AACpC;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA,WAAW,cAAc;AACzB,WAAW,QAAQ;AACnB,WAAW,QAAQ;AACnB,WAAW,QAAQ;AACnB,WAAW,QAAQ;AACnB,WAAW,QAAQ;AACnB,aAAa,cAAc;AAC3B;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yDAAyD,OAAO;AAChE;AACA;;AAEA;AACA;AACA,WAAW,YAAY;AACvB,WAAW,QAAQ;AACnB,WAAW,QAAQ;AACnB,WAAW,QAAQ;AACnB,WAAW,QAAQ;AACnB,WAAW,QAAQ;AACnB;AACA,aAAa,YAAY;AACzB;AACO;AACP;AACA;AACA;;AAEA;AACA,kBAAkB,eAAe;AACjC;AACA,oBAAoB,cAAc;AAClC;AACA,sBAAsB,aAAa;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,WAAW,YAAY;AACvB,WAAW,QAAQ;AACnB,WAAW,QAAQ;AACnB,WAAW,QAAQ;AACnB,WAAW,QAAQ;AACnB,WAAW,QAAQ;AACnB;AACA,aAAa,YAAY;AACzB;AACO;AACP;AACA;AACA;AACA;AACA,kBAAkB,eAAe;AACjC;;AAEA;AACA;;AAEA,oBAAoB,cAAc;AAClC;AACA;;AAEA;AACA;;AAEA,sBAAsB,aAAa;AACnC;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,WAAW,YAAY;AACvB,WAAW,QAAQ;AACnB,WAAW,QAAQ;AACnB,WAAW,QAAQ;AACnB,WAAW,QAAQ;AACnB,WAAW,QAAQ;AACnB;AACA,WAAW,QAAQ;AACnB,aAAa,YAAY;AACzB;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yDAAyD,OAAO;AAChE;AACA;;;;;;;;;;;;;;;;;;;;;AClNO;AACP,UAAU,gBAAgB;AAC1B;AACA;AACA,yBAAyB,mBAAmB;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA;;AAEO;AACP,UAAU,gBAAgB;AAC1B;AACA;AACA,yBAAyB,mBAAmB;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA;;AAEO;AACP,UAAU,gBAAgB;AAC1B;AACA;AACA;AACA,yBAAyB,mBAAmB;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA;;AAEO;AACP,UAAU,gBAAgB;AAC1B;AACA,yBAAyB,uBAAuB;AAChD;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEO;AACP,UAAU,gBAAgB;AAC1B;AACA,yBAAyB,wBAAwB;AACjD;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEO;AACP,UAAU,gBAAgB;AAC1B;;AAEA,yBAAyB,yBAAyB;AAClD;AACA,gDAAgD;AAChD,gDAAgD;;AAEhD;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;AC9G6C;AACJ;;AAEzC,gCAAgC,sDAAU;AAC1C;AACA;AACA;AACA;;AAEA;AACA;AACA,gBAAgB,iDAAU;AAC1B;AACA;AACA;AACA;;AAEO;AACP;AACA;;;;;;;;;;;;;;;;ACnBA;AACA;AACA,cAAc,QAAQ;AACtB,cAAc,QAAQ;AACtB;;AAEO;AACP;AACA;AACA,aAAa,SAAS;AACtB,eAAe;AACf;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,aAAa,OAAO;AACpB,eAAe;AACf;AACA;AACA,yCAAyC,OAAO;AAChD;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;ACrCiC;AACY;AACuB;;AAEpE;AACA;AACA;AACA,aAAa,QAAQ;AACrB,aAAa,QAAQ;AACrB,aAAa,aAAa;AAC1B;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,eAAe,QAAQ;AACvB;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,aAAa,QAAQ;AACrB,aAAa,QAAQ;AACrB,aAAa,UAAU;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;;AAEO,4BAA4B,sDAAU;AAC7C;AACA;AACA,aAAa,YAAY;AACzB,aAAa,QAAQ;AACrB,aAAa,QAAQ;AACrB,aAAa,QAAQ;AACrB;AACA,wBAAwB,qCAAqC,IAAI;AACjE;AACA;AACA;;AAEA,0BAA0B,iDAAQ;AAClC;AACA;AACA;AACA,OAAO;AACP,KAAK;;AAEL,eAAe,oBAAoB;AACnC;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA,aAAa,gCAAgC;AAC7C;AACA;AACA;AACA;AACA;AACA;;AAEA,iBAAiB,iBAAiB;AAClC;;AAEA,cAAc,WAAW;AACzB;AACA;AACA;;AAEA;;AAEA,2CAA2C,eAAe;AAC1D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,UAAU,+CAAI;AACd;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mCAAmC,SAAS;AAC5C;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,gBAAgB,iDAAU;AAC1B;;AAEA;AACA;AACA;AACA,gBAAgB,qDAAc;AAC9B;;AAEA;AACA,mCAAmC,8CAAG;;AAEtC;AACA;AACA;;AAEA;AACA;AACA,aAAa,aAAa;AAC1B;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA,+BAA+B,4BAA4B;AAC3D;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,cAAc;AACd;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB;AAChB;AACA;AACA,cAAc;AACd;AACA;AACA,WAAW;AACX;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,aAAa,KAAK;AAClB,eAAe;AACf;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,QAAQ;AACR;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA,aAAa,gCAAgC;AAC7C,aAAa,KAAK;AAClB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,qCAAqC,wBAAwB;AAC7D;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,UAAU;AACV;AACA;;AAEA;AACA;AACA,UAAU;AACV;AACA;;AAEA;AACA;AACA;;AAEA;AACA,KAAK;AACL;AACA;;;;;;;;;;;;;;;;;ACvSO;AACP;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,aAAa,QAAQ;AACrB,eAAe,QAAQ;AACvB;AACA,0BAA0B;AAC1B;AACA;;AAEA;AACA,eAAe,aAAa;AAC5B;AACA;AACA;AACA;AACA;;AAEO;AACP;AACA;AACA;;AAEA;AACA;AACA,aAAa,QAAQ;AACrB;AACA,kBAAkB,+BAA+B,IAAI,IAAI;AACzD;AACA;AACA;;;;;;;;;;;;;;;;;AC5CqD;;AAErD,4BAA4B,kDAAY;AACxC;AACA;AACA,aAAa,UAAU;AACvB;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEO,0BAA0B,gDAAU;AAC3C;AACA;AACA;AACA;;AAEA,kBAAkB,+BAA+B,IAAI;AACrD;AACA;AACA,KAAK;AACL;AACA;AACA;;;;;;;;;;;;;;;;;;;;;ACxCwB;AACE;AACD;;AAE4B;AACT;;AAE5C,2BAA2B,kDAAY;AACvC;AACA;AACA,aAAa,qBAAqB;AAClC;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEO,yBAAyB,gDAAU;AAC1C;AACA;AACA,qBAAqB,sCAAY;AACjC,0DAA0D,iCAAI,GAAG,kCAAK;AACtE;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;;AAEA;AACA;AACA;AACA,aAAa;;AAEb;AACA;AACA;AACA;AACA,aAAa;AACb;AACA,WAAW;AACX;AACA,SAAS;AACT;AACA;;AAEA;AACA;AACA,8BAA8B,iDAAU;AACxC;AACA,mEAAmE,iDAAU;AAC7E;AACA,KAAK;AACL;;AAEA,kBAAkB,kBAAkB,IAAI;AACxC;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;AChFqD;AACT;;AAE5C,0BAA0B,kDAAY;AACtC;AACA;AACA,aAAa,gBAAgB;AAC7B,aAAa,aAAa;AAC1B;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEO,wBAAwB,gDAAU;AACzC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,qCAAqC,iDAAU;AAC/C;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA,kBAAkB,kBAAkB,IAAI;AACxC;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;AC5DoB;AACyB;;AAE7C;AACA;AACA,IAAI,qCAAQ;AACZ;AACA;AACA,QAAQ;AACR;AACA;AACA,KAAK;AACL,GAAG;AACH;;AAEA;AACA;AACA,IAAI,oCAAO;AACX;AACA;AACA,QAAQ;AACR;AACA;AACA,KAAK;AACL,GAAG;AACH;;AAEA;AACA;AACA,IAAI,oCAAO;AACX;AACA;AACA,QAAQ;AACR,kBAAkB,mBAAmB;AACrC;AACA,KAAK;AACL,GAAG;AACH;;AAEA,yBAAyB,sDAAU;AACnC;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,YAAY,SAAS;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEO;AACP;AACA;;;;;;;;;;;;;;;;;ACnE6C;;AAE7C,+BAA+B,sDAAU;AACzC;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,KAAK;AACL;AACA;;AAEA;AACA;AACA,WAAW,MAAM;AACjB;AACA;AACO;AACP;AACA;;;;;;;;;;;;;;;;;;AC/BA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,WAAW,QAAQ;AACnB,aAAa,QAAQ;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;;AAEL;AACA;;AAEA;AACA;AACA,WAAW,QAAQ;AACnB,aAAa,QAAQ;AACrB;AACO;AACP,sDAAsD;AACtD;AACA,WAAW;AACX;;AAEA;AACA;AACA,WAAW,QAAQ;AACnB,aAAa,QAAQ;AACrB;AACO;AACP;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA,WAAW;AACX;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,aAAa;AACxB,WAAW,QAAQ;AACnB,aAAa,UAAU;AACvB;AACO;AACP;AACA;AACA;;AAEA,6BAA6B,SAAS;AACtC,yBAAyB,cAAc;;AAEvC;AACA;AACA,kBAAkB,QAAQ;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA,YAAY,oBAAoB;;AAEhC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;;AAEL;AACA;;AAEA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;AChJsF;AACzC;AACM;;AAEH;AACJ;AACE;;AAE9C,2BAA2B,sDAAU;AACrC;AACA;AACA,aAAa,YAAY;AACzB,aAAa,QAAQ;AACrB,aAAa,SAAS;AACtB,aAAa,SAAS;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,aAAa,SAAS;AACtB;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;;AAEA;AACA,yBAAyB,mBAAmB;AAC5C;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,wBAAwB;AACxB,kBAAkB,gBAAgB,QAAQ,OAAO,GAAG,gBAAgB;AACpE;AACA,SAAS;AACT,OAAO;AACP;AACA,KAAK;;AAEL;AACA;AACA,MAAM;AACN,cAAc,eAAe,EAAE,+DAAgB;AAC/C;AACA,2BAA2B,8DAAe;AAC1C;AACA;AACA;;AAEA;;AAEA,cAAc,oBAAoB,EAAE,gEAAiB;AACrD;AACA;AACA;AACA;AACA;AACA,OAAO;;AAEP;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;;AAEA;AACA,YAAY,iBAAiB;AAC7B;AACA;AACA;AACA,wBAAwB,OAAO,GAAG,gBAAgB;AAClD,OAAO;AACP;AACA,KAAK;;AAEL;AACA;AACA;AACA,MAAM;AACN;;AAEA,cAAc,QAAQ,EAAE,gEAAiB;AACzC;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA,4CAA4C,sBAAsB;AAClE;AACA;AACA;AACA,aAAa,4DAAa,WAAW,sBAAsB;AAC3D;;AAEO,gCAAgC,YAAY,uEAAuE,IAAI;AAC9H,qBAAqB,yDAAW;AAChC;AACA;AACA;;AAEO,8BAA8B,YAAY,0DAA0D,IAAI;AAC/G,qBAAqB,qDAAS;AAC9B;AACA;AACA;;AAEO,+BAA+B,YAAY,0DAA0D,IAAI;AAChH,qBAAqB,uDAAU;AAC/B;AACA;AACA;;AAEA;AACA;AACA,WAAW,QAAQ;AACnB,WAAW,QAAQ;AACnB;AACO,iCAAiC,qCAAqC,IAAI;AACjF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC9LO;AACP;AACA;AACA;AACA;AACA;AACA;;AAEO;AACP;AACA;AACA,kBAAkB,sBAAsB;AACxC;AACA,qBAAqB,iBAAiB;AACtC;AACA;AACA;AACA;AACA;AACA;;AAEO;AACP;AACA;AACA;AACA;AACA;AACA;;AAEO;AACP,UAAU,SAAS;AACnB,kBAAkB,YAAY;AAC9B;AACA;AACA;;AAEO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEO;AACP;AACA,kBAAkB,OAAO;AACzB;AACA;AACA;AACA;;AAEO;AACP;AACA,kBAAkB,cAAc;AAChC;AACA;AACA;AACA;;AAEO;AACP;AACA,UAAU,SAAS;AACnB,kBAAkB,YAAY;AAC9B;AACA;AACA;AACA;;AAEO;AACP;AACA;AACA;AACA;AACA;;AAEA;AACO;AACP;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACO;AACP;AACA;;AAEO;AACP;AACA;AACA;AACA;;AAEA;AACO;AACP;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;;AAEO;;;;;;;;;;;;;;;;AC7JQ;AACf,yBAAyB;AACzB;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,kBAAkB,sBAAsB,IAAI;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ,IAAI;AACJ,mBAAmB,cAAc;AACjC;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,iCAAiC,QAAQ;AACzC;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,iCAAiC,QAAQ;AACzC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA","sources":["webpack://@aics/volume-viewer/./node_modules/xml-utils/count-substring.js","webpack://@aics/volume-viewer/./node_modules/xml-utils/find-tag-by-name.js","webpack://@aics/volume-viewer/./node_modules/xml-utils/find-tags-by-name.js","webpack://@aics/volume-viewer/./node_modules/xml-utils/get-attribute.js","webpack://@aics/volume-viewer/./node_modules/xml-utils/index-of-match-end.js","webpack://@aics/volume-viewer/./node_modules/xml-utils/index-of-match.js","webpack://@aics/volume-viewer/./node_modules/@petamoriken/float16/src/DataView.mjs","webpack://@aics/volume-viewer/./node_modules/@petamoriken/float16/src/_util/arrayIterator.mjs","webpack://@aics/volume-viewer/./node_modules/@petamoriken/float16/src/_util/converter.mjs","webpack://@aics/volume-viewer/./node_modules/@petamoriken/float16/src/_util/messages.mjs","webpack://@aics/volume-viewer/./node_modules/@petamoriken/float16/src/_util/primordials.mjs","webpack://@aics/volume-viewer/./node_modules/geotiff/dist-module/compression/basedecoder.js","webpack://@aics/volume-viewer/./node_modules/geotiff/dist-module/compression/index.js","webpack://@aics/volume-viewer/./node_modules/geotiff/dist-module/dataslice.js","webpack://@aics/volume-viewer/./node_modules/geotiff/dist-module/dataview64.js","webpack://@aics/volume-viewer/./node_modules/geotiff/dist-module/geotiff.js","webpack://@aics/volume-viewer/./node_modules/geotiff/dist-module/geotiffimage.js","webpack://@aics/volume-viewer/./node_modules/geotiff/dist-module/geotiffwriter.js","webpack://@aics/volume-viewer/./node_modules/geotiff/dist-module/globals.js","webpack://@aics/volume-viewer/./node_modules/geotiff/dist-module/logging.js","webpack://@aics/volume-viewer/./node_modules/geotiff/dist-module/pool.js","webpack://@aics/volume-viewer/./node_modules/geotiff/dist-module/predictor.js","webpack://@aics/volume-viewer/./node_modules/geotiff/dist-module/resample.js","webpack://@aics/volume-viewer/./node_modules/geotiff/dist-module/rgb.js","webpack://@aics/volume-viewer/./node_modules/geotiff/dist-module/source/arraybuffer.js","webpack://@aics/volume-viewer/./node_modules/geotiff/dist-module/source/basesource.js","webpack://@aics/volume-viewer/./node_modules/geotiff/dist-module/source/blockedsource.js","webpack://@aics/volume-viewer/./node_modules/geotiff/dist-module/source/client/base.js","webpack://@aics/volume-viewer/./node_modules/geotiff/dist-module/source/client/fetch.js","webpack://@aics/volume-viewer/./node_modules/geotiff/dist-module/source/client/http.js","webpack://@aics/volume-viewer/./node_modules/geotiff/dist-module/source/client/xhr.js","webpack://@aics/volume-viewer/./node_modules/geotiff/dist-module/source/file.js","webpack://@aics/volume-viewer/./node_modules/geotiff/dist-module/source/filereader.js","webpack://@aics/volume-viewer/./node_modules/geotiff/dist-module/source/httputils.js","webpack://@aics/volume-viewer/./node_modules/geotiff/dist-module/source/remote.js","webpack://@aics/volume-viewer/./node_modules/geotiff/dist-module/utils.js","webpack://@aics/volume-viewer/./node_modules/quick-lru/index.js"],"sourcesContent":["function countSubstring(string, substring) {\n  const pattern = new RegExp(substring, \"g\");\n  const match = string.match(pattern);\n  return match ? match.length : 0;\n}\n\nmodule.exports = countSubstring;\nmodule.exports.default = countSubstring;\n","const indexOfMatch = require(\"./index-of-match.js\");\nconst indexOfMatchEnd = require(\"./index-of-match-end.js\");\nconst countSubstring = require(\"./count-substring.js\");\n\nfunction findTagByName(xml, tagName, options) {\n  const debug = (options && options.debug) || false;\n  const nested = !(options && typeof options.nested === false);\n\n  const startIndex = (options && options.startIndex) || 0;\n\n  if (debug) console.log(\"[xml-utils] starting findTagByName with\", tagName, \" and \", options);\n\n  const start = indexOfMatch(xml, `\\<${tagName}[ \\n\\>\\/]`, startIndex);\n  if (debug) console.log(\"[xml-utils] start:\", start);\n  if (start === -1) return undefined;\n\n  const afterStart = xml.slice(start + tagName.length);\n\n  let relativeEnd = indexOfMatchEnd(afterStart, \"^[^<]*[ /]>\", 0);\n\n  const selfClosing = relativeEnd !== -1 && afterStart[relativeEnd - 1] === \"/\";\n  if (debug) console.log(\"[xml-utils] selfClosing:\", selfClosing);\n\n  if (selfClosing === false) {\n    // check if tag has subtags with the same name\n    if (nested) {\n      let startIndex = 0;\n      let openings = 1;\n      let closings = 0;\n      while ((relativeEnd = indexOfMatchEnd(afterStart, \"[ /]\" + tagName + \">\", startIndex)) !== -1) {\n        const clip = afterStart.substring(startIndex, relativeEnd + 1);\n        openings += countSubstring(clip, \"<\" + tagName + \"[ \\n\\t>]\");\n        closings += countSubstring(clip, \"</\" + tagName + \">\");\n        // we can't have more openings than closings\n        if (closings >= openings) break;\n        startIndex = relativeEnd;\n      }\n    } else {\n      relativeEnd = indexOfMatchEnd(afterStart, \"[ /]\" + tagName + \">\", 0);\n    }\n  }\n\n  const end = start + tagName.length + relativeEnd + 1;\n  if (debug) console.log(\"[xml-utils] end:\", end);\n  if (end === -1) return undefined;\n\n  const outer = xml.slice(start, end);\n  // tag is like <gml:identifier codeSpace=\"OGP\">urn:ogc:def:crs:EPSG::32617</gml:identifier>\n\n  let inner;\n  if (selfClosing) {\n    inner = null;\n  } else {\n    inner = outer.slice(outer.indexOf(\">\") + 1, outer.lastIndexOf(\"<\"));\n  }\n\n  return { inner, outer, start, end };\n}\n\nmodule.exports = findTagByName;\nmodule.exports.default = findTagByName;\n","const findTagByName = require(\"./find-tag-by-name.js\");\n\nfunction findTagsByName(xml, tagName, options) {\n  const tags = [];\n  const debug = (options && options.debug) || false;\n  const nested = options && typeof options.nested === \"boolean\" ? options.nested : true;\n  let startIndex = (options && options.startIndex) || 0;\n  let tag;\n  while ((tag = findTagByName(xml, tagName, { debug, startIndex }))) {\n    if (nested) {\n      startIndex = tag.start + 1 + tagName.length;\n    } else {\n      startIndex = tag.end;\n    }\n    tags.push(tag);\n  }\n  if (debug) console.log(\"findTagsByName found\", tags.length, \"tags\");\n  return tags;\n}\n\nmodule.exports = findTagsByName;\nmodule.exports.default = findTagsByName;\n","function getAttribute(tag, attributeName, options) {\n  const debug = (options && options.debug) || false;\n  if (debug) console.log(\"[xml-utils] getting \" + attributeName + \" in \" + tag);\n\n  const xml = typeof tag === \"object\" ? tag.outer : tag;\n\n  // only search for attributes in the opening tag\n  const opening = xml.slice(0, xml.indexOf(\">\") + 1);\n\n  const quotechars = ['\"', \"'\"];\n  for (let i = 0; i < quotechars.length; i++) {\n    const char = quotechars[i];\n    const pattern = attributeName + \"\\\\=\" + char + \"([^\" + char + \"]*)\" + char;\n    if (debug) console.log(\"[xml-utils] pattern:\", pattern);\n\n    const re = new RegExp(pattern);\n    const match = re.exec(opening);\n    if (debug) console.log(\"[xml-utils] match:\", match);\n    if (match) return match[1];\n  }\n}\n\nmodule.exports = getAttribute;\nmodule.exports.default = getAttribute;\n","function indexOfMatchEnd(xml, pattern, startIndex) {\n  const re = new RegExp(pattern);\n  const match = re.exec(xml.slice(startIndex));\n  if (match) return startIndex + match.index + match[0].length - 1;\n  else return -1;\n}\n\nmodule.exports = indexOfMatchEnd;\nmodule.exports.default = indexOfMatchEnd;\n","function indexOfMatch(xml, pattern, startIndex) {\n  const re = new RegExp(pattern);\n  const match = re.exec(xml.slice(startIndex));\n  if (match) return startIndex + match.index;\n  else return -1;\n}\n\nmodule.exports = indexOfMatch;\nmodule.exports.default = indexOfMatch;\n","import { safeIfNeeded } from \"./_util/arrayIterator.mjs\";\nimport { convertToNumber, roundToFloat16Bits } from \"./_util/converter.mjs\";\nimport {\n  DataViewPrototypeGetUint16,\n  DataViewPrototypeSetUint16,\n} from \"./_util/primordials.mjs\";\n\n/**\n * returns an unsigned 16-bit float at the specified byte offset from the start of the DataView\n *\n * @param {DataView} dataView\n * @param {number} byteOffset\n * @param {[boolean]} opts\n * @returns {number}\n */\nexport function getFloat16(dataView, byteOffset, ...opts) {\n  return convertToNumber(\n    DataViewPrototypeGetUint16(dataView, byteOffset, ...safeIfNeeded(opts))\n  );\n}\n\n/**\n * stores an unsigned 16-bit float value at the specified byte offset from the start of the DataView\n *\n * @param {DataView} dataView\n * @param {number} byteOffset\n * @param {number} value\n * @param {[boolean]} opts\n */\nexport function setFloat16(dataView, byteOffset, value, ...opts) {\n  return DataViewPrototypeSetUint16(\n    dataView,\n    byteOffset,\n    roundToFloat16Bits(value),\n    ...safeIfNeeded(opts)\n  );\n}\n","import {\n  ArrayIteratorPrototype,\n  ArrayIteratorPrototypeNext,\n  ArrayPrototypeSymbolIterator,\n  GeneratorPrototypeNext,\n  IteratorPrototype,\n  NativeArrayPrototypeSymbolIterator,\n  NativeWeakMap,\n  ObjectCreate,\n  ObjectDefineProperty,\n  ReflectGetOwnPropertyDescriptor,\n  ReflectOwnKeys,\n  SymbolIterator,\n  WeakMapPrototypeGet,\n  WeakMapPrototypeSet,\n} from \"./primordials.mjs\";\n\n/** @type {WeakMap<{}, IterableIterator<any>>} */\nconst arrayIterators = new NativeWeakMap();\n\nconst SafeIteratorPrototype = ObjectCreate(null, {\n  next: {\n    value: function next() {\n      const arrayIterator = WeakMapPrototypeGet(arrayIterators, this);\n      return ArrayIteratorPrototypeNext(arrayIterator);\n    },\n  },\n\n  [SymbolIterator]: {\n    value: function values() {\n      return this;\n    },\n  },\n});\n\n/**\n * Wrap the Array around the SafeIterator If Array.prototype [@@iterator] has been modified\n *\n * @type {<T>(array: T[]) => Iterable<T>}\n */\nexport function safeIfNeeded(array) {\n  if (\n    array[SymbolIterator] === NativeArrayPrototypeSymbolIterator &&\n    ArrayIteratorPrototype.next === ArrayIteratorPrototypeNext\n  ) {\n    return array;\n  }\n\n  const safe = ObjectCreate(SafeIteratorPrototype);\n  WeakMapPrototypeSet(arrayIterators, safe, ArrayPrototypeSymbolIterator(array));\n  return safe;\n}\n\n/** @type {WeakMap<{}, Generator<any>>} */\nconst generators = new NativeWeakMap();\n\n/** @see https://tc39.es/ecma262/#sec-%arrayiteratorprototype%-object */\nconst DummyArrayIteratorPrototype = ObjectCreate(IteratorPrototype, {\n  next: {\n    value: function next() {\n      const generator = WeakMapPrototypeGet(generators, this);\n      return GeneratorPrototypeNext(generator);\n    },\n    writable: true,\n    configurable: true,\n  },\n});\n\nfor (const key of ReflectOwnKeys(ArrayIteratorPrototype)) {\n  // next method has already defined\n  if (key === \"next\") {\n    continue;\n  }\n\n  // Copy ArrayIteratorPrototype descriptors to DummyArrayIteratorPrototype\n  ObjectDefineProperty(DummyArrayIteratorPrototype, key, ReflectGetOwnPropertyDescriptor(ArrayIteratorPrototype, key));\n}\n\n/**\n * Wrap the Generator around the dummy ArrayIterator\n *\n * @type {<T>(generator: Generator<T>) => IterableIterator<T>}\n */\nexport function wrap(generator) {\n  const dummy = ObjectCreate(DummyArrayIteratorPrototype);\n  WeakMapPrototypeSet(generators, dummy, generator);\n  return dummy;\n}\n","// algorithm: http://fox-toolkit.org/ftp/fasthalffloatconversion.pdf\n\nimport {\n  NativeArrayBuffer,\n  NativeFloat32Array,\n  NativeUint32Array,\n} from \"./primordials.mjs\";\n\nconst buffer = new NativeArrayBuffer(4);\nconst floatView = new NativeFloat32Array(buffer);\nconst uint32View = new NativeUint32Array(buffer);\n\nconst baseTable = new NativeUint32Array(512);\nconst shiftTable = new NativeUint32Array(512);\n\nfor (let i = 0; i < 256; ++i) {\n  const e = i - 127;\n\n  // very small number (0, -0)\n  if (e < -27) {\n    baseTable[i]         = 0x0000;\n    baseTable[i | 0x100] = 0x8000;\n    shiftTable[i]         = 24;\n    shiftTable[i | 0x100] = 24;\n\n  // small number (denorm)\n  } else if (e < -14) {\n    baseTable[i]         =  0x0400 >> (-e - 14);\n    baseTable[i | 0x100] = (0x0400 >> (-e - 14)) | 0x8000;\n    shiftTable[i]         = -e - 1;\n    shiftTable[i | 0x100] = -e - 1;\n\n  // normal number\n  } else if (e <= 15) {\n    baseTable[i]         =  (e + 15) << 10;\n    baseTable[i | 0x100] = ((e + 15) << 10) | 0x8000;\n    shiftTable[i]         = 13;\n    shiftTable[i | 0x100] = 13;\n\n  // large number (Infinity, -Infinity)\n  } else if (e < 128) {\n    baseTable[i]         = 0x7c00;\n    baseTable[i | 0x100] = 0xfc00;\n    shiftTable[i]         = 24;\n    shiftTable[i | 0x100] = 24;\n\n  // stay (NaN, Infinity, -Infinity)\n  } else {\n    baseTable[i]         = 0x7c00;\n    baseTable[i | 0x100] = 0xfc00;\n    shiftTable[i]         = 13;\n    shiftTable[i | 0x100] = 13;\n  }\n}\n\n/**\n * round a number to a half float number bits\n *\n * @param {unknown} num - double float\n * @returns {number} half float number bits\n */\nexport function roundToFloat16Bits(num) {\n  floatView[0] = /** @type {any} */ (num);\n  const f = uint32View[0];\n  const e = (f >> 23) & 0x1ff;\n  return baseTable[e] + ((f & 0x007fffff) >> shiftTable[e]);\n}\n\nconst mantissaTable = new NativeUint32Array(2048);\nconst exponentTable = new NativeUint32Array(64);\nconst offsetTable = new NativeUint32Array(64);\n\nfor (let i = 1; i < 1024; ++i) {\n  let m = i << 13;    // zero pad mantissa bits\n  let e = 0;          // zero exponent\n\n  // normalized\n  while((m & 0x00800000) === 0) {\n    m <<= 1;\n    e -= 0x00800000;  // decrement exponent\n  }\n\n  m &= ~0x00800000;   // clear leading 1 bit\n  e += 0x38800000;    // adjust bias\n\n  mantissaTable[i] = m | e;\n}\nfor (let i = 1024; i < 2048; ++i) {\n  mantissaTable[i] = 0x38000000 + ((i - 1024) << 13);\n}\n\nfor (let i = 1; i < 31; ++i) {\n  exponentTable[i] = i << 23;\n}\nexponentTable[31] = 0x47800000;\nexponentTable[32] = 0x80000000;\nfor (let i = 33; i < 63; ++i) {\n  exponentTable[i] = 0x80000000 + ((i - 32) << 23);\n}\nexponentTable[63] = 0xc7800000;\n\nfor (let i = 1; i < 64; ++i) {\n  if (i !== 32) {\n    offsetTable[i] = 1024;\n  }\n}\n\n/**\n * convert a half float number bits to a number\n *\n * @param {number} float16bits - half float number bits\n * @returns {number} double float\n */\nexport function convertToNumber(float16bits) {\n  const m = float16bits >> 10;\n  uint32View[0] = mantissaTable[offsetTable[m] + (float16bits & 0x3ff)] + exponentTable[m];\n  return floatView[0];\n}\n","export const THIS_IS_NOT_AN_OBJECT = \"This is not an object\";\nexport const THIS_IS_NOT_A_FLOAT16ARRAY_OBJECT = \"This is not a Float16Array object\";\nexport const THIS_CONSTRUCTOR_IS_NOT_A_SUBCLASS_OF_FLOAT16ARRAY =\n  \"This constructor is not a subclass of Float16Array\";\nexport const THE_CONSTRUCTOR_PROPERTY_VALUE_IS_NOT_AN_OBJECT =\n  \"The constructor property value is not an object\";\nexport const SPECIES_CONSTRUCTOR_DIDNT_RETURN_TYPEDARRAY_OBJECT =\n  \"Species constructor didn't return TypedArray object\";\nexport const DERIVED_CONSTRUCTOR_CREATED_TYPEDARRAY_OBJECT_WHICH_WAS_TOO_SMALL_LENGTH =\n  \"Derived constructor created TypedArray object which was too small length\";\nexport const ATTEMPTING_TO_ACCESS_DETACHED_ARRAYBUFFER =\n  \"Attempting to access detached ArrayBuffer\";\nexport const CANNOT_CONVERT_UNDEFINED_OR_NULL_TO_OBJECT =\n  \"Cannot convert undefined or null to object\";\nexport const CANNOT_MIX_BIGINT_AND_OTHER_TYPES =\n  \"Cannot mix BigInt and other types, use explicit conversions\";\nexport const ITERATOR_PROPERTY_IS_NOT_CALLABLE = \"@@iterator property is not callable\";\nexport const REDUCE_OF_EMPTY_ARRAY_WITH_NO_INITIAL_VALUE =\n  \"Reduce of empty array with no initial value\";\nexport const THE_COMPARISON_FUNCTION_MUST_BE_EITHER_A_FUNCTION_OR_UNDEFINED =\n  \"The comparison function must be either a function or undefined\";\nexport const OFFSET_IS_OUT_OF_BOUNDS = \"Offset is out of bounds\";\n","/* eslint-disable no-restricted-globals, no-restricted-syntax */\n/* global SharedArrayBuffer */\n\nimport { CANNOT_CONVERT_UNDEFINED_OR_NULL_TO_OBJECT } from \"./messages.mjs\";\n\n/** @type {<T extends (...args: any) => any>(target: T) => (thisArg: ThisType<T>, ...args: any[]) => any} */\nfunction uncurryThis(target) {\n  return (thisArg, ...args) => {\n    return ReflectApply(target, thisArg, args);\n  };\n}\n\n/** @type {(target: any, key: string | symbol) => (thisArg: any, ...args: any[]) => any} */\nfunction uncurryThisGetter(target, key) {\n  return uncurryThis(\n    ReflectGetOwnPropertyDescriptor(\n      target,\n      key\n    ).get\n  );\n}\n\n// Reflect\nexport const {\n  apply: ReflectApply,\n  construct: ReflectConstruct,\n  defineProperty: ReflectDefineProperty,\n  get: ReflectGet,\n  getOwnPropertyDescriptor: ReflectGetOwnPropertyDescriptor,\n  getPrototypeOf: ReflectGetPrototypeOf,\n  has: ReflectHas,\n  ownKeys: ReflectOwnKeys,\n  set: ReflectSet,\n  setPrototypeOf: ReflectSetPrototypeOf,\n} = Reflect;\n\n// Proxy\nexport const NativeProxy = Proxy;\n\n// Number\nexport const {\n  MAX_SAFE_INTEGER,\n  isFinite: NumberIsFinite,\n  isNaN: NumberIsNaN,\n} = Number;\n\n// Symbol\nexport const {\n  iterator: SymbolIterator,\n  species: SymbolSpecies,\n  toStringTag: SymbolToStringTag,\n  for: SymbolFor,\n} = Symbol;\n\n// Object\nexport const NativeObject = Object;\nexport const {\n  create: ObjectCreate,\n  defineProperty: ObjectDefineProperty,\n  freeze: ObjectFreeze,\n  is: ObjectIs,\n} = NativeObject;\nconst ObjectPrototype = NativeObject.prototype;\n/** @type {(object: object, key: PropertyKey) => Function | undefined} */\nexport const ObjectPrototype__lookupGetter__ = /** @type {any} */ (ObjectPrototype).__lookupGetter__\n  ? uncurryThis(/** @type {any} */ (ObjectPrototype).__lookupGetter__)\n  : (object, key) => {\n    if (object == null) {\n      throw NativeTypeError(\n        CANNOT_CONVERT_UNDEFINED_OR_NULL_TO_OBJECT\n      );\n    }\n\n    let target = NativeObject(object);\n    do {\n      const descriptor = ReflectGetOwnPropertyDescriptor(target, key);\n      if (descriptor !== undefined) {\n        if (ObjectHasOwn(descriptor, \"get\")) {\n          return descriptor.get;\n        }\n\n        return;\n      }\n    } while ((target = ReflectGetPrototypeOf(target)) !== null);\n  };\n/** @type {(object: object, key: PropertyKey) => boolean} */\nexport const ObjectHasOwn = /** @type {any} */ (NativeObject).hasOwn ||\n  uncurryThis(ObjectPrototype.hasOwnProperty);\n\n// Array\nconst NativeArray = Array;\nexport const ArrayIsArray = NativeArray.isArray;\nconst ArrayPrototype = NativeArray.prototype;\n/** @type {(array: ArrayLike<unknown>, separator?: string) => string} */\nexport const ArrayPrototypeJoin = uncurryThis(ArrayPrototype.join);\n/** @type {<T>(array: T[], ...items: T[]) => number} */\nexport const ArrayPrototypePush = uncurryThis(ArrayPrototype.push);\n/** @type {(array: ArrayLike<unknown>, ...opts: any[]) => string} */\nexport const ArrayPrototypeToLocaleString = uncurryThis(\n  ArrayPrototype.toLocaleString\n);\nexport const NativeArrayPrototypeSymbolIterator = ArrayPrototype[SymbolIterator];\n/** @type {<T>(array: T[]) => IterableIterator<T>} */\nexport const ArrayPrototypeSymbolIterator = uncurryThis(NativeArrayPrototypeSymbolIterator);\n\n// Math\nexport const MathTrunc = Math.trunc;\n\n// ArrayBuffer\nexport const NativeArrayBuffer = ArrayBuffer;\nexport const ArrayBufferIsView = NativeArrayBuffer.isView;\nconst ArrayBufferPrototype = NativeArrayBuffer.prototype;\n/** @type {(buffer: ArrayBuffer, begin?: number, end?: number) => number} */\nexport const ArrayBufferPrototypeSlice = uncurryThis(ArrayBufferPrototype.slice);\n/** @type {(buffer: ArrayBuffer) => ArrayBuffer} */\nexport const ArrayBufferPrototypeGetByteLength = uncurryThisGetter(ArrayBufferPrototype, \"byteLength\");\n\n// SharedArrayBuffer\nexport const NativeSharedArrayBuffer = typeof SharedArrayBuffer !== \"undefined\" ? SharedArrayBuffer : null;\n/** @type {(buffer: SharedArrayBuffer) => SharedArrayBuffer} */\nexport const SharedArrayBufferPrototypeGetByteLength = NativeSharedArrayBuffer\n  && uncurryThisGetter(NativeSharedArrayBuffer.prototype, \"byteLength\");\n\n// TypedArray\n/** @typedef {Uint8Array|Uint8ClampedArray|Uint16Array|Uint32Array|Int8Array|Int16Array|Int32Array|Float32Array|Float64Array|BigUint64Array|BigInt64Array} TypedArray */\n/** @type {any} */\nexport const TypedArray = ReflectGetPrototypeOf(Uint8Array);\nconst TypedArrayFrom = TypedArray.from;\nexport const TypedArrayPrototype = TypedArray.prototype;\nexport const NativeTypedArrayPrototypeSymbolIterator = TypedArrayPrototype[SymbolIterator];\n/** @type {(typedArray: TypedArray) => IterableIterator<number>} */\nexport const TypedArrayPrototypeKeys = uncurryThis(TypedArrayPrototype.keys);\n/** @type {(typedArray: TypedArray) => IterableIterator<number>} */\nexport const TypedArrayPrototypeValues = uncurryThis(\n  TypedArrayPrototype.values\n);\n/** @type {(typedArray: TypedArray) => IterableIterator<[number, number]>} */\nexport const TypedArrayPrototypeEntries = uncurryThis(\n  TypedArrayPrototype.entries\n);\n/** @type {(typedArray: TypedArray, array: ArrayLike<number>, offset?: number) => void} */\nexport const TypedArrayPrototypeSet = uncurryThis(TypedArrayPrototype.set);\n/** @type {<T extends TypedArray>(typedArray: T) => T} */\nexport const TypedArrayPrototypeReverse = uncurryThis(\n  TypedArrayPrototype.reverse\n);\n/** @type {<T extends TypedArray>(typedArray: T, value: number, start?: number, end?: number) => T} */\nexport const TypedArrayPrototypeFill = uncurryThis(TypedArrayPrototype.fill);\n/** @type {<T extends TypedArray>(typedArray: T, target: number, start: number, end?: number) => T} */\nexport const TypedArrayPrototypeCopyWithin = uncurryThis(\n  TypedArrayPrototype.copyWithin\n);\n/** @type {<T extends TypedArray>(typedArray: T, compareFn?: (a: number, b: number) => number) => T} */\nexport const TypedArrayPrototypeSort = uncurryThis(TypedArrayPrototype.sort);\n/** @type {<T extends TypedArray>(typedArray: T, start?: number, end?: number) => T} */\nexport const TypedArrayPrototypeSlice = uncurryThis(TypedArrayPrototype.slice);\n/** @type {<T extends TypedArray>(typedArray: T, start?: number, end?: number) => T} */\nexport const TypedArrayPrototypeSubarray = uncurryThis(\n  TypedArrayPrototype.subarray\n);\n/** @type {((typedArray: TypedArray) => ArrayBuffer)} */\nexport const TypedArrayPrototypeGetBuffer = uncurryThisGetter(\n  TypedArrayPrototype,\n  \"buffer\"\n);\n/** @type {((typedArray: TypedArray) => number)} */\nexport const TypedArrayPrototypeGetByteOffset = uncurryThisGetter(\n  TypedArrayPrototype,\n  \"byteOffset\"\n);\n/** @type {((typedArray: TypedArray) => number)} */\nexport const TypedArrayPrototypeGetLength = uncurryThisGetter(\n  TypedArrayPrototype,\n  \"length\"\n);\n/** @type {(target: unknown) => string} */\nexport const TypedArrayPrototypeGetSymbolToStringTag = uncurryThisGetter(\n  TypedArrayPrototype,\n  SymbolToStringTag\n);\n\n// Uint16Array\nexport const NativeUint16Array = Uint16Array;\n/** @type {Uint16ArrayConstructor[\"from\"]} */\nexport const Uint16ArrayFrom = (...args) => {\n  return ReflectApply(TypedArrayFrom, NativeUint16Array, args);\n};\n\n// Uint32Array\nexport const NativeUint32Array = Uint32Array;\n\n// Float32Array\nexport const NativeFloat32Array = Float32Array;\n\n// ArrayIterator\n/** @type {any} */\nexport const ArrayIteratorPrototype = ReflectGetPrototypeOf([][SymbolIterator]());\n/** @type {<T>(arrayIterator: IterableIterator<T>) => IteratorResult<T>} */\nexport const ArrayIteratorPrototypeNext = uncurryThis(ArrayIteratorPrototype.next);\n\n// Generator\n/** @type {<T = unknown, TReturn = any, TNext = unknown>(generator: Generator<T, TReturn, TNext>, value?: TNext) => T} */\nexport const GeneratorPrototypeNext = uncurryThis((function* () {})().next);\n\n// Iterator\nexport const IteratorPrototype = ReflectGetPrototypeOf(ArrayIteratorPrototype);\n\n// DataView\nconst DataViewPrototype = DataView.prototype;\n/** @type {(dataView: DataView, byteOffset: number, littleEndian?: boolean) => number} */\nexport const DataViewPrototypeGetUint16 = uncurryThis(\n  DataViewPrototype.getUint16\n);\n/** @type {(dataView: DataView, byteOffset: number, value: number, littleEndian?: boolean) => void} */\nexport const DataViewPrototypeSetUint16 = uncurryThis(\n  DataViewPrototype.setUint16\n);\n\n// Error\nexport const NativeTypeError = TypeError;\nexport const NativeRangeError = RangeError;\n\n// WeakSet\n/**\n * Do not construct with arguments to avoid calling the \"add\" method\n *\n * @type {{new <T extends {}>(): WeakSet<T>}}\n */\nexport const NativeWeakSet = WeakSet;\nconst WeakSetPrototype = NativeWeakSet.prototype;\n/** @type {<T extends {}>(set: WeakSet<T>, value: T) => Set<T>} */\nexport const WeakSetPrototypeAdd = uncurryThis(WeakSetPrototype.add);\n/** @type {<T extends {}>(set: WeakSet<T>, value: T) => boolean} */\nexport const WeakSetPrototypeHas = uncurryThis(WeakSetPrototype.has);\n\n// WeakMap\n/**\n * Do not construct with arguments to avoid calling the \"set\" method\n *\n * @type {{new <K extends {}, V>(): WeakMap<K, V>}}\n */\nexport const NativeWeakMap = WeakMap;\nconst WeakMapPrototype = NativeWeakMap.prototype;\n/** @type {<K extends {}, V>(weakMap: WeakMap<K, V>, key: K) => V} */\nexport const WeakMapPrototypeGet = uncurryThis(WeakMapPrototype.get);\n/** @type {<K extends {}, V>(weakMap: WeakMap<K, V>, key: K) => boolean} */\nexport const WeakMapPrototypeHas = uncurryThis(WeakMapPrototype.has);\n/** @type {<K extends {}, V>(weakMap: WeakMap<K, V>, key: K, value: V) => WeakMap} */\nexport const WeakMapPrototypeSet = uncurryThis(WeakMapPrototype.set);\n","import { applyPredictor } from '../predictor.js';\n\nexport default class BaseDecoder {\n  async decode(fileDirectory, buffer) {\n    const decoded = await this.decodeBlock(buffer);\n    const predictor = fileDirectory.Predictor || 1;\n    if (predictor !== 1) {\n      const isTiled = !fileDirectory.StripOffsets;\n      const tileWidth = isTiled ? fileDirectory.TileWidth : fileDirectory.ImageWidth;\n      const tileHeight = isTiled ? fileDirectory.TileLength : (\n        fileDirectory.RowsPerStrip || fileDirectory.ImageLength\n      );\n      return applyPredictor(\n        decoded, predictor, tileWidth, tileHeight, fileDirectory.BitsPerSample,\n        fileDirectory.PlanarConfiguration,\n      );\n    }\n    return decoded;\n  }\n}\n","const registry = new Map();\n\nexport function addDecoder(cases, importFn) {\n  if (!Array.isArray(cases)) {\n    cases = [cases]; // eslint-disable-line no-param-reassign\n  }\n  cases.forEach((c) => registry.set(c, importFn));\n}\n\nexport async function getDecoder(fileDirectory) {\n  const importFn = registry.get(fileDirectory.Compression);\n  if (!importFn) {\n    throw new Error(`Unknown compression method identifier: ${fileDirectory.Compression}`);\n  }\n  const Decoder = await importFn();\n  return new Decoder(fileDirectory);\n}\n\n// Add default decoders to registry (end-user may override with other implementations)\naddDecoder([undefined, 1], () => import('./raw.js').then((m) => m.default));\naddDecoder(5, () => import('./lzw.js').then((m) => m.default));\naddDecoder(6, () => {\n  throw new Error('old style JPEG compression is not supported.');\n});\naddDecoder(7, () => import('./jpeg.js').then((m) => m.default));\naddDecoder([8, 32946], () => import('./deflate.js').then((m) => m.default));\naddDecoder(32773, () => import('./packbits.js').then((m) => m.default));\naddDecoder(34887, () => import('./lerc.js').then((m) => m.default));\naddDecoder(50001, () => import('./webimage.js').then((m) => m.default));\n","export default class DataSlice {\n  constructor(arrayBuffer, sliceOffset, littleEndian, bigTiff) {\n    this._dataView = new DataView(arrayBuffer);\n    this._sliceOffset = sliceOffset;\n    this._littleEndian = littleEndian;\n    this._bigTiff = bigTiff;\n  }\n\n  get sliceOffset() {\n    return this._sliceOffset;\n  }\n\n  get sliceTop() {\n    return this._sliceOffset + this.buffer.byteLength;\n  }\n\n  get littleEndian() {\n    return this._littleEndian;\n  }\n\n  get bigTiff() {\n    return this._bigTiff;\n  }\n\n  get buffer() {\n    return this._dataView.buffer;\n  }\n\n  covers(offset, length) {\n    return this.sliceOffset <= offset && this.sliceTop >= offset + length;\n  }\n\n  readUint8(offset) {\n    return this._dataView.getUint8(\n      offset - this._sliceOffset, this._littleEndian,\n    );\n  }\n\n  readInt8(offset) {\n    return this._dataView.getInt8(\n      offset - this._sliceOffset, this._littleEndian,\n    );\n  }\n\n  readUint16(offset) {\n    return this._dataView.getUint16(\n      offset - this._sliceOffset, this._littleEndian,\n    );\n  }\n\n  readInt16(offset) {\n    return this._dataView.getInt16(\n      offset - this._sliceOffset, this._littleEndian,\n    );\n  }\n\n  readUint32(offset) {\n    return this._dataView.getUint32(\n      offset - this._sliceOffset, this._littleEndian,\n    );\n  }\n\n  readInt32(offset) {\n    return this._dataView.getInt32(\n      offset - this._sliceOffset, this._littleEndian,\n    );\n  }\n\n  readFloat32(offset) {\n    return this._dataView.getFloat32(\n      offset - this._sliceOffset, this._littleEndian,\n    );\n  }\n\n  readFloat64(offset) {\n    return this._dataView.getFloat64(\n      offset - this._sliceOffset, this._littleEndian,\n    );\n  }\n\n  readUint64(offset) {\n    const left = this.readUint32(offset);\n    const right = this.readUint32(offset + 4);\n    let combined;\n    if (this._littleEndian) {\n      combined = left + ((2 ** 32) * right);\n      if (!Number.isSafeInteger(combined)) {\n        throw new Error(\n          `${combined} exceeds MAX_SAFE_INTEGER. `\n          + 'Precision may be lost. Please report if you get this message to https://github.com/geotiffjs/geotiff.js/issues',\n        );\n      }\n      return combined;\n    }\n    combined = ((2 ** 32) * left) + right;\n    if (!Number.isSafeInteger(combined)) {\n      throw new Error(\n        `${combined} exceeds MAX_SAFE_INTEGER. `\n        + 'Precision may be lost. Please report if you get this message to https://github.com/geotiffjs/geotiff.js/issues',\n      );\n    }\n\n    return combined;\n  }\n\n  // adapted from https://stackoverflow.com/a/55338384/8060591\n  readInt64(offset) {\n    let value = 0;\n    const isNegative = (this._dataView.getUint8(offset + (this._littleEndian ? 7 : 0)) & 0x80)\n      > 0;\n    let carrying = true;\n    for (let i = 0; i < 8; i++) {\n      let byte = this._dataView.getUint8(\n        offset + (this._littleEndian ? i : 7 - i),\n      );\n      if (isNegative) {\n        if (carrying) {\n          if (byte !== 0x00) {\n            byte = ~(byte - 1) & 0xff;\n            carrying = false;\n          }\n        } else {\n          byte = ~byte & 0xff;\n        }\n      }\n      value += byte * (256 ** i);\n    }\n    if (isNegative) {\n      value = -value;\n    }\n    return value;\n  }\n\n  readOffset(offset) {\n    if (this._bigTiff) {\n      return this.readUint64(offset);\n    }\n    return this.readUint32(offset);\n  }\n}\n","import { getFloat16 } from '@petamoriken/float16';\n\nexport default class DataView64 {\n  constructor(arrayBuffer) {\n    this._dataView = new DataView(arrayBuffer);\n  }\n\n  get buffer() {\n    return this._dataView.buffer;\n  }\n\n  getUint64(offset, littleEndian) {\n    const left = this.getUint32(offset, littleEndian);\n    const right = this.getUint32(offset + 4, littleEndian);\n    let combined;\n    if (littleEndian) {\n      combined = left + ((2 ** 32) * right);\n      if (!Number.isSafeInteger(combined)) {\n        throw new Error(\n          `${combined} exceeds MAX_SAFE_INTEGER. `\n          + 'Precision may be lost. Please report if you get this message to https://github.com/geotiffjs/geotiff.js/issues',\n        );\n      }\n      return combined;\n    }\n    combined = ((2 ** 32) * left) + right;\n    if (!Number.isSafeInteger(combined)) {\n      throw new Error(\n        `${combined} exceeds MAX_SAFE_INTEGER. `\n        + 'Precision may be lost. Please report if you get this message to https://github.com/geotiffjs/geotiff.js/issues',\n      );\n    }\n\n    return combined;\n  }\n\n  // adapted from https://stackoverflow.com/a/55338384/8060591\n  getInt64(offset, littleEndian) {\n    let value = 0;\n    const isNegative = (this._dataView.getUint8(offset + (littleEndian ? 7 : 0)) & 0x80) > 0;\n    let carrying = true;\n    for (let i = 0; i < 8; i++) {\n      let byte = this._dataView.getUint8(offset + (littleEndian ? i : 7 - i));\n      if (isNegative) {\n        if (carrying) {\n          if (byte !== 0x00) {\n            byte = ~(byte - 1) & 0xff;\n            carrying = false;\n          }\n        } else {\n          byte = ~byte & 0xff;\n        }\n      }\n      value += byte * (256 ** i);\n    }\n    if (isNegative) {\n      value = -value;\n    }\n    return value;\n  }\n\n  getUint8(offset, littleEndian) {\n    return this._dataView.getUint8(offset, littleEndian);\n  }\n\n  getInt8(offset, littleEndian) {\n    return this._dataView.getInt8(offset, littleEndian);\n  }\n\n  getUint16(offset, littleEndian) {\n    return this._dataView.getUint16(offset, littleEndian);\n  }\n\n  getInt16(offset, littleEndian) {\n    return this._dataView.getInt16(offset, littleEndian);\n  }\n\n  getUint32(offset, littleEndian) {\n    return this._dataView.getUint32(offset, littleEndian);\n  }\n\n  getInt32(offset, littleEndian) {\n    return this._dataView.getInt32(offset, littleEndian);\n  }\n\n  getFloat16(offset, littleEndian) {\n    return getFloat16(this._dataView, offset, littleEndian);\n  }\n\n  getFloat32(offset, littleEndian) {\n    return this._dataView.getFloat32(offset, littleEndian);\n  }\n\n  getFloat64(offset, littleEndian) {\n    return this._dataView.getFloat64(offset, littleEndian);\n  }\n}\n","/** @module geotiff */\nimport GeoTIFFImage from './geotiffimage.js';\nimport DataView64 from './dataview64.js';\nimport DataSlice from './dataslice.js';\nimport Pool from './pool.js';\n\nimport { makeRemoteSource } from './source/remote.js';\nimport { makeBufferSource } from './source/arraybuffer.js';\nimport { makeFileReaderSource } from './source/filereader.js';\nimport { makeFileSource } from './source/file.js';\n\nimport { fieldTypes, fieldTagNames, arrayFields, geoKeyNames } from './globals.js';\nimport { writeGeotiff } from './geotiffwriter.js';\nimport * as globals from './globals.js';\nimport * as rgb from './rgb.js';\nimport { getDecoder, addDecoder } from './compression/index.js';\nimport { setLogger } from './logging.js';\n\nexport { globals };\nexport { rgb };\nexport { default as BaseDecoder } from './compression/basedecoder.js';\nexport { getDecoder, addDecoder };\nexport { setLogger };\n\n/**\n * @typedef {Uint8Array | Int8Array | Uint16Array | Int16Array | Uint32Array | Int32Array | Float32Array | Float64Array}\n * TypedArray\n */\n\n/**\n * @typedef {{ height:number, width: number }} Dimensions\n */\n\n/**\n * The autogenerated docs are a little confusing here. The effective type is:\n *\n * `TypedArray & { height: number; width: number}`\n * @typedef {TypedArray & Dimensions} TypedArrayWithDimensions\n */\n\n/**\n * The autogenerated docs are a little confusing here. The effective type is:\n *\n * `TypedArray[] & { height: number; width: number}`\n * @typedef {TypedArray[] & Dimensions} TypedArrayArrayWithDimensions\n */\n\n/**\n *  The autogenerated docs are a little confusing here. The effective type is:\n *\n * `(TypedArray | TypedArray[]) & { height: number; width: number}`\n * @typedef {TypedArrayWithDimensions | TypedArrayArrayWithDimensions} ReadRasterResult\n */\n\nfunction getFieldTypeLength(fieldType) {\n  switch (fieldType) {\n    case fieldTypes.BYTE: case fieldTypes.ASCII: case fieldTypes.SBYTE: case fieldTypes.UNDEFINED:\n      return 1;\n    case fieldTypes.SHORT: case fieldTypes.SSHORT:\n      return 2;\n    case fieldTypes.LONG: case fieldTypes.SLONG: case fieldTypes.FLOAT: case fieldTypes.IFD:\n      return 4;\n    case fieldTypes.RATIONAL: case fieldTypes.SRATIONAL: case fieldTypes.DOUBLE:\n    case fieldTypes.LONG8: case fieldTypes.SLONG8: case fieldTypes.IFD8:\n      return 8;\n    default:\n      throw new RangeError(`Invalid field type: ${fieldType}`);\n  }\n}\n\nfunction parseGeoKeyDirectory(fileDirectory) {\n  const rawGeoKeyDirectory = fileDirectory.GeoKeyDirectory;\n  if (!rawGeoKeyDirectory) {\n    return null;\n  }\n\n  const geoKeyDirectory = {};\n  for (let i = 4; i <= rawGeoKeyDirectory[3] * 4; i += 4) {\n    const key = geoKeyNames[rawGeoKeyDirectory[i]];\n    const location = (rawGeoKeyDirectory[i + 1])\n      ? (fieldTagNames[rawGeoKeyDirectory[i + 1]]) : null;\n    const count = rawGeoKeyDirectory[i + 2];\n    const offset = rawGeoKeyDirectory[i + 3];\n\n    let value = null;\n    if (!location) {\n      value = offset;\n    } else {\n      value = fileDirectory[location];\n      if (typeof value === 'undefined' || value === null) {\n        throw new Error(`Could not get value of geoKey '${key}'.`);\n      } else if (typeof value === 'string') {\n        value = value.substring(offset, offset + count - 1);\n      } else if (value.subarray) {\n        value = value.subarray(offset, offset + count);\n        if (count === 1) {\n          value = value[0];\n        }\n      }\n    }\n    geoKeyDirectory[key] = value;\n  }\n  return geoKeyDirectory;\n}\n\nfunction getValues(dataSlice, fieldType, count, offset) {\n  let values = null;\n  let readMethod = null;\n  const fieldTypeLength = getFieldTypeLength(fieldType);\n\n  switch (fieldType) {\n    case fieldTypes.BYTE: case fieldTypes.ASCII: case fieldTypes.UNDEFINED:\n      values = new Uint8Array(count); readMethod = dataSlice.readUint8;\n      break;\n    case fieldTypes.SBYTE:\n      values = new Int8Array(count); readMethod = dataSlice.readInt8;\n      break;\n    case fieldTypes.SHORT:\n      values = new Uint16Array(count); readMethod = dataSlice.readUint16;\n      break;\n    case fieldTypes.SSHORT:\n      values = new Int16Array(count); readMethod = dataSlice.readInt16;\n      break;\n    case fieldTypes.LONG: case fieldTypes.IFD:\n      values = new Uint32Array(count); readMethod = dataSlice.readUint32;\n      break;\n    case fieldTypes.SLONG:\n      values = new Int32Array(count); readMethod = dataSlice.readInt32;\n      break;\n    case fieldTypes.LONG8: case fieldTypes.IFD8:\n      values = new Array(count); readMethod = dataSlice.readUint64;\n      break;\n    case fieldTypes.SLONG8:\n      values = new Array(count); readMethod = dataSlice.readInt64;\n      break;\n    case fieldTypes.RATIONAL:\n      values = new Uint32Array(count * 2); readMethod = dataSlice.readUint32;\n      break;\n    case fieldTypes.SRATIONAL:\n      values = new Int32Array(count * 2); readMethod = dataSlice.readInt32;\n      break;\n    case fieldTypes.FLOAT:\n      values = new Float32Array(count); readMethod = dataSlice.readFloat32;\n      break;\n    case fieldTypes.DOUBLE:\n      values = new Float64Array(count); readMethod = dataSlice.readFloat64;\n      break;\n    default:\n      throw new RangeError(`Invalid field type: ${fieldType}`);\n  }\n\n  // normal fields\n  if (!(fieldType === fieldTypes.RATIONAL || fieldType === fieldTypes.SRATIONAL)) {\n    for (let i = 0; i < count; ++i) {\n      values[i] = readMethod.call(\n        dataSlice, offset + (i * fieldTypeLength),\n      );\n    }\n  } else { // RATIONAL or SRATIONAL\n    for (let i = 0; i < count; i += 2) {\n      values[i] = readMethod.call(\n        dataSlice, offset + (i * fieldTypeLength),\n      );\n      values[i + 1] = readMethod.call(\n        dataSlice, offset + ((i * fieldTypeLength) + 4),\n      );\n    }\n  }\n\n  if (fieldType === fieldTypes.ASCII) {\n    return new TextDecoder('utf-8').decode(values);\n  }\n  return values;\n}\n\n/**\n * Data class to store the parsed file directory, geo key directory and\n * offset to the next IFD\n */\nclass ImageFileDirectory {\n  constructor(fileDirectory, geoKeyDirectory, nextIFDByteOffset) {\n    this.fileDirectory = fileDirectory;\n    this.geoKeyDirectory = geoKeyDirectory;\n    this.nextIFDByteOffset = nextIFDByteOffset;\n  }\n}\n\n/**\n * Error class for cases when an IFD index was requested, that does not exist\n * in the file.\n */\nclass GeoTIFFImageIndexError extends Error {\n  constructor(index) {\n    super(`No image at index ${index}`);\n    this.index = index;\n  }\n}\n\nclass GeoTIFFBase {\n  /**\n   * (experimental) Reads raster data from the best fitting image. This function uses\n   * the image with the lowest resolution that is still a higher resolution than the\n   * requested resolution.\n   * When specified, the `bbox` option is translated to the `window` option and the\n   * `resX` and `resY` to `width` and `height` respectively.\n   * Then, the [readRasters]{@link GeoTIFFImage#readRasters} method of the selected\n   * image is called and the result returned.\n   * @see GeoTIFFImage.readRasters\n   * @param {import('./geotiffimage').ReadRasterOptions} [options={}] optional parameters\n   * @returns {Promise<ReadRasterResult>} the decoded array(s), with `height` and `width`, as a promise\n   */\n  async readRasters(options = {}) {\n    const { window: imageWindow, width, height } = options;\n    let { resX, resY, bbox } = options;\n\n    const firstImage = await this.getImage();\n    let usedImage = firstImage;\n    const imageCount = await this.getImageCount();\n    const imgBBox = firstImage.getBoundingBox();\n\n    if (imageWindow && bbox) {\n      throw new Error('Both \"bbox\" and \"window\" passed.');\n    }\n\n    // if width/height is passed, transform it to resolution\n    if (width || height) {\n      // if we have an image window (pixel coordinates), transform it to a BBox\n      // using the origin/resolution of the first image.\n      if (imageWindow) {\n        const [oX, oY] = firstImage.getOrigin();\n        const [rX, rY] = firstImage.getResolution();\n\n        bbox = [\n          oX + (imageWindow[0] * rX),\n          oY + (imageWindow[1] * rY),\n          oX + (imageWindow[2] * rX),\n          oY + (imageWindow[3] * rY),\n        ];\n      }\n\n      // if we have a bbox (or calculated one)\n\n      const usedBBox = bbox || imgBBox;\n\n      if (width) {\n        if (resX) {\n          throw new Error('Both width and resX passed');\n        }\n        resX = (usedBBox[2] - usedBBox[0]) / width;\n      }\n      if (height) {\n        if (resY) {\n          throw new Error('Both width and resY passed');\n        }\n        resY = (usedBBox[3] - usedBBox[1]) / height;\n      }\n    }\n\n    // if resolution is set or calculated, try to get the image with the worst acceptable resolution\n    if (resX || resY) {\n      const allImages = [];\n      for (let i = 0; i < imageCount; ++i) {\n        const image = await this.getImage(i);\n        const { SubfileType: subfileType, NewSubfileType: newSubfileType } = image.fileDirectory;\n        if (i === 0 || subfileType === 2 || newSubfileType & 1) {\n          allImages.push(image);\n        }\n      }\n\n      allImages.sort((a, b) => a.getWidth() - b.getWidth());\n      for (let i = 0; i < allImages.length; ++i) {\n        const image = allImages[i];\n        const imgResX = (imgBBox[2] - imgBBox[0]) / image.getWidth();\n        const imgResY = (imgBBox[3] - imgBBox[1]) / image.getHeight();\n\n        usedImage = image;\n        if ((resX && resX > imgResX) || (resY && resY > imgResY)) {\n          break;\n        }\n      }\n    }\n\n    let wnd = imageWindow;\n    if (bbox) {\n      const [oX, oY] = firstImage.getOrigin();\n      const [imageResX, imageResY] = usedImage.getResolution(firstImage);\n\n      wnd = [\n        Math.round((bbox[0] - oX) / imageResX),\n        Math.round((bbox[1] - oY) / imageResY),\n        Math.round((bbox[2] - oX) / imageResX),\n        Math.round((bbox[3] - oY) / imageResY),\n      ];\n      wnd = [\n        Math.min(wnd[0], wnd[2]),\n        Math.min(wnd[1], wnd[3]),\n        Math.max(wnd[0], wnd[2]),\n        Math.max(wnd[1], wnd[3]),\n      ];\n    }\n\n    return usedImage.readRasters({ ...options, window: wnd });\n  }\n}\n\n/**\n * @typedef {Object} GeoTIFFOptions\n * @property {boolean} [cache=false] whether or not decoded tiles shall be cached.\n */\n\n/**\n * The abstraction for a whole GeoTIFF file.\n * @augments GeoTIFFBase\n */\nclass GeoTIFF extends GeoTIFFBase {\n  /**\n   * @constructor\n   * @param {*} source The datasource to read from.\n   * @param {boolean} littleEndian Whether the image uses little endian.\n   * @param {boolean} bigTiff Whether the image uses bigTIFF conventions.\n   * @param {number} firstIFDOffset The numeric byte-offset from the start of the image\n   *                                to the first IFD.\n   * @param {GeoTIFFOptions} [options] further options.\n   */\n  constructor(source, littleEndian, bigTiff, firstIFDOffset, options = {}) {\n    super();\n    this.source = source;\n    this.littleEndian = littleEndian;\n    this.bigTiff = bigTiff;\n    this.firstIFDOffset = firstIFDOffset;\n    this.cache = options.cache || false;\n    this.ifdRequests = [];\n    this.ghostValues = null;\n  }\n\n  async getSlice(offset, size) {\n    const fallbackSize = this.bigTiff ? 4048 : 1024;\n    return new DataSlice(\n      (await this.source.fetch([{\n        offset,\n        length: typeof size !== 'undefined' ? size : fallbackSize,\n      }]))[0],\n      offset,\n      this.littleEndian,\n      this.bigTiff,\n    );\n  }\n\n  /**\n   * Instructs to parse an image file directory at the given file offset.\n   * As there is no way to ensure that a location is indeed the start of an IFD,\n   * this function must be called with caution (e.g only using the IFD offsets from\n   * the headers or other IFDs).\n   * @param {number} offset the offset to parse the IFD at\n   * @returns {Promise<ImageFileDirectory>} the parsed IFD\n   */\n  async parseFileDirectoryAt(offset) {\n    const entrySize = this.bigTiff ? 20 : 12;\n    const offsetSize = this.bigTiff ? 8 : 2;\n\n    let dataSlice = await this.getSlice(offset);\n    const numDirEntries = this.bigTiff\n      ? dataSlice.readUint64(offset)\n      : dataSlice.readUint16(offset);\n\n    // if the slice does not cover the whole IFD, request a bigger slice, where the\n    // whole IFD fits: num of entries + n x tag length + offset to next IFD\n    const byteSize = (numDirEntries * entrySize) + (this.bigTiff ? 16 : 6);\n    if (!dataSlice.covers(offset, byteSize)) {\n      dataSlice = await this.getSlice(offset, byteSize);\n    }\n\n    const fileDirectory = {};\n\n    // loop over the IFD and create a file directory object\n    let i = offset + (this.bigTiff ? 8 : 2);\n    for (let entryCount = 0; entryCount < numDirEntries; i += entrySize, ++entryCount) {\n      const fieldTag = dataSlice.readUint16(i);\n      const fieldType = dataSlice.readUint16(i + 2);\n      const typeCount = this.bigTiff\n        ? dataSlice.readUint64(i + 4)\n        : dataSlice.readUint32(i + 4);\n\n      let fieldValues;\n      let value;\n      const fieldTypeLength = getFieldTypeLength(fieldType);\n      const valueOffset = i + (this.bigTiff ? 12 : 8);\n\n      // check whether the value is directly encoded in the tag or refers to a\n      // different external byte range\n      if (fieldTypeLength * typeCount <= (this.bigTiff ? 8 : 4)) {\n        fieldValues = getValues(dataSlice, fieldType, typeCount, valueOffset);\n      } else {\n        // resolve the reference to the actual byte range\n        const actualOffset = dataSlice.readOffset(valueOffset);\n        const length = getFieldTypeLength(fieldType) * typeCount;\n\n        // check, whether we actually cover the referenced byte range; if not,\n        // request a new slice of bytes to read from it\n        if (dataSlice.covers(actualOffset, length)) {\n          fieldValues = getValues(dataSlice, fieldType, typeCount, actualOffset);\n        } else {\n          const fieldDataSlice = await this.getSlice(actualOffset, length);\n          fieldValues = getValues(fieldDataSlice, fieldType, typeCount, actualOffset);\n        }\n      }\n\n      // unpack single values from the array\n      if (typeCount === 1 && arrayFields.indexOf(fieldTag) === -1\n        && !(fieldType === fieldTypes.RATIONAL || fieldType === fieldTypes.SRATIONAL)) {\n        value = fieldValues[0];\n      } else {\n        value = fieldValues;\n      }\n\n      // write the tags value to the file directly\n      fileDirectory[fieldTagNames[fieldTag]] = value;\n    }\n    const geoKeyDirectory = parseGeoKeyDirectory(fileDirectory);\n    const nextIFDByteOffset = dataSlice.readOffset(\n      offset + offsetSize + (entrySize * numDirEntries),\n    );\n\n    return new ImageFileDirectory(\n      fileDirectory,\n      geoKeyDirectory,\n      nextIFDByteOffset,\n    );\n  }\n\n  async requestIFD(index) {\n    // see if we already have that IFD index requested.\n    if (this.ifdRequests[index]) {\n      // attach to an already requested IFD\n      return this.ifdRequests[index];\n    } else if (index === 0) {\n      // special case for index 0\n      this.ifdRequests[index] = this.parseFileDirectoryAt(this.firstIFDOffset);\n      return this.ifdRequests[index];\n    } else if (!this.ifdRequests[index - 1]) {\n      // if the previous IFD was not yet loaded, load that one first\n      // this is the recursive call.\n      try {\n        this.ifdRequests[index - 1] = this.requestIFD(index - 1);\n      } catch (e) {\n        // if the previous one already was an index error, rethrow\n        // with the current index\n        if (e instanceof GeoTIFFImageIndexError) {\n          throw new GeoTIFFImageIndexError(index);\n        }\n        // rethrow anything else\n        throw e;\n      }\n    }\n    // if the previous IFD was loaded, we can finally fetch the one we are interested in.\n    // we need to wrap this in an IIFE, otherwise this.ifdRequests[index] would be delayed\n    this.ifdRequests[index] = (async () => {\n      const previousIfd = await this.ifdRequests[index - 1];\n      if (previousIfd.nextIFDByteOffset === 0) {\n        throw new GeoTIFFImageIndexError(index);\n      }\n      return this.parseFileDirectoryAt(previousIfd.nextIFDByteOffset);\n    })();\n    return this.ifdRequests[index];\n  }\n\n  /**\n   * Get the n-th internal subfile of an image. By default, the first is returned.\n   *\n   * @param {number} [index=0] the index of the image to return.\n   * @returns {Promise<GeoTIFFImage>} the image at the given index\n   */\n  async getImage(index = 0) {\n    const ifd = await this.requestIFD(index);\n    return new GeoTIFFImage(\n      ifd.fileDirectory, ifd.geoKeyDirectory,\n      this.dataView, this.littleEndian, this.cache, this.source,\n    );\n  }\n\n  /**\n   * Returns the count of the internal subfiles.\n   *\n   * @returns {Promise<number>} the number of internal subfile images\n   */\n  async getImageCount() {\n    let index = 0;\n    // loop until we run out of IFDs\n    let hasNext = true;\n    while (hasNext) {\n      try {\n        await this.requestIFD(index);\n        ++index;\n      } catch (e) {\n        if (e instanceof GeoTIFFImageIndexError) {\n          hasNext = false;\n        } else {\n          throw e;\n        }\n      }\n    }\n    return index;\n  }\n\n  /**\n   * Get the values of the COG ghost area as a parsed map.\n   * See https://gdal.org/drivers/raster/cog.html#header-ghost-area for reference\n   * @returns {Promise<Object>} the parsed ghost area or null, if no such area was found\n   */\n  async getGhostValues() {\n    const offset = this.bigTiff ? 16 : 8;\n    if (this.ghostValues) {\n      return this.ghostValues;\n    }\n    const detectionString = 'GDAL_STRUCTURAL_METADATA_SIZE=';\n    const heuristicAreaSize = detectionString.length + 100;\n    let slice = await this.getSlice(offset, heuristicAreaSize);\n    if (detectionString === getValues(slice, fieldTypes.ASCII, detectionString.length, offset)) {\n      const valuesString = getValues(slice, fieldTypes.ASCII, heuristicAreaSize, offset);\n      const firstLine = valuesString.split('\\n')[0];\n      const metadataSize = Number(firstLine.split('=')[1].split(' ')[0]) + firstLine.length;\n      if (metadataSize > heuristicAreaSize) {\n        slice = await this.getSlice(offset, metadataSize);\n      }\n      const fullString = getValues(slice, fieldTypes.ASCII, metadataSize, offset);\n      this.ghostValues = {};\n      fullString\n        .split('\\n')\n        .filter((line) => line.length > 0)\n        .map((line) => line.split('='))\n        .forEach(([key, value]) => {\n          this.ghostValues[key] = value;\n        });\n    }\n    return this.ghostValues;\n  }\n\n  /**\n   * Parse a (Geo)TIFF file from the given source.\n   *\n   * @param {*} source The source of data to parse from.\n   * @param {GeoTIFFOptions} [options] Additional options.\n   * @param {AbortSignal} [signal] An AbortSignal that may be signalled if the request is\n   *                               to be aborted\n   */\n  static async fromSource(source, options, signal) {\n    const headerData = (await source.fetch([{ offset: 0, length: 1024 }], signal))[0];\n    const dataView = new DataView64(headerData);\n\n    const BOM = dataView.getUint16(0, 0);\n    let littleEndian;\n    if (BOM === 0x4949) {\n      littleEndian = true;\n    } else if (BOM === 0x4D4D) {\n      littleEndian = false;\n    } else {\n      throw new TypeError('Invalid byte order value.');\n    }\n\n    const magicNumber = dataView.getUint16(2, littleEndian);\n    let bigTiff;\n    if (magicNumber === 42) {\n      bigTiff = false;\n    } else if (magicNumber === 43) {\n      bigTiff = true;\n      const offsetByteSize = dataView.getUint16(4, littleEndian);\n      if (offsetByteSize !== 8) {\n        throw new Error('Unsupported offset byte-size.');\n      }\n    } else {\n      throw new TypeError('Invalid magic number.');\n    }\n\n    const firstIFDOffset = bigTiff\n      ? dataView.getUint64(8, littleEndian)\n      : dataView.getUint32(4, littleEndian);\n    return new GeoTIFF(source, littleEndian, bigTiff, firstIFDOffset, options);\n  }\n\n  /**\n   * Closes the underlying file buffer\n   * N.B. After the GeoTIFF has been completely processed it needs\n   * to be closed but only if it has been constructed from a file.\n   */\n  close() {\n    if (typeof this.source.close === 'function') {\n      return this.source.close();\n    }\n    return false;\n  }\n}\n\nexport { GeoTIFF };\nexport default GeoTIFF;\n\n/**\n * Wrapper for GeoTIFF files that have external overviews.\n * @augments GeoTIFFBase\n */\nclass MultiGeoTIFF extends GeoTIFFBase {\n  /**\n   * Construct a new MultiGeoTIFF from a main and several overview files.\n   * @param {GeoTIFF} mainFile The main GeoTIFF file.\n   * @param {GeoTIFF[]} overviewFiles An array of overview files.\n   */\n  constructor(mainFile, overviewFiles) {\n    super();\n    this.mainFile = mainFile;\n    this.overviewFiles = overviewFiles;\n    this.imageFiles = [mainFile].concat(overviewFiles);\n\n    this.fileDirectoriesPerFile = null;\n    this.fileDirectoriesPerFileParsing = null;\n    this.imageCount = null;\n  }\n\n  async parseFileDirectoriesPerFile() {\n    const requests = [this.mainFile.parseFileDirectoryAt(this.mainFile.firstIFDOffset)]\n      .concat(this.overviewFiles.map((file) => file.parseFileDirectoryAt(file.firstIFDOffset)));\n\n    this.fileDirectoriesPerFile = await Promise.all(requests);\n    return this.fileDirectoriesPerFile;\n  }\n\n  /**\n   * Get the n-th internal subfile of an image. By default, the first is returned.\n   *\n   * @param {number} [index=0] the index of the image to return.\n   * @returns {Promise<GeoTIFFImage>} the image at the given index\n   */\n  async getImage(index = 0) {\n    await this.getImageCount();\n    await this.parseFileDirectoriesPerFile();\n    let visited = 0;\n    let relativeIndex = 0;\n    for (let i = 0; i < this.imageFiles.length; i++) {\n      const imageFile = this.imageFiles[i];\n      for (let ii = 0; ii < this.imageCounts[i]; ii++) {\n        if (index === visited) {\n          const ifd = await imageFile.requestIFD(relativeIndex);\n          return new GeoTIFFImage(\n            ifd.fileDirectory, ifd.geoKeyDirectory,\n            imageFile.dataView, imageFile.littleEndian, imageFile.cache, imageFile.source,\n          );\n        }\n        visited++;\n        relativeIndex++;\n      }\n      relativeIndex = 0;\n    }\n\n    throw new RangeError('Invalid image index');\n  }\n\n  /**\n   * Returns the count of the internal subfiles.\n   *\n   * @returns {Promise<number>} the number of internal subfile images\n   */\n  async getImageCount() {\n    if (this.imageCount !== null) {\n      return this.imageCount;\n    }\n    const requests = [this.mainFile.getImageCount()]\n      .concat(this.overviewFiles.map((file) => file.getImageCount()));\n    this.imageCounts = await Promise.all(requests);\n    this.imageCount = this.imageCounts.reduce((count, ifds) => count + ifds, 0);\n    return this.imageCount;\n  }\n}\n\nexport { MultiGeoTIFF };\n\n/**\n * Creates a new GeoTIFF from a remote URL.\n * @param {string} url The URL to access the image from\n * @param {object} [options] Additional options to pass to the source.\n *                           See {@link makeRemoteSource} for details.\n * @param {AbortSignal} [signal] An AbortSignal that may be signalled if the request is\n *                               to be aborted\n * @returns {Promise<GeoTIFF>} The resulting GeoTIFF file.\n */\nexport async function fromUrl(url, options = {}, signal) {\n  return GeoTIFF.fromSource(makeRemoteSource(url, options), signal);\n}\n\n/**\n * Construct a new GeoTIFF from an\n * [ArrayBuffer]{@link https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/ArrayBuffer}.\n * @param {ArrayBuffer} arrayBuffer The data to read the file from.\n * @param {AbortSignal} [signal] An AbortSignal that may be signalled if the request is\n *                               to be aborted\n * @returns {Promise<GeoTIFF>} The resulting GeoTIFF file.\n */\nexport async function fromArrayBuffer(arrayBuffer, signal) {\n  return GeoTIFF.fromSource(makeBufferSource(arrayBuffer), signal);\n}\n\n/**\n * Construct a GeoTIFF from a local file path. This uses the node\n * [filesystem API]{@link https://nodejs.org/api/fs.html} and is\n * not available on browsers.\n *\n * N.B. After the GeoTIFF has been completely processed it needs\n * to be closed but only if it has been constructed from a file.\n * @param {string} path The file path to read from.\n * @param {AbortSignal} [signal] An AbortSignal that may be signalled if the request is\n *                               to be aborted\n * @returns {Promise<GeoTIFF>} The resulting GeoTIFF file.\n */\nexport async function fromFile(path, signal) {\n  return GeoTIFF.fromSource(makeFileSource(path), signal);\n}\n\n/**\n * Construct a GeoTIFF from an HTML\n * [Blob]{@link https://developer.mozilla.org/en-US/docs/Web/API/Blob} or\n * [File]{@link https://developer.mozilla.org/en-US/docs/Web/API/File}\n * object.\n * @param {Blob|File} blob The Blob or File object to read from.\n * @param {AbortSignal} [signal] An AbortSignal that may be signalled if the request is\n *                               to be aborted\n * @returns {Promise<GeoTIFF>} The resulting GeoTIFF file.\n */\nexport async function fromBlob(blob, signal) {\n  return GeoTIFF.fromSource(makeFileReaderSource(blob), signal);\n}\n\n/**\n * Construct a MultiGeoTIFF from the given URLs.\n * @param {string} mainUrl The URL for the main file.\n * @param {string[]} overviewUrls An array of URLs for the overview images.\n * @param {Object} [options] Additional options to pass to the source.\n *                           See [makeRemoteSource]{@link module:source.makeRemoteSource}\n *                           for details.\n * @param {AbortSignal} [signal] An AbortSignal that may be signalled if the request is\n *                               to be aborted\n * @returns {Promise<MultiGeoTIFF>} The resulting MultiGeoTIFF file.\n */\nexport async function fromUrls(mainUrl, overviewUrls = [], options = {}, signal) {\n  const mainFile = await GeoTIFF.fromSource(makeRemoteSource(mainUrl, options), signal);\n  const overviewFiles = await Promise.all(\n    overviewUrls.map((url) => GeoTIFF.fromSource(makeRemoteSource(url, options))),\n  );\n\n  return new MultiGeoTIFF(mainFile, overviewFiles);\n}\n\n/**\n * Main creating function for GeoTIFF files.\n * @param {(Array)} array of pixel values\n * @returns {metadata} metadata\n */\nexport function writeArrayBuffer(values, metadata) {\n  return writeGeotiff(values, metadata);\n}\n\nexport { Pool };\nexport { GeoTIFFImage };\n","/** @module geotiffimage */\nimport { getFloat16 } from '@petamoriken/float16';\nimport getAttribute from 'xml-utils/get-attribute.js';\nimport findTagsByName from 'xml-utils/find-tags-by-name.js';\n\nimport { photometricInterpretations, ExtraSamplesValues } from './globals.js';\nimport { fromWhiteIsZero, fromBlackIsZero, fromPalette, fromCMYK, fromYCbCr, fromCIELab } from './rgb.js';\nimport { getDecoder } from './compression/index.js';\nimport { resample, resampleInterleaved } from './resample.js';\n\n/**\n * @typedef {Object} ReadRasterOptions\n * @property {Array<number>} [window=whole window] the subset to read data from in pixels.\n * @property {Array<number>} [bbox=whole image] the subset to read data from in\n *                                           geographical coordinates.\n * @property {Array<number>} [samples=all samples] the selection of samples to read from. Default is all samples.\n * @property {boolean} [interleave=false] whether the data shall be read\n *                                             in one single array or separate\n *                                             arrays.\n * @property {Pool} [pool=null] The optional decoder pool to use.\n * @property {number} [width] The desired width of the output. When the width is not the\n *                                 same as the images, resampling will be performed.\n * @property {number} [height] The desired height of the output. When the width is not the\n *                                  same as the images, resampling will be performed.\n * @property {string} [resampleMethod='nearest'] The desired resampling method.\n * @property {AbortSignal} [signal] An AbortSignal that may be signalled if the request is\n *                                       to be aborted\n * @property {number|number[]} [fillValue] The value to use for parts of the image\n *                                              outside of the images extent. When multiple\n *                                              samples are requested, an array of fill values\n *                                              can be passed.\n */\n\n/** @typedef {import(\"./geotiff.js\").TypedArray} TypedArray */\n/** @typedef {import(\"./geotiff.js\").ReadRasterResult} ReadRasterResult */\n\nfunction sum(array, start, end) {\n  let s = 0;\n  for (let i = start; i < end; ++i) {\n    s += array[i];\n  }\n  return s;\n}\n\nfunction arrayForType(format, bitsPerSample, size) {\n  switch (format) {\n    case 1: // unsigned integer data\n      if (bitsPerSample <= 8) {\n        return new Uint8Array(size);\n      } else if (bitsPerSample <= 16) {\n        return new Uint16Array(size);\n      } else if (bitsPerSample <= 32) {\n        return new Uint32Array(size);\n      }\n      break;\n    case 2: // twos complement signed integer data\n      if (bitsPerSample === 8) {\n        return new Int8Array(size);\n      } else if (bitsPerSample === 16) {\n        return new Int16Array(size);\n      } else if (bitsPerSample === 32) {\n        return new Int32Array(size);\n      }\n      break;\n    case 3: // floating point data\n      switch (bitsPerSample) {\n        case 16:\n        case 32:\n          return new Float32Array(size);\n        case 64:\n          return new Float64Array(size);\n        default:\n          break;\n      }\n      break;\n    default:\n      break;\n  }\n  throw Error('Unsupported data format/bitsPerSample');\n}\n\nfunction needsNormalization(format, bitsPerSample) {\n  if ((format === 1 || format === 2) && bitsPerSample <= 32 && bitsPerSample % 8 === 0) {\n    return false;\n  } else if (format === 3 && (bitsPerSample === 16 || bitsPerSample === 32 || bitsPerSample === 64)) {\n    return false;\n  }\n  return true;\n}\n\nfunction normalizeArray(inBuffer, format, planarConfiguration, samplesPerPixel, bitsPerSample, tileWidth, tileHeight) {\n  // const inByteArray = new Uint8Array(inBuffer);\n  const view = new DataView(inBuffer);\n  const outSize = planarConfiguration === 2\n    ? tileHeight * tileWidth\n    : tileHeight * tileWidth * samplesPerPixel;\n  const samplesToTransfer = planarConfiguration === 2\n    ? 1 : samplesPerPixel;\n  const outArray = arrayForType(format, bitsPerSample, outSize);\n  // let pixel = 0;\n\n  const bitMask = parseInt('1'.repeat(bitsPerSample), 2);\n\n  if (format === 1) { // unsigned integer\n    // translation of https://github.com/OSGeo/gdal/blob/master/gdal/frmts/gtiff/geotiff.cpp#L7337\n    let pixelBitSkip;\n    // let sampleBitOffset = 0;\n    if (planarConfiguration === 1) {\n      pixelBitSkip = samplesPerPixel * bitsPerSample;\n      // sampleBitOffset = (samplesPerPixel - 1) * bitsPerSample;\n    } else {\n      pixelBitSkip = bitsPerSample;\n    }\n\n    // Bits per line rounds up to next byte boundary.\n    let bitsPerLine = tileWidth * pixelBitSkip;\n    if ((bitsPerLine & 7) !== 0) {\n      bitsPerLine = (bitsPerLine + 7) & (~7);\n    }\n\n    for (let y = 0; y < tileHeight; ++y) {\n      const lineBitOffset = y * bitsPerLine;\n      for (let x = 0; x < tileWidth; ++x) {\n        const pixelBitOffset = lineBitOffset + (x * samplesToTransfer * bitsPerSample);\n        for (let i = 0; i < samplesToTransfer; ++i) {\n          const bitOffset = pixelBitOffset + (i * bitsPerSample);\n          const outIndex = (((y * tileWidth) + x) * samplesToTransfer) + i;\n\n          const byteOffset = Math.floor(bitOffset / 8);\n          const innerBitOffset = bitOffset % 8;\n          if (innerBitOffset + bitsPerSample <= 8) {\n            outArray[outIndex] = (view.getUint8(byteOffset) >> (8 - bitsPerSample) - innerBitOffset) & bitMask;\n          } else if (innerBitOffset + bitsPerSample <= 16) {\n            outArray[outIndex] = (view.getUint16(byteOffset) >> (16 - bitsPerSample) - innerBitOffset) & bitMask;\n          } else if (innerBitOffset + bitsPerSample <= 24) {\n            const raw = (view.getUint16(byteOffset) << 8) | (view.getUint8(byteOffset + 2));\n            outArray[outIndex] = (raw >> (24 - bitsPerSample) - innerBitOffset) & bitMask;\n          } else {\n            outArray[outIndex] = (view.getUint32(byteOffset) >> (32 - bitsPerSample) - innerBitOffset) & bitMask;\n          }\n\n          // let outWord = 0;\n          // for (let bit = 0; bit < bitsPerSample; ++bit) {\n          //   if (inByteArray[bitOffset >> 3]\n          //     & (0x80 >> (bitOffset & 7))) {\n          //     outWord |= (1 << (bitsPerSample - 1 - bit));\n          //   }\n          //   ++bitOffset;\n          // }\n\n          // outArray[outIndex] = outWord;\n          // outArray[pixel] = outWord;\n          // pixel += 1;\n        }\n        // bitOffset = bitOffset + pixelBitSkip - bitsPerSample;\n      }\n    }\n  } else if (format === 3) { // floating point\n    // Float16 is handled elsewhere\n    // normalize 16/24 bit floats to 32 bit floats in the array\n    // console.time();\n    // if (bitsPerSample === 16) {\n    //   for (let byte = 0, outIndex = 0; byte < inBuffer.byteLength; byte += 2, ++outIndex) {\n    //     outArray[outIndex] = getFloat16(view, byte);\n    //   }\n    // }\n    // console.timeEnd()\n  }\n\n  return outArray.buffer;\n}\n\n/**\n * GeoTIFF sub-file image.\n */\nclass GeoTIFFImage {\n  /**\n   * @constructor\n   * @param {Object} fileDirectory The parsed file directory\n   * @param {Object} geoKeys The parsed geo-keys\n   * @param {DataView} dataView The DataView for the underlying file.\n   * @param {Boolean} littleEndian Whether the file is encoded in little or big endian\n   * @param {Boolean} cache Whether or not decoded tiles shall be cached\n   * @param {import('./source/basesource').BaseSource} source The datasource to read from\n   */\n  constructor(fileDirectory, geoKeys, dataView, littleEndian, cache, source) {\n    this.fileDirectory = fileDirectory;\n    this.geoKeys = geoKeys;\n    this.dataView = dataView;\n    this.littleEndian = littleEndian;\n    this.tiles = cache ? {} : null;\n    this.isTiled = !fileDirectory.StripOffsets;\n    const planarConfiguration = fileDirectory.PlanarConfiguration;\n    this.planarConfiguration = (typeof planarConfiguration === 'undefined') ? 1 : planarConfiguration;\n    if (this.planarConfiguration !== 1 && this.planarConfiguration !== 2) {\n      throw new Error('Invalid planar configuration.');\n    }\n\n    this.source = source;\n  }\n\n  /**\n   * Returns the associated parsed file directory.\n   * @returns {Object} the parsed file directory\n   */\n  getFileDirectory() {\n    return this.fileDirectory;\n  }\n\n  /**\n   * Returns the associated parsed geo keys.\n   * @returns {Object} the parsed geo keys\n   */\n  getGeoKeys() {\n    return this.geoKeys;\n  }\n\n  /**\n   * Returns the width of the image.\n   * @returns {Number} the width of the image\n   */\n  getWidth() {\n    return this.fileDirectory.ImageWidth;\n  }\n\n  /**\n   * Returns the height of the image.\n   * @returns {Number} the height of the image\n   */\n  getHeight() {\n    return this.fileDirectory.ImageLength;\n  }\n\n  /**\n   * Returns the number of samples per pixel.\n   * @returns {Number} the number of samples per pixel\n   */\n  getSamplesPerPixel() {\n    return typeof this.fileDirectory.SamplesPerPixel !== 'undefined'\n      ? this.fileDirectory.SamplesPerPixel : 1;\n  }\n\n  /**\n   * Returns the width of each tile.\n   * @returns {Number} the width of each tile\n   */\n  getTileWidth() {\n    return this.isTiled ? this.fileDirectory.TileWidth : this.getWidth();\n  }\n\n  /**\n   * Returns the height of each tile.\n   * @returns {Number} the height of each tile\n   */\n  getTileHeight() {\n    if (this.isTiled) {\n      return this.fileDirectory.TileLength;\n    }\n    if (typeof this.fileDirectory.RowsPerStrip !== 'undefined') {\n      return Math.min(this.fileDirectory.RowsPerStrip, this.getHeight());\n    }\n    return this.getHeight();\n  }\n\n  getBlockWidth() {\n    return this.getTileWidth();\n  }\n\n  getBlockHeight(y) {\n    if (this.isTiled || (y + 1) * this.getTileHeight() <= this.getHeight()) {\n      return this.getTileHeight();\n    } else {\n      return this.getHeight() - (y * this.getTileHeight());\n    }\n  }\n\n  /**\n   * Calculates the number of bytes for each pixel across all samples. Only full\n   * bytes are supported, an exception is thrown when this is not the case.\n   * @returns {Number} the bytes per pixel\n   */\n  getBytesPerPixel() {\n    let bytes = 0;\n    for (let i = 0; i < this.fileDirectory.BitsPerSample.length; ++i) {\n      bytes += this.getSampleByteSize(i);\n    }\n    return bytes;\n  }\n\n  getSampleByteSize(i) {\n    if (i >= this.fileDirectory.BitsPerSample.length) {\n      throw new RangeError(`Sample index ${i} is out of range.`);\n    }\n    return Math.ceil(this.fileDirectory.BitsPerSample[i] / 8);\n  }\n\n  getReaderForSample(sampleIndex) {\n    const format = this.fileDirectory.SampleFormat\n      ? this.fileDirectory.SampleFormat[sampleIndex] : 1;\n    const bitsPerSample = this.fileDirectory.BitsPerSample[sampleIndex];\n    switch (format) {\n      case 1: // unsigned integer data\n        if (bitsPerSample <= 8) {\n          return DataView.prototype.getUint8;\n        } else if (bitsPerSample <= 16) {\n          return DataView.prototype.getUint16;\n        } else if (bitsPerSample <= 32) {\n          return DataView.prototype.getUint32;\n        }\n        break;\n      case 2: // twos complement signed integer data\n        if (bitsPerSample <= 8) {\n          return DataView.prototype.getInt8;\n        } else if (bitsPerSample <= 16) {\n          return DataView.prototype.getInt16;\n        } else if (bitsPerSample <= 32) {\n          return DataView.prototype.getInt32;\n        }\n        break;\n      case 3:\n        switch (bitsPerSample) {\n          case 16:\n            return function (offset, littleEndian) {\n              return getFloat16(this, offset, littleEndian);\n            };\n          case 32:\n            return DataView.prototype.getFloat32;\n          case 64:\n            return DataView.prototype.getFloat64;\n          default:\n            break;\n        }\n        break;\n      default:\n        break;\n    }\n    throw Error('Unsupported data format/bitsPerSample');\n  }\n\n  getSampleFormat(sampleIndex = 0) {\n    return this.fileDirectory.SampleFormat\n      ? this.fileDirectory.SampleFormat[sampleIndex] : 1;\n  }\n\n  getBitsPerSample(sampleIndex = 0) {\n    return this.fileDirectory.BitsPerSample[sampleIndex];\n  }\n\n  getArrayForSample(sampleIndex, size) {\n    const format = this.getSampleFormat(sampleIndex);\n    const bitsPerSample = this.getBitsPerSample(sampleIndex);\n    return arrayForType(format, bitsPerSample, size);\n  }\n\n  /**\n   * Returns the decoded strip or tile.\n   * @param {Number} x the strip or tile x-offset\n   * @param {Number} y the tile y-offset (0 for stripped images)\n   * @param {Number} sample the sample to get for separated samples\n   * @param {import(\"./geotiff\").Pool|import(\"./geotiff\").BaseDecoder} poolOrDecoder the decoder or decoder pool\n   * @param {AbortSignal} [signal] An AbortSignal that may be signalled if the request is\n   *                               to be aborted\n   * @returns {Promise.<ArrayBuffer>}\n   */\n  async getTileOrStrip(x, y, sample, poolOrDecoder, signal) {\n    const numTilesPerRow = Math.ceil(this.getWidth() / this.getTileWidth());\n    const numTilesPerCol = Math.ceil(this.getHeight() / this.getTileHeight());\n    let index;\n    const { tiles } = this;\n    if (this.planarConfiguration === 1) {\n      index = (y * numTilesPerRow) + x;\n    } else if (this.planarConfiguration === 2) {\n      index = (sample * numTilesPerRow * numTilesPerCol) + (y * numTilesPerRow) + x;\n    }\n\n    let offset;\n    let byteCount;\n    if (this.isTiled) {\n      offset = this.fileDirectory.TileOffsets[index];\n      byteCount = this.fileDirectory.TileByteCounts[index];\n    } else {\n      offset = this.fileDirectory.StripOffsets[index];\n      byteCount = this.fileDirectory.StripByteCounts[index];\n    }\n    const slice = (await this.source.fetch([{ offset, length: byteCount }], signal))[0];\n\n    let request;\n    if (tiles === null || !tiles[index]) {\n    // resolve each request by potentially applying array normalization\n      request = (async () => {\n        let data = await poolOrDecoder.decode(this.fileDirectory, slice);\n        const sampleFormat = this.getSampleFormat();\n        const bitsPerSample = this.getBitsPerSample();\n        if (needsNormalization(sampleFormat, bitsPerSample)) {\n          data = normalizeArray(\n            data,\n            sampleFormat,\n            this.planarConfiguration,\n            this.getSamplesPerPixel(),\n            bitsPerSample,\n            this.getTileWidth(),\n            this.getBlockHeight(y),\n          );\n        }\n        return data;\n      })();\n\n      // set the cache\n      if (tiles !== null) {\n        tiles[index] = request;\n      }\n    } else {\n      // get from the cache\n      request = tiles[index];\n    }\n\n    // cache the tile request\n    return { x, y, sample, data: await request };\n  }\n\n  /**\n   * Internal read function.\n   * @private\n   * @param {Array} imageWindow The image window in pixel coordinates\n   * @param {Array} samples The selected samples (0-based indices)\n   * @param {TypedArray|TypedArray[]} valueArrays The array(s) to write into\n   * @param {Boolean} interleave Whether or not to write in an interleaved manner\n   * @param {import(\"./geotiff\").Pool|AbstractDecoder} poolOrDecoder the decoder or decoder pool\n   * @param {number} width the width of window to be read into\n   * @param {number} height the height of window to be read into\n   * @param {number} resampleMethod the resampling method to be used when interpolating\n   * @param {AbortSignal} [signal] An AbortSignal that may be signalled if the request is\n   *                               to be aborted\n   * @returns {Promise<ReadRasterResult>}\n   */\n  async _readRaster(imageWindow, samples, valueArrays, interleave, poolOrDecoder, width,\n    height, resampleMethod, signal) {\n    const tileWidth = this.getTileWidth();\n    const tileHeight = this.getTileHeight();\n    const imageWidth = this.getWidth();\n    const imageHeight = this.getHeight();\n\n    const minXTile = Math.max(Math.floor(imageWindow[0] / tileWidth), 0);\n    const maxXTile = Math.min(\n      Math.ceil(imageWindow[2] / tileWidth),\n      Math.ceil(imageWidth / tileWidth),\n    );\n    const minYTile = Math.max(Math.floor(imageWindow[1] / tileHeight), 0);\n    const maxYTile = Math.min(\n      Math.ceil(imageWindow[3] / tileHeight),\n      Math.ceil(imageHeight / tileHeight),\n    );\n    const windowWidth = imageWindow[2] - imageWindow[0];\n\n    let bytesPerPixel = this.getBytesPerPixel();\n\n    const srcSampleOffsets = [];\n    const sampleReaders = [];\n    for (let i = 0; i < samples.length; ++i) {\n      if (this.planarConfiguration === 1) {\n        srcSampleOffsets.push(sum(this.fileDirectory.BitsPerSample, 0, samples[i]) / 8);\n      } else {\n        srcSampleOffsets.push(0);\n      }\n      sampleReaders.push(this.getReaderForSample(samples[i]));\n    }\n\n    const promises = [];\n    const { littleEndian } = this;\n\n    for (let yTile = minYTile; yTile < maxYTile; ++yTile) {\n      for (let xTile = minXTile; xTile < maxXTile; ++xTile) {\n        for (let sampleIndex = 0; sampleIndex < samples.length; ++sampleIndex) {\n          const si = sampleIndex;\n          const sample = samples[sampleIndex];\n          if (this.planarConfiguration === 2) {\n            bytesPerPixel = this.getSampleByteSize(sampleIndex);\n          }\n          const promise = this.getTileOrStrip(xTile, yTile, sample, poolOrDecoder, signal).then((tile) => {\n            const buffer = tile.data;\n            const dataView = new DataView(buffer);\n            const blockHeight = this.getBlockHeight(tile.y);\n            const firstLine = tile.y * tileHeight;\n            const firstCol = tile.x * tileWidth;\n            const lastLine = firstLine + blockHeight;\n            const lastCol = (tile.x + 1) * tileWidth;\n            const reader = sampleReaders[si];\n\n            const ymax = Math.min(blockHeight, blockHeight - (lastLine - imageWindow[3]), imageHeight - firstLine);\n            const xmax = Math.min(tileWidth, tileWidth - (lastCol - imageWindow[2]), imageWidth - firstCol);\n\n            for (let y = Math.max(0, imageWindow[1] - firstLine); y < ymax; ++y) {\n              for (let x = Math.max(0, imageWindow[0] - firstCol); x < xmax; ++x) {\n                const pixelOffset = ((y * tileWidth) + x) * bytesPerPixel;\n                const value = reader.call(\n                  dataView, pixelOffset + srcSampleOffsets[si], littleEndian,\n                );\n                let windowCoordinate;\n                if (interleave) {\n                  windowCoordinate = ((y + firstLine - imageWindow[1]) * windowWidth * samples.length)\n                    + ((x + firstCol - imageWindow[0]) * samples.length)\n                    + si;\n                  valueArrays[windowCoordinate] = value;\n                } else {\n                  windowCoordinate = (\n                    (y + firstLine - imageWindow[1]) * windowWidth\n                  ) + x + firstCol - imageWindow[0];\n                  valueArrays[si][windowCoordinate] = value;\n                }\n              }\n            }\n          });\n          promises.push(promise);\n        }\n      }\n    }\n    await Promise.all(promises);\n\n    if ((width && (imageWindow[2] - imageWindow[0]) !== width)\n        || (height && (imageWindow[3] - imageWindow[1]) !== height)) {\n      let resampled;\n      if (interleave) {\n        resampled = resampleInterleaved(\n          valueArrays,\n          imageWindow[2] - imageWindow[0],\n          imageWindow[3] - imageWindow[1],\n          width, height,\n          samples.length,\n          resampleMethod,\n        );\n      } else {\n        resampled = resample(\n          valueArrays,\n          imageWindow[2] - imageWindow[0],\n          imageWindow[3] - imageWindow[1],\n          width, height,\n          resampleMethod,\n        );\n      }\n      resampled.width = width;\n      resampled.height = height;\n      return resampled;\n    }\n\n    valueArrays.width = width || imageWindow[2] - imageWindow[0];\n    valueArrays.height = height || imageWindow[3] - imageWindow[1];\n\n    return valueArrays;\n  }\n\n  /**\n   * Reads raster data from the image. This function reads all selected samples\n   * into separate arrays of the correct type for that sample or into a single\n   * combined array when `interleave` is set. When provided, only a subset\n   * of the raster is read for each sample.\n   *\n   * @param {ReadRasterOptions} [options={}] optional parameters\n   * @returns {Promise<ReadRasterResult>} the decoded arrays as a promise\n   */\n  async readRasters({\n    window: wnd, samples = [], interleave, pool = null,\n    width, height, resampleMethod, fillValue, signal,\n  } = {}) {\n    const imageWindow = wnd || [0, 0, this.getWidth(), this.getHeight()];\n\n    // check parameters\n    if (imageWindow[0] > imageWindow[2] || imageWindow[1] > imageWindow[3]) {\n      throw new Error('Invalid subsets');\n    }\n\n    const imageWindowWidth = imageWindow[2] - imageWindow[0];\n    const imageWindowHeight = imageWindow[3] - imageWindow[1];\n    const numPixels = imageWindowWidth * imageWindowHeight;\n    const samplesPerPixel = this.getSamplesPerPixel();\n\n    if (!samples || !samples.length) {\n      for (let i = 0; i < samplesPerPixel; ++i) {\n        samples.push(i);\n      }\n    } else {\n      for (let i = 0; i < samples.length; ++i) {\n        if (samples[i] >= samplesPerPixel) {\n          return Promise.reject(new RangeError(`Invalid sample index '${samples[i]}'.`));\n        }\n      }\n    }\n    let valueArrays;\n    if (interleave) {\n      const format = this.fileDirectory.SampleFormat\n        ? Math.max.apply(null, this.fileDirectory.SampleFormat) : 1;\n      const bitsPerSample = Math.max.apply(null, this.fileDirectory.BitsPerSample);\n      valueArrays = arrayForType(format, bitsPerSample, numPixels * samples.length);\n      if (fillValue) {\n        valueArrays.fill(fillValue);\n      }\n    } else {\n      valueArrays = [];\n      for (let i = 0; i < samples.length; ++i) {\n        const valueArray = this.getArrayForSample(samples[i], numPixels);\n        if (Array.isArray(fillValue) && i < fillValue.length) {\n          valueArray.fill(fillValue[i]);\n        } else if (fillValue && !Array.isArray(fillValue)) {\n          valueArray.fill(fillValue);\n        }\n        valueArrays.push(valueArray);\n      }\n    }\n\n    const poolOrDecoder = pool || await getDecoder(this.fileDirectory);\n\n    const result = await this._readRaster(\n      imageWindow, samples, valueArrays, interleave, poolOrDecoder, width, height, resampleMethod, signal,\n    );\n    return result;\n  }\n\n  /**\n   * Reads raster data from the image as RGB. The result is always an\n   * interleaved typed array.\n   * Colorspaces other than RGB will be transformed to RGB, color maps expanded.\n   * When no other method is applicable, the first sample is used to produce a\n   * grayscale image.\n   * When provided, only a subset of the raster is read for each sample.\n   *\n   * @param {Object} [options] optional parameters\n   * @param {Array<number>} [options.window] the subset to read data from in pixels.\n   * @param {boolean} [options.interleave=true] whether the data shall be read\n   *                                             in one single array or separate\n   *                                             arrays.\n   * @param {import(\"./geotiff\").Pool} [options.pool=null] The optional decoder pool to use.\n   * @param {number} [options.width] The desired width of the output. When the width is no the\n   *                                 same as the images, resampling will be performed.\n   * @param {number} [options.height] The desired height of the output. When the width is no the\n   *                                  same as the images, resampling will be performed.\n   * @param {string} [options.resampleMethod='nearest'] The desired resampling method.\n   * @param {boolean} [options.enableAlpha=false] Enable reading alpha channel if present.\n   * @param {AbortSignal} [options.signal] An AbortSignal that may be signalled if the request is\n   *                                       to be aborted\n   * @returns {Promise<ReadRasterResult>} the RGB array as a Promise\n   */\n  async readRGB({ window, interleave = true, pool = null, width, height,\n    resampleMethod, enableAlpha = false, signal } = {}) {\n    const imageWindow = window || [0, 0, this.getWidth(), this.getHeight()];\n\n    // check parameters\n    if (imageWindow[0] > imageWindow[2] || imageWindow[1] > imageWindow[3]) {\n      throw new Error('Invalid subsets');\n    }\n\n    const pi = this.fileDirectory.PhotometricInterpretation;\n\n    if (pi === photometricInterpretations.RGB) {\n      let s = [0, 1, 2];\n      if ((!(this.fileDirectory.ExtraSamples === ExtraSamplesValues.Unspecified)) && enableAlpha) {\n        s = [];\n        for (let i = 0; i < this.fileDirectory.BitsPerSample.length; i += 1) {\n          s.push(i);\n        }\n      }\n      return this.readRasters({\n        window,\n        interleave,\n        samples: s,\n        pool,\n        width,\n        height,\n        resampleMethod,\n        signal,\n      });\n    }\n\n    let samples;\n    switch (pi) {\n      case photometricInterpretations.WhiteIsZero:\n      case photometricInterpretations.BlackIsZero:\n      case photometricInterpretations.Palette:\n        samples = [0];\n        break;\n      case photometricInterpretations.CMYK:\n        samples = [0, 1, 2, 3];\n        break;\n      case photometricInterpretations.YCbCr:\n      case photometricInterpretations.CIELab:\n        samples = [0, 1, 2];\n        break;\n      default:\n        throw new Error('Invalid or unsupported photometric interpretation.');\n    }\n\n    const subOptions = {\n      window: imageWindow,\n      interleave: true,\n      samples,\n      pool,\n      width,\n      height,\n      resampleMethod,\n      signal,\n    };\n    const { fileDirectory } = this;\n    const raster = await this.readRasters(subOptions);\n\n    const max = 2 ** this.fileDirectory.BitsPerSample[0];\n    let data;\n    switch (pi) {\n      case photometricInterpretations.WhiteIsZero:\n        data = fromWhiteIsZero(raster, max);\n        break;\n      case photometricInterpretations.BlackIsZero:\n        data = fromBlackIsZero(raster, max);\n        break;\n      case photometricInterpretations.Palette:\n        data = fromPalette(raster, fileDirectory.ColorMap);\n        break;\n      case photometricInterpretations.CMYK:\n        data = fromCMYK(raster);\n        break;\n      case photometricInterpretations.YCbCr:\n        data = fromYCbCr(raster);\n        break;\n      case photometricInterpretations.CIELab:\n        data = fromCIELab(raster);\n        break;\n      default:\n        throw new Error('Unsupported photometric interpretation.');\n    }\n\n    // if non-interleaved data is requested, we must split the channels\n    // into their respective arrays\n    if (!interleave) {\n      const red = new Uint8Array(data.length / 3);\n      const green = new Uint8Array(data.length / 3);\n      const blue = new Uint8Array(data.length / 3);\n      for (let i = 0, j = 0; i < data.length; i += 3, ++j) {\n        red[j] = data[i];\n        green[j] = data[i + 1];\n        blue[j] = data[i + 2];\n      }\n      data = [red, green, blue];\n    }\n\n    data.width = raster.width;\n    data.height = raster.height;\n    return data;\n  }\n\n  /**\n   * Returns an array of tiepoints.\n   * @returns {Object[]}\n   */\n  getTiePoints() {\n    if (!this.fileDirectory.ModelTiepoint) {\n      return [];\n    }\n\n    const tiePoints = [];\n    for (let i = 0; i < this.fileDirectory.ModelTiepoint.length; i += 6) {\n      tiePoints.push({\n        i: this.fileDirectory.ModelTiepoint[i],\n        j: this.fileDirectory.ModelTiepoint[i + 1],\n        k: this.fileDirectory.ModelTiepoint[i + 2],\n        x: this.fileDirectory.ModelTiepoint[i + 3],\n        y: this.fileDirectory.ModelTiepoint[i + 4],\n        z: this.fileDirectory.ModelTiepoint[i + 5],\n      });\n    }\n    return tiePoints;\n  }\n\n  /**\n   * Returns the parsed GDAL metadata items.\n   *\n   * If sample is passed to null, dataset-level metadata will be returned.\n   * Otherwise only metadata specific to the provided sample will be returned.\n   *\n   * @param {number} [sample=null] The sample index.\n   * @returns {Object}\n   */\n  getGDALMetadata(sample = null) {\n    const metadata = {};\n    if (!this.fileDirectory.GDAL_METADATA) {\n      return null;\n    }\n    const string = this.fileDirectory.GDAL_METADATA;\n\n    let items = findTagsByName(string, 'Item');\n\n    if (sample === null) {\n      items = items.filter((item) => getAttribute(item, 'sample') === undefined);\n    } else {\n      items = items.filter((item) => Number(getAttribute(item, 'sample')) === sample);\n    }\n\n    for (let i = 0; i < items.length; ++i) {\n      const item = items[i];\n      metadata[getAttribute(item, 'name')] = item.inner;\n    }\n    return metadata;\n  }\n\n  /**\n   * Returns the GDAL nodata value\n   * @returns {number|null}\n   */\n  getGDALNoData() {\n    if (!this.fileDirectory.GDAL_NODATA) {\n      return null;\n    }\n    const string = this.fileDirectory.GDAL_NODATA;\n    return Number(string.substring(0, string.length - 1));\n  }\n\n  /**\n   * Returns the image origin as a XYZ-vector. When the image has no affine\n   * transformation, then an exception is thrown.\n   * @returns {Array<number>} The origin as a vector\n   */\n  getOrigin() {\n    const tiePoints = this.fileDirectory.ModelTiepoint;\n    const modelTransformation = this.fileDirectory.ModelTransformation;\n    if (tiePoints && tiePoints.length === 6) {\n      return [\n        tiePoints[3],\n        tiePoints[4],\n        tiePoints[5],\n      ];\n    }\n    if (modelTransformation) {\n      return [\n        modelTransformation[3],\n        modelTransformation[7],\n        modelTransformation[11],\n      ];\n    }\n    throw new Error('The image does not have an affine transformation.');\n  }\n\n  /**\n   * Returns the image resolution as a XYZ-vector. When the image has no affine\n   * transformation, then an exception is thrown.\n   * @param {GeoTIFFImage} [referenceImage=null] A reference image to calculate the resolution from\n   *                                             in cases when the current image does not have the\n   *                                             required tags on its own.\n   * @returns {Array<number>} The resolution as a vector\n   */\n  getResolution(referenceImage = null) {\n    const modelPixelScale = this.fileDirectory.ModelPixelScale;\n    const modelTransformation = this.fileDirectory.ModelTransformation;\n\n    if (modelPixelScale) {\n      return [\n        modelPixelScale[0],\n        -modelPixelScale[1],\n        modelPixelScale[2],\n      ];\n    }\n    if (modelTransformation) {\n      return [\n        modelTransformation[0],\n        modelTransformation[5],\n        modelTransformation[10],\n      ];\n    }\n\n    if (referenceImage) {\n      const [refResX, refResY, refResZ] = referenceImage.getResolution();\n      return [\n        refResX * referenceImage.getWidth() / this.getWidth(),\n        refResY * referenceImage.getHeight() / this.getHeight(),\n        refResZ * referenceImage.getWidth() / this.getWidth(),\n      ];\n    }\n\n    throw new Error('The image does not have an affine transformation.');\n  }\n\n  /**\n   * Returns whether or not the pixels of the image depict an area (or point).\n   * @returns {Boolean} Whether the pixels are a point\n   */\n  pixelIsArea() {\n    return this.geoKeys.GTRasterTypeGeoKey === 1;\n  }\n\n  /**\n   * Returns the image bounding box as an array of 4 values: min-x, min-y,\n   * max-x and max-y. When the image has no affine transformation, then an\n   * exception is thrown.\n   * @returns {Array<number>} The bounding box\n   */\n  getBoundingBox() {\n    const origin = this.getOrigin();\n    const resolution = this.getResolution();\n\n    const x1 = origin[0];\n    const y1 = origin[1];\n\n    const x2 = x1 + (resolution[0] * this.getWidth());\n    const y2 = y1 + (resolution[1] * this.getHeight());\n\n    return [\n      Math.min(x1, x2),\n      Math.min(y1, y2),\n      Math.max(x1, x2),\n      Math.max(y1, y2),\n    ];\n  }\n}\n\nexport default GeoTIFFImage;\n","/*\n  Some parts of this file are based on UTIF.js,\n  which was released under the MIT License.\n  You can view that here:\n  https://github.com/photopea/UTIF.js/blob/master/LICENSE\n*/\nimport { fieldTagNames, fieldTagTypes, fieldTypeNames, geoKeyNames } from './globals.js';\nimport { assign, endsWith, forEach, invert, times } from './utils.js';\n\nconst tagName2Code = invert(fieldTagNames);\nconst geoKeyName2Code = invert(geoKeyNames);\nconst name2code = {};\nassign(name2code, tagName2Code);\nassign(name2code, geoKeyName2Code);\nconst typeName2byte = invert(fieldTypeNames);\n\n// config variables\nconst numBytesInIfd = 1000;\n\nconst _binBE = {\n  nextZero: (data, o) => {\n    let oincr = o;\n    while (data[oincr] !== 0) {\n      oincr++;\n    }\n    return oincr;\n  },\n  readUshort: (buff, p) => {\n    return (buff[p] << 8) | buff[p + 1];\n  },\n  readShort: (buff, p) => {\n    const a = _binBE.ui8;\n    a[0] = buff[p + 1];\n    a[1] = buff[p + 0];\n    return _binBE.i16[0];\n  },\n  readInt: (buff, p) => {\n    const a = _binBE.ui8;\n    a[0] = buff[p + 3];\n    a[1] = buff[p + 2];\n    a[2] = buff[p + 1];\n    a[3] = buff[p + 0];\n    return _binBE.i32[0];\n  },\n  readUint: (buff, p) => {\n    const a = _binBE.ui8;\n    a[0] = buff[p + 3];\n    a[1] = buff[p + 2];\n    a[2] = buff[p + 1];\n    a[3] = buff[p + 0];\n    return _binBE.ui32[0];\n  },\n  readASCII: (buff, p, l) => {\n    return l.map((i) => String.fromCharCode(buff[p + i])).join('');\n  },\n  readFloat: (buff, p) => {\n    const a = _binBE.ui8;\n    times(4, (i) => {\n      a[i] = buff[p + 3 - i];\n    });\n    return _binBE.fl32[0];\n  },\n  readDouble: (buff, p) => {\n    const a = _binBE.ui8;\n    times(8, (i) => {\n      a[i] = buff[p + 7 - i];\n    });\n    return _binBE.fl64[0];\n  },\n  writeUshort: (buff, p, n) => {\n    buff[p] = (n >> 8) & 255;\n    buff[p + 1] = n & 255;\n  },\n  writeUint: (buff, p, n) => {\n    buff[p] = (n >> 24) & 255;\n    buff[p + 1] = (n >> 16) & 255;\n    buff[p + 2] = (n >> 8) & 255;\n    buff[p + 3] = (n >> 0) & 255;\n  },\n  writeASCII: (buff, p, s) => {\n    times(s.length, (i) => {\n      buff[p + i] = s.charCodeAt(i);\n    });\n  },\n  ui8: new Uint8Array(8),\n};\n\n_binBE.fl64 = new Float64Array(_binBE.ui8.buffer);\n\n_binBE.writeDouble = (buff, p, n) => {\n  _binBE.fl64[0] = n;\n  times(8, (i) => {\n    buff[p + i] = _binBE.ui8[7 - i];\n  });\n};\n\nconst _writeIFD = (bin, data, _offset, ifd) => {\n  let offset = _offset;\n\n  const keys = Object.keys(ifd).filter((key) => {\n    return key !== undefined && key !== null && key !== 'undefined';\n  });\n\n  bin.writeUshort(data, offset, keys.length);\n  offset += 2;\n\n  let eoff = offset + (12 * keys.length) + 4;\n\n  for (const key of keys) {\n    let tag = null;\n    if (typeof key === 'number') {\n      tag = key;\n    } else if (typeof key === 'string') {\n      tag = parseInt(key, 10);\n    }\n\n    const typeName = fieldTagTypes[tag];\n    const typeNum = typeName2byte[typeName];\n\n    if (typeName == null || typeName === undefined || typeof typeName === 'undefined') {\n      throw new Error(`unknown type of tag: ${tag}`);\n    }\n\n    let val = ifd[key];\n\n    if (val === undefined) {\n      throw new Error(`failed to get value for key ${key}`);\n    }\n\n    // ASCIIZ format with trailing 0 character\n    // http://www.fileformat.info/format/tiff/corion.htm\n    // https://stackoverflow.com/questions/7783044/whats-the-difference-between-asciiz-vs-ascii\n    if (typeName === 'ASCII' && typeof val === 'string' && endsWith(val, '\\u0000') === false) {\n      val += '\\u0000';\n    }\n\n    const num = val.length;\n\n    bin.writeUshort(data, offset, tag);\n    offset += 2;\n\n    bin.writeUshort(data, offset, typeNum);\n    offset += 2;\n\n    bin.writeUint(data, offset, num);\n    offset += 4;\n\n    let dlen = [-1, 1, 1, 2, 4, 8, 0, 0, 0, 0, 0, 0, 8][typeNum] * num;\n    let toff = offset;\n\n    if (dlen > 4) {\n      bin.writeUint(data, offset, eoff);\n      toff = eoff;\n    }\n\n    if (typeName === 'ASCII') {\n      bin.writeASCII(data, toff, val);\n    } else if (typeName === 'SHORT') {\n      times(num, (i) => {\n        bin.writeUshort(data, toff + (2 * i), val[i]);\n      });\n    } else if (typeName === 'LONG') {\n      times(num, (i) => {\n        bin.writeUint(data, toff + (4 * i), val[i]);\n      });\n    } else if (typeName === 'RATIONAL') {\n      times(num, (i) => {\n        bin.writeUint(data, toff + (8 * i), Math.round(val[i] * 10000));\n        bin.writeUint(data, toff + (8 * i) + 4, 10000);\n      });\n    } else if (typeName === 'DOUBLE') {\n      times(num, (i) => {\n        bin.writeDouble(data, toff + (8 * i), val[i]);\n      });\n    }\n\n    if (dlen > 4) {\n      dlen += (dlen & 1);\n      eoff += dlen;\n    }\n\n    offset += 4;\n  }\n\n  return [offset, eoff];\n};\n\nconst encodeIfds = (ifds) => {\n  const data = new Uint8Array(numBytesInIfd);\n  let offset = 4;\n  const bin = _binBE;\n\n  // set big-endian byte-order\n  // https://en.wikipedia.org/wiki/TIFF#Byte_order\n  data[0] = 77;\n  data[1] = 77;\n\n  // set format-version number\n  // https://en.wikipedia.org/wiki/TIFF#Byte_order\n  data[3] = 42;\n\n  let ifdo = 8;\n\n  bin.writeUint(data, offset, ifdo);\n\n  offset += 4;\n\n  ifds.forEach((ifd, i) => {\n    const noffs = _writeIFD(bin, data, ifdo, ifd);\n    ifdo = noffs[1];\n    if (i < ifds.length - 1) {\n      bin.writeUint(data, noffs[0], ifdo);\n    }\n  });\n\n  if (data.slice) {\n    return data.slice(0, ifdo).buffer;\n  }\n\n  // node hasn't implemented slice on Uint8Array yet\n  const result = new Uint8Array(ifdo);\n  for (let i = 0; i < ifdo; i++) {\n    result[i] = data[i];\n  }\n  return result.buffer;\n};\n\nconst encodeImage = (values, width, height, metadata) => {\n  if (height === undefined || height === null) {\n    throw new Error(`you passed into encodeImage a width of type ${height}`);\n  }\n\n  if (width === undefined || width === null) {\n    throw new Error(`you passed into encodeImage a width of type ${width}`);\n  }\n\n  const ifd = {\n    256: [width], // ImageWidth\n    257: [height], // ImageLength\n    273: [numBytesInIfd], // strips offset\n    278: [height], // RowsPerStrip\n    305: 'geotiff.js', // no array for ASCII(Z)\n  };\n\n  if (metadata) {\n    for (const i in metadata) {\n      if (metadata.hasOwnProperty(i)) {\n        ifd[i] = metadata[i];\n      }\n    }\n  }\n\n  const prfx = new Uint8Array(encodeIfds([ifd]));\n\n  const img = new Uint8Array(values);\n\n  const samplesPerPixel = ifd[277];\n\n  const data = new Uint8Array(numBytesInIfd + (width * height * samplesPerPixel));\n  times(prfx.length, (i) => {\n    data[i] = prfx[i];\n  });\n  forEach(img, (value, i) => {\n    data[numBytesInIfd + i] = value;\n  });\n\n  return data.buffer;\n};\n\nconst convertToTids = (input) => {\n  const result = {};\n  for (const key in input) {\n    if (key !== 'StripOffsets') {\n      if (!name2code[key]) {\n        console.error(key, 'not in name2code:', Object.keys(name2code));\n      }\n      result[name2code[key]] = input[key];\n    }\n  }\n  return result;\n};\n\nconst toArray = (input) => {\n  if (Array.isArray(input)) {\n    return input;\n  }\n  return [input];\n};\n\nconst metadataDefaults = [\n  ['Compression', 1], // no compression\n  ['PlanarConfiguration', 1],\n  ['ExtraSamples', 0],\n];\n\nexport function writeGeotiff(data, metadata) {\n  const isFlattened = typeof data[0] === 'number';\n\n  let height;\n  let numBands;\n  let width;\n  let flattenedValues;\n\n  if (isFlattened) {\n    height = metadata.height || metadata.ImageLength;\n    width = metadata.width || metadata.ImageWidth;\n    numBands = data.length / (height * width);\n    flattenedValues = data;\n  } else {\n    numBands = data.length;\n    height = data[0].length;\n    width = data[0][0].length;\n    flattenedValues = [];\n    times(height, (rowIndex) => {\n      times(width, (columnIndex) => {\n        times(numBands, (bandIndex) => {\n          flattenedValues.push(data[bandIndex][rowIndex][columnIndex]);\n        });\n      });\n    });\n  }\n\n  metadata.ImageLength = height;\n  delete metadata.height;\n  metadata.ImageWidth = width;\n  delete metadata.width;\n\n  // consult https://www.loc.gov/preservation/digital/formats/content/tiff_tags.shtml\n\n  if (!metadata.BitsPerSample) {\n    metadata.BitsPerSample = times(numBands, () => 8);\n  }\n\n  metadataDefaults.forEach((tag) => {\n    const key = tag[0];\n    if (!metadata[key]) {\n      const value = tag[1];\n      metadata[key] = value;\n    }\n  });\n\n  // The color space of the image data.\n  // 1=black is zero and 2=RGB.\n  if (!metadata.PhotometricInterpretation) {\n    metadata.PhotometricInterpretation = metadata.BitsPerSample.length === 3 ? 2 : 1;\n  }\n\n  // The number of components per pixel.\n  if (!metadata.SamplesPerPixel) {\n    metadata.SamplesPerPixel = [numBands];\n  }\n\n  if (!metadata.StripByteCounts) {\n    // we are only writing one strip\n    metadata.StripByteCounts = [numBands * height * width];\n  }\n\n  if (!metadata.ModelPixelScale) {\n    // assumes raster takes up exactly the whole globe\n    metadata.ModelPixelScale = [360 / width, 180 / height, 0];\n  }\n\n  if (!metadata.SampleFormat) {\n    metadata.SampleFormat = times(numBands, () => 1);\n  }\n\n  // if didn't pass in projection information, assume the popular 4326 \"geographic projection\"\n  if (!metadata.hasOwnProperty('GeographicTypeGeoKey') && !metadata.hasOwnProperty('ProjectedCSTypeGeoKey')) {\n    metadata.GeographicTypeGeoKey = 4326;\n    metadata.ModelTiepoint = [0, 0, 0, -180, 90, 0]; // raster fits whole globe\n    metadata.GeogCitationGeoKey = 'WGS 84';\n    metadata.GTModelTypeGeoKey = 2;\n  }\n\n  const geoKeys = Object.keys(metadata)\n    .filter((key) => endsWith(key, 'GeoKey'))\n    .sort((a, b) => name2code[a] - name2code[b]);\n\n  if (!metadata.GeoAsciiParams) {\n    let geoAsciiParams = '';\n    geoKeys.forEach((name) => {\n      const code = Number(name2code[name]);\n      const tagType = fieldTagTypes[code];\n      if (tagType === 'ASCII') {\n        geoAsciiParams += `${metadata[name].toString()}\\u0000`;\n      }\n    });\n    if (geoAsciiParams.length > 0) {\n      metadata.GeoAsciiParams = geoAsciiParams;\n    }\n  }\n\n  if (!metadata.GeoKeyDirectory) {\n    const NumberOfKeys = geoKeys.length;\n\n    const GeoKeyDirectory = [1, 1, 0, NumberOfKeys];\n    geoKeys.forEach((geoKey) => {\n      const KeyID = Number(name2code[geoKey]);\n      GeoKeyDirectory.push(KeyID);\n\n      let Count;\n      let TIFFTagLocation;\n      let valueOffset;\n      if (fieldTagTypes[KeyID] === 'SHORT') {\n        Count = 1;\n        TIFFTagLocation = 0;\n        valueOffset = metadata[geoKey];\n      } else if (geoKey === 'GeogCitationGeoKey') {\n        Count = metadata.GeoAsciiParams.length;\n        TIFFTagLocation = Number(name2code.GeoAsciiParams);\n        valueOffset = 0;\n      } else {\n        console.log(`[geotiff.js] couldn't get TIFFTagLocation for ${geoKey}`);\n      }\n      GeoKeyDirectory.push(TIFFTagLocation);\n      GeoKeyDirectory.push(Count);\n      GeoKeyDirectory.push(valueOffset);\n    });\n    metadata.GeoKeyDirectory = GeoKeyDirectory;\n  }\n\n  // delete GeoKeys from metadata, because stored in GeoKeyDirectory tag\n  for (const geoKey in geoKeys) {\n    if (geoKeys.hasOwnProperty(geoKey)) {\n      delete metadata[geoKey];\n    }\n  }\n\n  [\n    'Compression',\n    'ExtraSamples',\n    'GeographicTypeGeoKey',\n    'GTModelTypeGeoKey',\n    'GTRasterTypeGeoKey',\n    'ImageLength', // synonym of ImageHeight\n    'ImageWidth',\n    'Orientation',\n    'PhotometricInterpretation',\n    'ProjectedCSTypeGeoKey',\n    'PlanarConfiguration',\n    'ResolutionUnit',\n    'SamplesPerPixel',\n    'XPosition',\n    'YPosition',\n  ].forEach((name) => {\n    if (metadata[name]) {\n      metadata[name] = toArray(metadata[name]);\n    }\n  });\n\n  const encodedMetadata = convertToTids(metadata);\n\n  const outputImage = encodeImage(flattenedValues, width, height, encodedMetadata);\n\n  return outputImage;\n}\n","export const fieldTagNames = {\n  // TIFF Baseline\n  0x013B: 'Artist',\n  0x0102: 'BitsPerSample',\n  0x0109: 'CellLength',\n  0x0108: 'CellWidth',\n  0x0140: 'ColorMap',\n  0x0103: 'Compression',\n  0x8298: 'Copyright',\n  0x0132: 'DateTime',\n  0x0152: 'ExtraSamples',\n  0x010A: 'FillOrder',\n  0x0121: 'FreeByteCounts',\n  0x0120: 'FreeOffsets',\n  0x0123: 'GrayResponseCurve',\n  0x0122: 'GrayResponseUnit',\n  0x013C: 'HostComputer',\n  0x010E: 'ImageDescription',\n  0x0101: 'ImageLength',\n  0x0100: 'ImageWidth',\n  0x010F: 'Make',\n  0x0119: 'MaxSampleValue',\n  0x0118: 'MinSampleValue',\n  0x0110: 'Model',\n  0x00FE: 'NewSubfileType',\n  0x0112: 'Orientation',\n  0x0106: 'PhotometricInterpretation',\n  0x011C: 'PlanarConfiguration',\n  0x0128: 'ResolutionUnit',\n  0x0116: 'RowsPerStrip',\n  0x0115: 'SamplesPerPixel',\n  0x0131: 'Software',\n  0x0117: 'StripByteCounts',\n  0x0111: 'StripOffsets',\n  0x00FF: 'SubfileType',\n  0x0107: 'Threshholding',\n  0x011A: 'XResolution',\n  0x011B: 'YResolution',\n\n  // TIFF Extended\n  0x0146: 'BadFaxLines',\n  0x0147: 'CleanFaxData',\n  0x0157: 'ClipPath',\n  0x0148: 'ConsecutiveBadFaxLines',\n  0x01B1: 'Decode',\n  0x01B2: 'DefaultImageColor',\n  0x010D: 'DocumentName',\n  0x0150: 'DotRange',\n  0x0141: 'HalftoneHints',\n  0x015A: 'Indexed',\n  0x015B: 'JPEGTables',\n  0x011D: 'PageName',\n  0x0129: 'PageNumber',\n  0x013D: 'Predictor',\n  0x013F: 'PrimaryChromaticities',\n  0x0214: 'ReferenceBlackWhite',\n  0x0153: 'SampleFormat',\n  0x0154: 'SMinSampleValue',\n  0x0155: 'SMaxSampleValue',\n  0x022F: 'StripRowCounts',\n  0x014A: 'SubIFDs',\n  0x0124: 'T4Options',\n  0x0125: 'T6Options',\n  0x0145: 'TileByteCounts',\n  0x0143: 'TileLength',\n  0x0144: 'TileOffsets',\n  0x0142: 'TileWidth',\n  0x012D: 'TransferFunction',\n  0x013E: 'WhitePoint',\n  0x0158: 'XClipPathUnits',\n  0x011E: 'XPosition',\n  0x0211: 'YCbCrCoefficients',\n  0x0213: 'YCbCrPositioning',\n  0x0212: 'YCbCrSubSampling',\n  0x0159: 'YClipPathUnits',\n  0x011F: 'YPosition',\n\n  // EXIF\n  0x9202: 'ApertureValue',\n  0xA001: 'ColorSpace',\n  0x9004: 'DateTimeDigitized',\n  0x9003: 'DateTimeOriginal',\n  0x8769: 'Exif IFD',\n  0x9000: 'ExifVersion',\n  0x829A: 'ExposureTime',\n  0xA300: 'FileSource',\n  0x9209: 'Flash',\n  0xA000: 'FlashpixVersion',\n  0x829D: 'FNumber',\n  0xA420: 'ImageUniqueID',\n  0x9208: 'LightSource',\n  0x927C: 'MakerNote',\n  0x9201: 'ShutterSpeedValue',\n  0x9286: 'UserComment',\n\n  // IPTC\n  0x83BB: 'IPTC',\n\n  // ICC\n  0x8773: 'ICC Profile',\n\n  // XMP\n  0x02BC: 'XMP',\n\n  // GDAL\n  0xA480: 'GDAL_METADATA',\n  0xA481: 'GDAL_NODATA',\n\n  // Photoshop\n  0x8649: 'Photoshop',\n\n  // GeoTiff\n  0x830E: 'ModelPixelScale',\n  0x8482: 'ModelTiepoint',\n  0x85D8: 'ModelTransformation',\n  0x87AF: 'GeoKeyDirectory',\n  0x87B0: 'GeoDoubleParams',\n  0x87B1: 'GeoAsciiParams',\n\n  // LERC\n  0xC5F2: 'LercParameters',\n};\n\nexport const fieldTags = {};\nfor (const key in fieldTagNames) {\n  if (fieldTagNames.hasOwnProperty(key)) {\n    fieldTags[fieldTagNames[key]] = parseInt(key, 10);\n  }\n}\n\nexport const fieldTagTypes = {\n  256: 'SHORT',\n  257: 'SHORT',\n  258: 'SHORT',\n  259: 'SHORT',\n  262: 'SHORT',\n  273: 'LONG',\n  274: 'SHORT',\n  277: 'SHORT',\n  278: 'LONG',\n  279: 'LONG',\n  282: 'RATIONAL',\n  283: 'RATIONAL',\n  284: 'SHORT',\n  286: 'SHORT',\n  287: 'RATIONAL',\n  296: 'SHORT',\n  297: 'SHORT',\n  305: 'ASCII',\n  306: 'ASCII',\n  338: 'SHORT',\n  339: 'SHORT',\n  513: 'LONG',\n  514: 'LONG',\n  1024: 'SHORT',\n  1025: 'SHORT',\n  2048: 'SHORT',\n  2049: 'ASCII',\n  3072: 'SHORT',\n  3073: 'ASCII',\n  33550: 'DOUBLE',\n  33922: 'DOUBLE',\n  34665: 'LONG',\n  34735: 'SHORT',\n  34737: 'ASCII',\n  42113: 'ASCII',\n};\n\nexport const arrayFields = [\n  fieldTags.BitsPerSample,\n  fieldTags.ExtraSamples,\n  fieldTags.SampleFormat,\n  fieldTags.StripByteCounts,\n  fieldTags.StripOffsets,\n  fieldTags.StripRowCounts,\n  fieldTags.TileByteCounts,\n  fieldTags.TileOffsets,\n  fieldTags.SubIFDs,\n];\n\nexport const fieldTypeNames = {\n  0x0001: 'BYTE',\n  0x0002: 'ASCII',\n  0x0003: 'SHORT',\n  0x0004: 'LONG',\n  0x0005: 'RATIONAL',\n  0x0006: 'SBYTE',\n  0x0007: 'UNDEFINED',\n  0x0008: 'SSHORT',\n  0x0009: 'SLONG',\n  0x000A: 'SRATIONAL',\n  0x000B: 'FLOAT',\n  0x000C: 'DOUBLE',\n  // IFD offset, suggested by https://owl.phy.queensu.ca/~phil/exiftool/standards.html\n  0x000D: 'IFD',\n  // introduced by BigTIFF\n  0x0010: 'LONG8',\n  0x0011: 'SLONG8',\n  0x0012: 'IFD8',\n};\n\nexport const fieldTypes = {};\nfor (const key in fieldTypeNames) {\n  if (fieldTypeNames.hasOwnProperty(key)) {\n    fieldTypes[fieldTypeNames[key]] = parseInt(key, 10);\n  }\n}\n\nexport const photometricInterpretations = {\n  WhiteIsZero: 0,\n  BlackIsZero: 1,\n  RGB: 2,\n  Palette: 3,\n  TransparencyMask: 4,\n  CMYK: 5,\n  YCbCr: 6,\n\n  CIELab: 8,\n  ICCLab: 9,\n};\n\nexport const ExtraSamplesValues = {\n  Unspecified: 0,\n  Assocalpha: 1,\n  Unassalpha: 2,\n};\n\nexport const LercParameters = {\n  Version: 0,\n  AddCompression: 1,\n};\n\nexport const LercAddCompression = {\n  None: 0,\n  Deflate: 1,\n};\n\nexport const geoKeyNames = {\n  1024: 'GTModelTypeGeoKey',\n  1025: 'GTRasterTypeGeoKey',\n  1026: 'GTCitationGeoKey',\n  2048: 'GeographicTypeGeoKey',\n  2049: 'GeogCitationGeoKey',\n  2050: 'GeogGeodeticDatumGeoKey',\n  2051: 'GeogPrimeMeridianGeoKey',\n  2052: 'GeogLinearUnitsGeoKey',\n  2053: 'GeogLinearUnitSizeGeoKey',\n  2054: 'GeogAngularUnitsGeoKey',\n  2055: 'GeogAngularUnitSizeGeoKey',\n  2056: 'GeogEllipsoidGeoKey',\n  2057: 'GeogSemiMajorAxisGeoKey',\n  2058: 'GeogSemiMinorAxisGeoKey',\n  2059: 'GeogInvFlatteningGeoKey',\n  2060: 'GeogAzimuthUnitsGeoKey',\n  2061: 'GeogPrimeMeridianLongGeoKey',\n  2062: 'GeogTOWGS84GeoKey',\n  3072: 'ProjectedCSTypeGeoKey',\n  3073: 'PCSCitationGeoKey',\n  3074: 'ProjectionGeoKey',\n  3075: 'ProjCoordTransGeoKey',\n  3076: 'ProjLinearUnitsGeoKey',\n  3077: 'ProjLinearUnitSizeGeoKey',\n  3078: 'ProjStdParallel1GeoKey',\n  3079: 'ProjStdParallel2GeoKey',\n  3080: 'ProjNatOriginLongGeoKey',\n  3081: 'ProjNatOriginLatGeoKey',\n  3082: 'ProjFalseEastingGeoKey',\n  3083: 'ProjFalseNorthingGeoKey',\n  3084: 'ProjFalseOriginLongGeoKey',\n  3085: 'ProjFalseOriginLatGeoKey',\n  3086: 'ProjFalseOriginEastingGeoKey',\n  3087: 'ProjFalseOriginNorthingGeoKey',\n  3088: 'ProjCenterLongGeoKey',\n  3089: 'ProjCenterLatGeoKey',\n  3090: 'ProjCenterEastingGeoKey',\n  3091: 'ProjCenterNorthingGeoKey',\n  3092: 'ProjScaleAtNatOriginGeoKey',\n  3093: 'ProjScaleAtCenterGeoKey',\n  3094: 'ProjAzimuthAngleGeoKey',\n  3095: 'ProjStraightVertPoleLongGeoKey',\n  3096: 'ProjRectifiedGridAngleGeoKey',\n  4096: 'VerticalCSTypeGeoKey',\n  4097: 'VerticalCitationGeoKey',\n  4098: 'VerticalDatumGeoKey',\n  4099: 'VerticalUnitsGeoKey',\n};\n\nexport const geoKeys = {};\nfor (const key in geoKeyNames) {\n  if (geoKeyNames.hasOwnProperty(key)) {\n    geoKeys[geoKeyNames[key]] = parseInt(key, 10);\n  }\n}\n","/**\n * A no-op logger\n */\nclass DummyLogger {\n  log() {}\n\n  debug() {}\n\n  info() {}\n\n  warn() {}\n\n  error() {}\n\n  time() {}\n\n  timeEnd() {}\n}\n\nlet LOGGER = new DummyLogger();\n\n/**\n *\n * @param {object} logger the new logger. e.g `console`\n */\nexport function setLogger(logger = new DummyLogger()) {\n  LOGGER = logger;\n}\n\nexport function debug(...args) {\n  return LOGGER.debug(...args);\n}\n\nexport function log(...args) {\n  return LOGGER.log(...args);\n}\n\nexport function info(...args) {\n  return LOGGER.info(...args);\n}\n\nexport function warn(...args) {\n  return LOGGER.warn(...args);\n}\n\nexport function error(...args) {\n  return LOGGER.error(...args);\n}\n\nexport function time(...args) {\n  return LOGGER.time(...args);\n}\n\nexport function timeEnd(...args) {\n  return LOGGER.timeEnd(...args);\n}\n","import { getDecoder } from './compression/index.js';\n\nconst defaultPoolSize = typeof navigator !== 'undefined' ? (navigator.hardwareConcurrency || 2) : 2;\n\n/**\n * @module pool\n */\n\n/**\n * Pool for workers to decode chunks of the images.\n */\nclass Pool {\n  /**\n   * @constructor\n   * @param {Number} [size] The size of the pool. Defaults to the number of CPUs\n   *                      available. When this parameter is `null` or 0, then the\n   *                      decoding will be done in the main thread.\n   * @param {function(): Worker} [createWorker] A function that creates the decoder worker.\n   * Defaults to a worker with all decoders that ship with geotiff.js. The `createWorker()`\n   * function is expected to return a `Worker` compatible with Web Workers. For code that\n   * runs in Node, [web-worker](https://www.npmjs.com/package/web-worker) is a good choice.\n   *\n   * A worker that uses a custom lzw decoder would look like this `my-custom-worker.js` file:\n   * ```js\n   * import { addDecoder, getDecoder } from 'geotiff';\n   * addDecoder(5, () => import ('./my-custom-lzw').then((m) => m.default));\n   * self.addEventListener('message', async (e) => {\n   *   const { id, fileDirectory, buffer } = e.data;\n   *   const decoder = await getDecoder(fileDirectory);\n   *   const decoded = await decoder.decode(fileDirectory, buffer);\n   *   self.postMessage({ decoded, id }, [decoded]);\n   * });\n   * ```\n   * The way the above code is built into a worker by the `createWorker()` function\n   * depends on the used bundler. For most bundlers, something like this will work:\n   * ```js\n   * function createWorker() {\n   *   return new Worker(new URL('./my-custom-worker.js', import.meta.url));\n   * }\n   * ```\n   */\n  constructor(size = defaultPoolSize, createWorker) {\n    this.workers = null;\n    this._awaitingDecoder = null;\n    this.size = size;\n    this.messageId = 0;\n    if (size) {\n      this._awaitingDecoder = createWorker ? Promise.resolve(createWorker) : new Promise((resolve) => {\n        import('./worker/decoder.js').then((module) => {\n          resolve(module.create);\n        });\n      });\n      this._awaitingDecoder.then((create) => {\n        this._awaitingDecoder = null;\n        this.workers = [];\n        for (let i = 0; i < size; i++) {\n          this.workers.push({ worker: create(), idle: true });\n        }\n      });\n    }\n  }\n\n  /**\n   * Decode the given block of bytes with the set compression method.\n   * @param {ArrayBuffer} buffer the array buffer of bytes to decode.\n   * @returns {Promise<ArrayBuffer>} the decoded result as a `Promise`\n   */\n  async decode(fileDirectory, buffer) {\n    if (this._awaitingDecoder) {\n      await this._awaitingDecoder;\n    }\n    return this.size === 0\n      ? getDecoder(fileDirectory).then((decoder) => decoder.decode(fileDirectory, buffer))\n      : new Promise((resolve) => {\n        const worker = this.workers.find((candidate) => candidate.idle)\n          || this.workers[Math.floor(Math.random() * this.size)];\n        worker.idle = false;\n        const id = this.messageId++;\n        const onMessage = (e) => {\n          if (e.data.id === id) {\n            worker.idle = true;\n            resolve(e.data.decoded);\n            worker.worker.removeEventListener('message', onMessage);\n          }\n        };\n        worker.worker.addEventListener('message', onMessage);\n        worker.worker.postMessage({ fileDirectory, buffer, id }, [buffer]);\n      });\n  }\n\n  destroy() {\n    if (this.workers) {\n      this.workers.forEach((worker) => {\n        worker.worker.terminate();\n      });\n      this.workers = null;\n    }\n  }\n}\n\nexport default Pool;\n","function decodeRowAcc(row, stride) {\n  let length = row.length - stride;\n  let offset = 0;\n  do {\n    for (let i = stride; i > 0; i--) {\n      row[offset + stride] += row[offset];\n      offset++;\n    }\n\n    length -= stride;\n  } while (length > 0);\n}\n\nfunction decodeRowFloatingPoint(row, stride, bytesPerSample) {\n  let index = 0;\n  let count = row.length;\n  const wc = count / bytesPerSample;\n\n  while (count > stride) {\n    for (let i = stride; i > 0; --i) {\n      row[index + stride] += row[index];\n      ++index;\n    }\n    count -= stride;\n  }\n\n  const copy = row.slice();\n  for (let i = 0; i < wc; ++i) {\n    for (let b = 0; b < bytesPerSample; ++b) {\n      row[(bytesPerSample * i) + b] = copy[((bytesPerSample - b - 1) * wc) + i];\n    }\n  }\n}\n\nexport function applyPredictor(block, predictor, width, height, bitsPerSample,\n  planarConfiguration) {\n  if (!predictor || predictor === 1) {\n    return block;\n  }\n\n  for (let i = 0; i < bitsPerSample.length; ++i) {\n    if (bitsPerSample[i] % 8 !== 0) {\n      throw new Error('When decoding with predictor, only multiple of 8 bits are supported.');\n    }\n    if (bitsPerSample[i] !== bitsPerSample[0]) {\n      throw new Error('When decoding with predictor, all samples must have the same size.');\n    }\n  }\n\n  const bytesPerSample = bitsPerSample[0] / 8;\n  const stride = planarConfiguration === 2 ? 1 : bitsPerSample.length;\n\n  for (let i = 0; i < height; ++i) {\n    // Last strip will be truncated if height % stripHeight != 0\n    if (i * stride * width * bytesPerSample >= block.byteLength) {\n      break;\n    }\n    let row;\n    if (predictor === 2) { // horizontal prediction\n      switch (bitsPerSample[0]) {\n        case 8:\n          row = new Uint8Array(\n            block, i * stride * width * bytesPerSample, stride * width * bytesPerSample,\n          );\n          break;\n        case 16:\n          row = new Uint16Array(\n            block, i * stride * width * bytesPerSample, stride * width * bytesPerSample / 2,\n          );\n          break;\n        case 32:\n          row = new Uint32Array(\n            block, i * stride * width * bytesPerSample, stride * width * bytesPerSample / 4,\n          );\n          break;\n        default:\n          throw new Error(`Predictor 2 not allowed with ${bitsPerSample[0]} bits per sample.`);\n      }\n      decodeRowAcc(row, stride, bytesPerSample);\n    } else if (predictor === 3) { // horizontal floating point\n      row = new Uint8Array(\n        block, i * stride * width * bytesPerSample, stride * width * bytesPerSample,\n      );\n      decodeRowFloatingPoint(row, stride, bytesPerSample);\n    }\n  }\n  return block;\n}\n","/**\n * @module resample\n */\n\nfunction copyNewSize(array, width, height, samplesPerPixel = 1) {\n  return new (Object.getPrototypeOf(array).constructor)(width * height * samplesPerPixel);\n}\n\n/**\n * Resample the input arrays using nearest neighbor value selection.\n * @param {TypedArray[]} valueArrays The input arrays to resample\n * @param {number} inWidth The width of the input rasters\n * @param {number} inHeight The height of the input rasters\n * @param {number} outWidth The desired width of the output rasters\n * @param {number} outHeight The desired height of the output rasters\n * @returns {TypedArray[]} The resampled rasters\n */\nexport function resampleNearest(valueArrays, inWidth, inHeight, outWidth, outHeight) {\n  const relX = inWidth / outWidth;\n  const relY = inHeight / outHeight;\n  return valueArrays.map((array) => {\n    const newArray = copyNewSize(array, outWidth, outHeight);\n    for (let y = 0; y < outHeight; ++y) {\n      const cy = Math.min(Math.round(relY * y), inHeight - 1);\n      for (let x = 0; x < outWidth; ++x) {\n        const cx = Math.min(Math.round(relX * x), inWidth - 1);\n        const value = array[(cy * inWidth) + cx];\n        newArray[(y * outWidth) + x] = value;\n      }\n    }\n    return newArray;\n  });\n}\n\n// simple linear interpolation, code from:\n// https://en.wikipedia.org/wiki/Linear_interpolation#Programming_language_support\nfunction lerp(v0, v1, t) {\n  return ((1 - t) * v0) + (t * v1);\n}\n\n/**\n * Resample the input arrays using bilinear interpolation.\n * @param {TypedArray[]} valueArrays The input arrays to resample\n * @param {number} inWidth The width of the input rasters\n * @param {number} inHeight The height of the input rasters\n * @param {number} outWidth The desired width of the output rasters\n * @param {number} outHeight The desired height of the output rasters\n * @returns {TypedArray[]} The resampled rasters\n */\nexport function resampleBilinear(valueArrays, inWidth, inHeight, outWidth, outHeight) {\n  const relX = inWidth / outWidth;\n  const relY = inHeight / outHeight;\n\n  return valueArrays.map((array) => {\n    const newArray = copyNewSize(array, outWidth, outHeight);\n    for (let y = 0; y < outHeight; ++y) {\n      const rawY = relY * y;\n\n      const yl = Math.floor(rawY);\n      const yh = Math.min(Math.ceil(rawY), (inHeight - 1));\n\n      for (let x = 0; x < outWidth; ++x) {\n        const rawX = relX * x;\n        const tx = rawX % 1;\n\n        const xl = Math.floor(rawX);\n        const xh = Math.min(Math.ceil(rawX), (inWidth - 1));\n\n        const ll = array[(yl * inWidth) + xl];\n        const hl = array[(yl * inWidth) + xh];\n        const lh = array[(yh * inWidth) + xl];\n        const hh = array[(yh * inWidth) + xh];\n\n        const value = lerp(\n          lerp(ll, hl, tx),\n          lerp(lh, hh, tx),\n          rawY % 1,\n        );\n        newArray[(y * outWidth) + x] = value;\n      }\n    }\n    return newArray;\n  });\n}\n\n/**\n * Resample the input arrays using the selected resampling method.\n * @param {TypedArray[]} valueArrays The input arrays to resample\n * @param {number} inWidth The width of the input rasters\n * @param {number} inHeight The height of the input rasters\n * @param {number} outWidth The desired width of the output rasters\n * @param {number} outHeight The desired height of the output rasters\n * @param {string} [method = 'nearest'] The desired resampling method\n * @returns {TypedArray[]} The resampled rasters\n */\nexport function resample(valueArrays, inWidth, inHeight, outWidth, outHeight, method = 'nearest') {\n  switch (method.toLowerCase()) {\n    case 'nearest':\n      return resampleNearest(valueArrays, inWidth, inHeight, outWidth, outHeight);\n    case 'bilinear':\n    case 'linear':\n      return resampleBilinear(valueArrays, inWidth, inHeight, outWidth, outHeight);\n    default:\n      throw new Error(`Unsupported resampling method: '${method}'`);\n  }\n}\n\n/**\n * Resample the pixel interleaved input array using nearest neighbor value selection.\n * @param {TypedArray} valueArrays The input arrays to resample\n * @param {number} inWidth The width of the input rasters\n * @param {number} inHeight The height of the input rasters\n * @param {number} outWidth The desired width of the output rasters\n * @param {number} outHeight The desired height of the output rasters\n * @param {number} samples The number of samples per pixel for pixel\n *                         interleaved data\n * @returns {TypedArray} The resampled raster\n */\nexport function resampleNearestInterleaved(\n  valueArray, inWidth, inHeight, outWidth, outHeight, samples) {\n  const relX = inWidth / outWidth;\n  const relY = inHeight / outHeight;\n\n  const newArray = copyNewSize(valueArray, outWidth, outHeight, samples);\n  for (let y = 0; y < outHeight; ++y) {\n    const cy = Math.min(Math.round(relY * y), inHeight - 1);\n    for (let x = 0; x < outWidth; ++x) {\n      const cx = Math.min(Math.round(relX * x), inWidth - 1);\n      for (let i = 0; i < samples; ++i) {\n        const value = valueArray[(cy * inWidth * samples) + (cx * samples) + i];\n        newArray[(y * outWidth * samples) + (x * samples) + i] = value;\n      }\n    }\n  }\n  return newArray;\n}\n\n/**\n * Resample the pixel interleaved input array using bilinear interpolation.\n * @param {TypedArray} valueArrays The input arrays to resample\n * @param {number} inWidth The width of the input rasters\n * @param {number} inHeight The height of the input rasters\n * @param {number} outWidth The desired width of the output rasters\n * @param {number} outHeight The desired height of the output rasters\n * @param {number} samples The number of samples per pixel for pixel\n *                         interleaved data\n * @returns {TypedArray} The resampled raster\n */\nexport function resampleBilinearInterleaved(\n  valueArray, inWidth, inHeight, outWidth, outHeight, samples) {\n  const relX = inWidth / outWidth;\n  const relY = inHeight / outHeight;\n  const newArray = copyNewSize(valueArray, outWidth, outHeight, samples);\n  for (let y = 0; y < outHeight; ++y) {\n    const rawY = relY * y;\n\n    const yl = Math.floor(rawY);\n    const yh = Math.min(Math.ceil(rawY), (inHeight - 1));\n\n    for (let x = 0; x < outWidth; ++x) {\n      const rawX = relX * x;\n      const tx = rawX % 1;\n\n      const xl = Math.floor(rawX);\n      const xh = Math.min(Math.ceil(rawX), (inWidth - 1));\n\n      for (let i = 0; i < samples; ++i) {\n        const ll = valueArray[(yl * inWidth * samples) + (xl * samples) + i];\n        const hl = valueArray[(yl * inWidth * samples) + (xh * samples) + i];\n        const lh = valueArray[(yh * inWidth * samples) + (xl * samples) + i];\n        const hh = valueArray[(yh * inWidth * samples) + (xh * samples) + i];\n\n        const value = lerp(\n          lerp(ll, hl, tx),\n          lerp(lh, hh, tx),\n          rawY % 1,\n        );\n        newArray[(y * outWidth * samples) + (x * samples) + i] = value;\n      }\n    }\n  }\n  return newArray;\n}\n\n/**\n * Resample the pixel interleaved input array using the selected resampling method.\n * @param {TypedArray} valueArray The input array to resample\n * @param {number} inWidth The width of the input rasters\n * @param {number} inHeight The height of the input rasters\n * @param {number} outWidth The desired width of the output rasters\n * @param {number} outHeight The desired height of the output rasters\n * @param {number} samples The number of samples per pixel for pixel\n *                                 interleaved data\n * @param {string} [method = 'nearest'] The desired resampling method\n * @returns {TypedArray} The resampled rasters\n */\nexport function resampleInterleaved(valueArray, inWidth, inHeight, outWidth, outHeight, samples, method = 'nearest') {\n  switch (method.toLowerCase()) {\n    case 'nearest':\n      return resampleNearestInterleaved(\n        valueArray, inWidth, inHeight, outWidth, outHeight, samples,\n      );\n    case 'bilinear':\n    case 'linear':\n      return resampleBilinearInterleaved(\n        valueArray, inWidth, inHeight, outWidth, outHeight, samples,\n      );\n    default:\n      throw new Error(`Unsupported resampling method: '${method}'`);\n  }\n}\n","export function fromWhiteIsZero(raster, max) {\n  const { width, height } = raster;\n  const rgbRaster = new Uint8Array(width * height * 3);\n  let value;\n  for (let i = 0, j = 0; i < raster.length; ++i, j += 3) {\n    value = 256 - (raster[i] / max * 256);\n    rgbRaster[j] = value;\n    rgbRaster[j + 1] = value;\n    rgbRaster[j + 2] = value;\n  }\n  return rgbRaster;\n}\n\nexport function fromBlackIsZero(raster, max) {\n  const { width, height } = raster;\n  const rgbRaster = new Uint8Array(width * height * 3);\n  let value;\n  for (let i = 0, j = 0; i < raster.length; ++i, j += 3) {\n    value = raster[i] / max * 256;\n    rgbRaster[j] = value;\n    rgbRaster[j + 1] = value;\n    rgbRaster[j + 2] = value;\n  }\n  return rgbRaster;\n}\n\nexport function fromPalette(raster, colorMap) {\n  const { width, height } = raster;\n  const rgbRaster = new Uint8Array(width * height * 3);\n  const greenOffset = colorMap.length / 3;\n  const blueOffset = colorMap.length / 3 * 2;\n  for (let i = 0, j = 0; i < raster.length; ++i, j += 3) {\n    const mapIndex = raster[i];\n    rgbRaster[j] = colorMap[mapIndex] / 65536 * 256;\n    rgbRaster[j + 1] = colorMap[mapIndex + greenOffset] / 65536 * 256;\n    rgbRaster[j + 2] = colorMap[mapIndex + blueOffset] / 65536 * 256;\n  }\n  return rgbRaster;\n}\n\nexport function fromCMYK(cmykRaster) {\n  const { width, height } = cmykRaster;\n  const rgbRaster = new Uint8Array(width * height * 3);\n  for (let i = 0, j = 0; i < cmykRaster.length; i += 4, j += 3) {\n    const c = cmykRaster[i];\n    const m = cmykRaster[i + 1];\n    const y = cmykRaster[i + 2];\n    const k = cmykRaster[i + 3];\n\n    rgbRaster[j] = 255 * ((255 - c) / 256) * ((255 - k) / 256);\n    rgbRaster[j + 1] = 255 * ((255 - m) / 256) * ((255 - k) / 256);\n    rgbRaster[j + 2] = 255 * ((255 - y) / 256) * ((255 - k) / 256);\n  }\n  return rgbRaster;\n}\n\nexport function fromYCbCr(yCbCrRaster) {\n  const { width, height } = yCbCrRaster;\n  const rgbRaster = new Uint8ClampedArray(width * height * 3);\n  for (let i = 0, j = 0; i < yCbCrRaster.length; i += 3, j += 3) {\n    const y = yCbCrRaster[i];\n    const cb = yCbCrRaster[i + 1];\n    const cr = yCbCrRaster[i + 2];\n\n    rgbRaster[j] = (y + (1.40200 * (cr - 0x80)));\n    rgbRaster[j + 1] = (y - (0.34414 * (cb - 0x80)) - (0.71414 * (cr - 0x80)));\n    rgbRaster[j + 2] = (y + (1.77200 * (cb - 0x80)));\n  }\n  return rgbRaster;\n}\n\nconst Xn = 0.95047;\nconst Yn = 1.00000;\nconst Zn = 1.08883;\n\n// from https://github.com/antimatter15/rgb-lab/blob/master/color.js\n\nexport function fromCIELab(cieLabRaster) {\n  const { width, height } = cieLabRaster;\n  const rgbRaster = new Uint8Array(width * height * 3);\n\n  for (let i = 0, j = 0; i < cieLabRaster.length; i += 3, j += 3) {\n    const L = cieLabRaster[i + 0];\n    const a_ = cieLabRaster[i + 1] << 24 >> 24; // conversion from uint8 to int8\n    const b_ = cieLabRaster[i + 2] << 24 >> 24; // same\n\n    let y = (L + 16) / 116;\n    let x = (a_ / 500) + y;\n    let z = y - (b_ / 200);\n    let r;\n    let g;\n    let b;\n\n    x = Xn * ((x * x * x > 0.008856) ? x * x * x : (x - (16 / 116)) / 7.787);\n    y = Yn * ((y * y * y > 0.008856) ? y * y * y : (y - (16 / 116)) / 7.787);\n    z = Zn * ((z * z * z > 0.008856) ? z * z * z : (z - (16 / 116)) / 7.787);\n\n    r = (x * 3.2406) + (y * -1.5372) + (z * -0.4986);\n    g = (x * -0.9689) + (y * 1.8758) + (z * 0.0415);\n    b = (x * 0.0557) + (y * -0.2040) + (z * 1.0570);\n\n    r = (r > 0.0031308) ? ((1.055 * (r ** (1 / 2.4))) - 0.055) : 12.92 * r;\n    g = (g > 0.0031308) ? ((1.055 * (g ** (1 / 2.4))) - 0.055) : 12.92 * g;\n    b = (b > 0.0031308) ? ((1.055 * (b ** (1 / 2.4))) - 0.055) : 12.92 * b;\n\n    rgbRaster[j] = Math.max(0, Math.min(1, r)) * 255;\n    rgbRaster[j + 1] = Math.max(0, Math.min(1, g)) * 255;\n    rgbRaster[j + 2] = Math.max(0, Math.min(1, b)) * 255;\n  }\n  return rgbRaster;\n}\n","import { BaseSource } from './basesource.js';\nimport { AbortError } from '../utils.js';\n\nclass ArrayBufferSource extends BaseSource {\n  constructor(arrayBuffer) {\n    super();\n    this.arrayBuffer = arrayBuffer;\n  }\n\n  fetchSlice(slice, signal) {\n    if (signal && signal.aborted) {\n      throw new AbortError('Request aborted');\n    }\n    return this.arrayBuffer.slice(slice.offset, slice.offset + slice.length);\n  }\n}\n\nexport function makeBufferSource(arrayBuffer) {\n  return new ArrayBufferSource(arrayBuffer);\n}\n","/**\n * @typedef Slice\n * @property {number} offset\n * @property {number} length\n */\n\nexport class BaseSource {\n  /**\n   *\n   * @param {Slice[]} slices\n   * @returns {ArrayBuffer[]}\n   */\n  async fetch(slices, signal = undefined) {\n    return Promise.all(\n      slices.map((slice) => this.fetchSlice(slice, signal)),\n    );\n  }\n\n  /**\n   *\n   * @param {Slice} slice\n   * @returns {ArrayBuffer}\n   */\n  async fetchSlice(slice) {\n    throw new Error(`fetching of slice ${slice} not possible, not implemented`);\n  }\n\n  /**\n   * Returns the filesize if already determined and null otherwise\n   */\n  get fileSize() {\n    return null;\n  }\n\n  async close() {\n    // no-op by default\n  }\n}\n","import QuickLRU from 'quick-lru';\nimport { BaseSource } from './basesource.js';\nimport { AbortError, AggregateError, wait, zip } from '../utils.js';\n\nclass Block {\n  /**\n   *\n   * @param {number} offset\n   * @param {number} length\n   * @param {ArrayBuffer} [data]\n   */\n  constructor(offset, length, data = null) {\n    this.offset = offset;\n    this.length = length;\n    this.data = data;\n  }\n\n  /**\n   * @returns {number} the top byte border\n   */\n  get top() {\n    return this.offset + this.length;\n  }\n}\n\nclass BlockGroup {\n  /**\n   *\n   * @param {number} offset\n   * @param {number} length\n   * @param {number[]} blockIds\n   */\n  constructor(offset, length, blockIds) {\n    this.offset = offset;\n    this.length = length;\n    this.blockIds = blockIds;\n  }\n}\n\nexport class BlockedSource extends BaseSource {\n  /**\n   *\n   * @param {BaseSource} source The underlying source that shall be blocked and cached\n   * @param {object} options\n   * @param {number} [options.blockSize]\n   * @param {number} [options.cacheSize]\n   */\n  constructor(source, { blockSize = 65536, cacheSize = 100 } = {}) {\n    super();\n    this.source = source;\n    this.blockSize = blockSize;\n\n    this.blockCache = new QuickLRU({\n      maxSize: cacheSize,\n      onEviction: (blockId, block) => {\n        this.evictedBlocks.set(blockId, block);\n      },\n    });\n\n    /** @type {Map<number, Block>} */\n    this.evictedBlocks = new Map();\n\n    // mapping blockId -> Block instance\n    this.blockRequests = new Map();\n\n    // set of blockIds missing for the current requests\n    this.blockIdsToFetch = new Set();\n\n    this.abortedBlockIds = new Set();\n  }\n\n  get fileSize() {\n    return this.source.fileSize;\n  }\n\n  /**\n   *\n   * @param {import(\"./basesource\").Slice[]} slices\n   */\n  async fetch(slices, signal) {\n    const blockRequests = [];\n    const missingBlockIds = [];\n    const allBlockIds = [];\n    this.evictedBlocks.clear();\n\n    for (const { offset, length } of slices) {\n      let top = offset + length;\n\n      const { fileSize } = this;\n      if (fileSize !== null) {\n        top = Math.min(top, fileSize);\n      }\n\n      const firstBlockOffset = Math.floor(offset / this.blockSize) * this.blockSize;\n\n      for (let current = firstBlockOffset; current < top; current += this.blockSize) {\n        const blockId = Math.floor(current / this.blockSize);\n        if (!this.blockCache.has(blockId) && !this.blockRequests.has(blockId)) {\n          this.blockIdsToFetch.add(blockId);\n          missingBlockIds.push(blockId);\n        }\n        if (this.blockRequests.has(blockId)) {\n          blockRequests.push(this.blockRequests.get(blockId));\n        }\n        allBlockIds.push(blockId);\n      }\n    }\n\n    // allow additional block requests to accumulate\n    await wait();\n    this.fetchBlocks(signal);\n\n    // Gather all of the new requests that this fetch call is contributing to `fetch`.\n    const missingRequests = [];\n    for (const blockId of missingBlockIds) {\n      // The requested missing block could already be in the cache\n      // instead of having its request still be outstanding.\n      if (this.blockRequests.has(blockId)) {\n        missingRequests.push(this.blockRequests.get(blockId));\n      }\n    }\n\n    // Actually await all pending requests that are needed for this `fetch`.\n    await Promise.allSettled(blockRequests);\n    await Promise.allSettled(missingRequests);\n\n    // Perform retries if a block was interrupted by a previous signal\n    const abortedBlockRequests = [];\n    const abortedBlockIds = allBlockIds\n      .filter((id) => this.abortedBlockIds.has(id) || !this.blockCache.has(id));\n    abortedBlockIds.forEach((id) => this.blockIdsToFetch.add(id));\n    // start the retry of some blocks if required\n    if (abortedBlockIds.length > 0 && signal && !signal.aborted) {\n      this.fetchBlocks(null);\n      for (const blockId of abortedBlockIds) {\n        const block = this.blockRequests.get(blockId);\n        if (!block) {\n          throw new Error(`Block ${blockId} is not in the block requests`);\n        }\n        abortedBlockRequests.push(block);\n      }\n      await Promise.allSettled(abortedBlockRequests);\n    }\n\n    // throw an  abort error\n    if (signal && signal.aborted) {\n      throw new AbortError('Request was aborted');\n    }\n\n    const blocks = allBlockIds.map((id) => this.blockCache.get(id) || this.evictedBlocks.get(id));\n    const failedBlocks = blocks.filter((i) => !i);\n    if (failedBlocks.length) {\n      throw new AggregateError(failedBlocks, 'Request failed');\n    }\n\n    // create a final Map, with all required blocks for this request to satisfy\n    const requiredBlocks = new Map(zip(allBlockIds, blocks));\n\n    // TODO: satisfy each slice\n    return this.readSliceData(slices, requiredBlocks);\n  }\n\n  /**\n   *\n   * @param {AbortSignal} signal\n   */\n  fetchBlocks(signal) {\n    // check if we still need to\n    if (this.blockIdsToFetch.size > 0) {\n      const groups = this.groupBlocks(this.blockIdsToFetch);\n\n      // start requesting slices of data\n      const groupRequests = this.source.fetch(groups, signal);\n\n      for (let groupIndex = 0; groupIndex < groups.length; ++groupIndex) {\n        const group = groups[groupIndex];\n\n        for (const blockId of group.blockIds) {\n          // make an async IIFE for each block\n          this.blockRequests.set(blockId, (async () => {\n            try {\n              const response = (await groupRequests)[groupIndex];\n              const blockOffset = blockId * this.blockSize;\n              const o = blockOffset - response.offset;\n              const t = Math.min(o + this.blockSize, response.data.byteLength);\n              const data = response.data.slice(o, t);\n              const block = new Block(\n                blockOffset,\n                data.byteLength,\n                data,\n                blockId,\n              );\n              this.blockCache.set(blockId, block);\n              this.abortedBlockIds.delete(blockId);\n            } catch (err) {\n              if (err.name === 'AbortError') {\n                // store the signal here, we need it to determine later if an\n                // error was caused by this signal\n                err.signal = signal;\n                this.blockCache.delete(blockId);\n                this.abortedBlockIds.add(blockId);\n              } else {\n                throw err;\n              }\n            } finally {\n              this.blockRequests.delete(blockId);\n            }\n          })());\n        }\n      }\n      this.blockIdsToFetch.clear();\n    }\n  }\n\n  /**\n   *\n   * @param {Set} blockIds\n   * @returns {BlockGroup[]}\n   */\n  groupBlocks(blockIds) {\n    const sortedBlockIds = Array.from(blockIds).sort((a, b) => a - b);\n    if (sortedBlockIds.length === 0) {\n      return [];\n    }\n    let current = [];\n    let lastBlockId = null;\n    const groups = [];\n\n    for (const blockId of sortedBlockIds) {\n      if (lastBlockId === null || lastBlockId + 1 === blockId) {\n        current.push(blockId);\n        lastBlockId = blockId;\n      } else {\n        groups.push(new BlockGroup(\n          current[0] * this.blockSize,\n          current.length * this.blockSize,\n          current,\n        ));\n        current = [blockId];\n        lastBlockId = blockId;\n      }\n    }\n\n    groups.push(new BlockGroup(\n      current[0] * this.blockSize,\n      current.length * this.blockSize,\n      current,\n    ));\n\n    return groups;\n  }\n\n  /**\n   *\n   * @param {import(\"./basesource\").Slice[]} slices\n   * @param {Map} blocks\n   */\n  readSliceData(slices, blocks) {\n    return slices.map((slice) => {\n      let top = slice.offset + slice.length;\n      if (this.fileSize !== null) {\n        top = Math.min(this.fileSize, top);\n      }\n      const blockIdLow = Math.floor(slice.offset / this.blockSize);\n      const blockIdHigh = Math.floor(top / this.blockSize);\n      const sliceData = new ArrayBuffer(slice.length);\n      const sliceView = new Uint8Array(sliceData);\n\n      for (let blockId = blockIdLow; blockId <= blockIdHigh; ++blockId) {\n        const block = blocks.get(blockId);\n        const delta = block.offset - slice.offset;\n        const topDelta = block.top - top;\n        let blockInnerOffset = 0;\n        let rangeInnerOffset = 0;\n        let usedBlockLength;\n\n        if (delta < 0) {\n          blockInnerOffset = -delta;\n        } else if (delta > 0) {\n          rangeInnerOffset = delta;\n        }\n\n        if (topDelta < 0) {\n          usedBlockLength = block.length - blockInnerOffset;\n        } else {\n          usedBlockLength = top - block.offset - blockInnerOffset;\n        }\n\n        const blockView = new Uint8Array(block.data, blockInnerOffset, usedBlockLength);\n        sliceView.set(blockView, rangeInnerOffset);\n      }\n\n      return sliceData;\n    });\n  }\n}\n","export class BaseResponse {\n  /**\n   * Returns whether the response has an ok'ish status code\n   */\n  get ok() {\n    return this.status >= 200 && this.status <= 299;\n  }\n\n  /**\n   * Returns the status code of the response\n   */\n  get status() {\n    throw new Error('not implemented');\n  }\n\n  /**\n   * Returns the value of the specified header\n   * @param {string} headerName the header name\n   * @returns {string} the header value\n   */\n  getHeader(headerName) { // eslint-disable-line no-unused-vars\n    throw new Error('not implemented');\n  }\n\n  /**\n   * @returns {ArrayBuffer} the response data of the request\n   */\n  async getData() {\n    throw new Error('not implemented');\n  }\n}\n\nexport class BaseClient {\n  constructor(url) {\n    this.url = url;\n  }\n\n  /**\n   * Send a request with the options\n   * @param {object} [options]\n   */\n  async request({ headers, credentials, signal } = {}) { // eslint-disable-line no-unused-vars\n    throw new Error('request is not implemented');\n  }\n}\n","import { BaseClient, BaseResponse } from './base.js';\n\nclass FetchResponse extends BaseResponse {\n  /**\n   * BaseResponse facade for fetch API Response\n   * @param {Response} response\n   */\n  constructor(response) {\n    super();\n    this.response = response;\n  }\n\n  get status() {\n    return this.response.status;\n  }\n\n  getHeader(name) {\n    return this.response.headers.get(name);\n  }\n\n  async getData() {\n    const data = this.response.arrayBuffer\n      ? await this.response.arrayBuffer()\n      : (await this.response.buffer()).buffer;\n    return data;\n  }\n}\n\nexport class FetchClient extends BaseClient {\n  constructor(url, credentials) {\n    super(url);\n    this.credentials = credentials;\n  }\n\n  async request({ headers, credentials, signal } = {}) {\n    const response = await fetch(this.url, {\n      headers, credentials, signal,\n    });\n    return new FetchResponse(response);\n  }\n}\n","import http from 'http';\nimport https from 'https';\nimport urlMod from 'url';\n\nimport { BaseClient, BaseResponse } from './base.js';\nimport { AbortError } from '../../utils.js';\n\nclass HttpResponse extends BaseResponse {\n  /**\n   * BaseResponse facade for node HTTP/HTTPS API Response\n   * @param {http.ServerResponse} response\n   */\n  constructor(response, dataPromise) {\n    super();\n    this.response = response;\n    this.dataPromise = dataPromise;\n  }\n\n  get status() {\n    return this.response.statusCode;\n  }\n\n  getHeader(name) {\n    return this.response.headers[name];\n  }\n\n  async getData() {\n    const data = await this.dataPromise;\n    return data;\n  }\n}\n\nexport class HttpClient extends BaseClient {\n  constructor(url) {\n    super(url);\n    this.parsedUrl = urlMod.parse(this.url);\n    this.httpApi = (this.parsedUrl.protocol === 'http:' ? http : https);\n  }\n\n  constructRequest(headers, signal) {\n    return new Promise((resolve, reject) => {\n      const request = this.httpApi.get(\n        {\n          ...this.parsedUrl,\n          headers,\n        },\n        (response) => {\n          const dataPromise = new Promise((resolveData) => {\n            const chunks = [];\n\n            // collect chunks\n            response.on('data', (chunk) => {\n              chunks.push(chunk);\n            });\n\n            // concatenate all chunks and resolve the promise with the resulting buffer\n            response.on('end', () => {\n              const data = Buffer.concat(chunks).buffer;\n              resolveData(data);\n            });\n            response.on('error', reject);\n          });\n          resolve(new HttpResponse(response, dataPromise));\n        },\n      );\n      request.on('error', reject);\n\n      if (signal) {\n        if (signal.aborted) {\n          request.destroy(new AbortError('Request aborted'));\n        }\n        signal.addEventListener('abort', () => request.destroy(new AbortError('Request aborted')));\n      }\n    });\n  }\n\n  async request({ headers, signal } = {}) {\n    const response = await this.constructRequest(headers, signal);\n    return response;\n  }\n}\n","import { BaseClient, BaseResponse } from './base.js';\nimport { AbortError } from '../../utils.js';\n\nclass XHRResponse extends BaseResponse {\n  /**\n   * BaseResponse facade for XMLHttpRequest\n   * @param {XMLHttpRequest} xhr\n   * @param {ArrayBuffer} data\n   */\n  constructor(xhr, data) {\n    super();\n    this.xhr = xhr;\n    this.data = data;\n  }\n\n  get status() {\n    return this.xhr.status;\n  }\n\n  getHeader(name) {\n    return this.xhr.getResponseHeader(name);\n  }\n\n  async getData() {\n    return this.data;\n  }\n}\n\nexport class XHRClient extends BaseClient {\n  constructRequest(headers, signal) {\n    return new Promise((resolve, reject) => {\n      const xhr = new XMLHttpRequest();\n      xhr.open('GET', this.url);\n      xhr.responseType = 'arraybuffer';\n      for (const [key, value] of Object.entries(headers)) {\n        xhr.setRequestHeader(key, value);\n      }\n\n      // hook signals\n      xhr.onload = () => {\n        const data = xhr.response;\n        resolve(new XHRResponse(xhr, data));\n      };\n      xhr.onerror = reject;\n      xhr.onabort = () => reject(new AbortError('Request aborted'));\n      xhr.send();\n\n      if (signal) {\n        if (signal.aborted) {\n          xhr.abort();\n        }\n        signal.addEventListener('abort', () => xhr.abort());\n      }\n    });\n  }\n\n  async request({ headers, signal } = {}) {\n    const response = await this.constructRequest(headers, signal);\n    return response;\n  }\n}\n","import fs from 'fs';\nimport { BaseSource } from './basesource.js';\n\nfunction closeAsync(fd) {\n  return new Promise((resolve, reject) => {\n    fs.close(fd, (err) => {\n      if (err) {\n        reject(err);\n      } else {\n        resolve();\n      }\n    });\n  });\n}\n\nfunction openAsync(path, flags, mode = undefined) {\n  return new Promise((resolve, reject) => {\n    fs.open(path, flags, mode, (err, fd) => {\n      if (err) {\n        reject(err);\n      } else {\n        resolve(fd);\n      }\n    });\n  });\n}\n\nfunction readAsync(...args) {\n  return new Promise((resolve, reject) => {\n    fs.read(...args, (err, bytesRead, buffer) => {\n      if (err) {\n        reject(err);\n      } else {\n        resolve({ bytesRead, buffer });\n      }\n    });\n  });\n}\n\nclass FileSource extends BaseSource {\n  constructor(path) {\n    super();\n    this.path = path;\n    this.openRequest = openAsync(path, 'r');\n  }\n\n  async fetchSlice(slice) {\n    // TODO: use `signal`\n    const fd = await this.openRequest;\n    const { buffer } = await readAsync(\n      fd,\n      Buffer.alloc(slice.length),\n      0,\n      slice.length,\n      slice.offset,\n    );\n    return buffer.buffer;\n  }\n\n  async close() {\n    const fd = await this.openRequest;\n    await closeAsync(fd);\n  }\n}\n\nexport function makeFileSource(path) {\n  return new FileSource(path);\n}\n","import { BaseSource } from './basesource.js';\n\nclass FileReaderSource extends BaseSource {\n  constructor(file) {\n    super();\n    this.file = file;\n  }\n\n  async fetchSlice(slice, signal) {\n    return new Promise((resolve, reject) => {\n      const blob = this.file.slice(slice.offset, slice.offset + slice.length);\n      const reader = new FileReader();\n      reader.onload = (event) => resolve(event.target.result);\n      reader.onerror = reject;\n      reader.onabort = reject;\n      reader.readAsArrayBuffer(blob);\n\n      if (signal) {\n        signal.addEventListener('abort', () => reader.abort());\n      }\n    });\n  }\n}\n\n/**\n * Create a new source from a given file/blob.\n * @param {Blob} file The file or blob to read from.\n * @returns The constructed source\n */\nexport function makeFileReaderSource(file) {\n  return new FileReaderSource(file);\n}\n","const CRLFCRLF = '\\r\\n\\r\\n';\n\n/*\n * Shim for 'Object.fromEntries'\n */\nfunction itemsToObject(items) {\n  if (typeof Object.fromEntries !== 'undefined') {\n    return Object.fromEntries(items);\n  }\n  const obj = {};\n  for (const [key, value] of items) {\n    obj[key.toLowerCase()] = value;\n  }\n  return obj;\n}\n\n/**\n * Parse HTTP headers from a given string.\n * @param {String} text the text to parse the headers from\n * @returns {Object} the parsed headers with lowercase keys\n */\nfunction parseHeaders(text) {\n  const items = text\n    .split('\\r\\n')\n    .map((line) => {\n      const kv = line.split(':').map((str) => str.trim());\n      kv[0] = kv[0].toLowerCase();\n      return kv;\n    });\n\n  return itemsToObject(items);\n}\n\n/**\n * Parse a 'Content-Type' header value to the content-type and parameters\n * @param {String} rawContentType the raw string to parse from\n * @returns {Object} the parsed content type with the fields: type and params\n */\nexport function parseContentType(rawContentType) {\n  const [type, ...rawParams] = rawContentType.split(';').map((s) => s.trim());\n  const paramsItems = rawParams.map((param) => param.split('='));\n  return { type, params: itemsToObject(paramsItems) };\n}\n\n/**\n * Parse a 'Content-Range' header value to its start, end, and total parts\n * @param {String} rawContentRange the raw string to parse from\n * @returns {Object} the parsed parts\n */\nexport function parseContentRange(rawContentRange) {\n  let start;\n  let end;\n  let total;\n\n  if (rawContentRange) {\n    [, start, end, total] = rawContentRange.match(/bytes (\\d+)-(\\d+)\\/(\\d+)/);\n    start = parseInt(start, 10);\n    end = parseInt(end, 10);\n    total = parseInt(total, 10);\n  }\n\n  return { start, end, total };\n}\n\n/**\n * Parses a list of byteranges from the given 'multipart/byteranges' HTTP response.\n * Each item in the list has the following properties:\n * - headers: the HTTP headers\n * - data: the sliced ArrayBuffer for that specific part\n * - offset: the offset of the byterange within its originating file\n * - length: the length of the byterange\n * @param {ArrayBuffer} responseArrayBuffer the response to be parsed and split\n * @param {String} boundary the boundary string used to split the sections\n * @returns {Object[]} the parsed byteranges\n */\nexport function parseByteRanges(responseArrayBuffer, boundary) {\n  let offset = null;\n  const decoder = new TextDecoder('ascii');\n  const out = [];\n\n  const startBoundary = `--${boundary}`;\n  const endBoundary = `${startBoundary}--`;\n\n  // search for the initial boundary, may be offset by some bytes\n  // TODO: more efficient to check for `--` in bytes directly\n  for (let i = 0; i < 10; ++i) {\n    const text = decoder.decode(\n      new Uint8Array(responseArrayBuffer, i, startBoundary.length),\n    );\n    if (text === startBoundary) {\n      offset = i;\n    }\n  }\n\n  if (offset === null) {\n    throw new Error('Could not find initial boundary');\n  }\n\n  while (offset < responseArrayBuffer.byteLength) {\n    const text = decoder.decode(\n      new Uint8Array(responseArrayBuffer, offset,\n        Math.min(startBoundary.length + 1024, responseArrayBuffer.byteLength - offset),\n      ),\n    );\n\n    // break if we arrived at the end\n    if (text.length === 0 || text.startsWith(endBoundary)) {\n      break;\n    }\n\n    // assert that we are actually dealing with a byterange and are at the correct offset\n    if (!text.startsWith(startBoundary)) {\n      throw new Error('Part does not start with boundary');\n    }\n\n    // get a substring from where we read the headers\n    const innerText = text.substr(startBoundary.length + 2);\n\n    if (innerText.length === 0) {\n      break;\n    }\n\n    // find the double linebreak that denotes the end of the headers\n    const endOfHeaders = innerText.indexOf(CRLFCRLF);\n\n    // parse the headers to get the content range size\n    const headers = parseHeaders(innerText.substr(0, endOfHeaders));\n    const { start, end, total } = parseContentRange(headers['content-range']);\n\n    // calculate the length of the slice and the next offset\n    const startOfData = offset + startBoundary.length + endOfHeaders + CRLFCRLF.length;\n    const length = parseInt(end, 10) + 1 - parseInt(start, 10);\n    out.push({\n      headers,\n      data: responseArrayBuffer.slice(startOfData, startOfData + length),\n      offset: start,\n      length,\n      fileSize: total,\n    });\n\n    offset = startOfData + length + 4;\n  }\n\n  return out;\n}\n","import { parseByteRanges, parseContentRange, parseContentType } from './httputils.js';\nimport { BaseSource } from './basesource.js';\nimport { BlockedSource } from './blockedsource.js';\n\nimport { FetchClient } from './client/fetch.js';\nimport { XHRClient } from './client/xhr.js';\nimport { HttpClient } from './client/http.js';\n\nclass RemoteSource extends BaseSource {\n  /**\n   *\n   * @param {BaseClient} client\n   * @param {object} headers\n   * @param {numbers} maxRanges\n   * @param {boolean} allowFullFile\n   */\n  constructor(client, headers, maxRanges, allowFullFile) {\n    super();\n    this.client = client;\n    this.headers = headers;\n    this.maxRanges = maxRanges;\n    this.allowFullFile = allowFullFile;\n    this._fileSize = null;\n  }\n\n  /**\n   *\n   * @param {Slice[]} slices\n   */\n  async fetch(slices, signal) {\n    // if we allow multi-ranges, split the incoming request into that many sub-requests\n    // and join them afterwards\n    if (this.maxRanges >= slices.length) {\n      return this.fetchSlices(slices, signal);\n    } else if (this.maxRanges > 0 && slices.length > 1) {\n      // TODO: split into multiple multi-range requests\n\n      // const subSlicesRequests = [];\n      // for (let i = 0; i < slices.length; i += this.maxRanges) {\n      //   subSlicesRequests.push(\n      //     this.fetchSlices(slices.slice(i, i + this.maxRanges), signal),\n      //   );\n      // }\n      // return (await Promise.all(subSlicesRequests)).flat();\n    }\n\n    // otherwise make a single request for each slice\n    return Promise.all(\n      slices.map((slice) => this.fetchSlice(slice, signal)),\n    );\n  }\n\n  async fetchSlices(slices, signal) {\n    const response = await this.client.request({\n      headers: {\n        ...this.headers,\n        Range: `bytes=${slices\n          .map(({ offset, length }) => `${offset}-${offset + length}`)\n          .join(',')\n        }`,\n      },\n      signal,\n    });\n\n    if (!response.ok) {\n      throw new Error('Error fetching data.');\n    } else if (response.status === 206) {\n      const { type, params } = parseContentType(response.getHeader('content-type'));\n      if (type === 'multipart/byteranges') {\n        const byteRanges = parseByteRanges(await response.getData(), params.boundary);\n        this._fileSize = byteRanges[0].fileSize || null;\n        return byteRanges;\n      }\n\n      const data = await response.getData();\n\n      const { start, end, total } = parseContentRange(response.getHeader('content-range'));\n      this._fileSize = total || null;\n      const first = [{\n        data,\n        offset: start,\n        length: end - start,\n      }];\n\n      if (slices.length > 1) {\n        // we requested more than one slice, but got only the first\n        // unfortunately, some HTTP Servers don't support multi-ranges\n        // and return only the first\n\n        // get the rest of the slices and fetch them iteratively\n        const others = await Promise.all(slices.slice(1).map((slice) => this.fetchSlice(slice, signal)));\n        return first.concat(others);\n      }\n      return first;\n    } else {\n      if (!this.allowFullFile) {\n        throw new Error('Server responded with full file');\n      }\n      const data = await response.getData();\n      this._fileSize = data.byteLength;\n      return [{\n        data,\n        offset: 0,\n        length: data.byteLength,\n      }];\n    }\n  }\n\n  async fetchSlice(slice, signal) {\n    const { offset, length } = slice;\n    const response = await this.client.request({\n      headers: {\n        ...this.headers,\n        Range: `bytes=${offset}-${offset + length}`,\n      },\n      signal,\n    });\n\n    // check the response was okay and if the server actually understands range requests\n    if (!response.ok) {\n      throw new Error('Error fetching data.');\n    } else if (response.status === 206) {\n      const data = await response.getData();\n\n      const { total } = parseContentRange(response.getHeader('content-range'));\n      this._fileSize = total || null;\n      return {\n        data,\n        offset,\n        length,\n      };\n    } else {\n      if (!this.allowFullFile) {\n        throw new Error('Server responded with full file');\n      }\n\n      const data = await response.getData();\n\n      this._fileSize = data.byteLength;\n      return {\n        data,\n        offset: 0,\n        length: data.byteLength,\n      };\n    }\n  }\n\n  get fileSize() {\n    return this._fileSize;\n  }\n}\n\nfunction maybeWrapInBlockedSource(source, { blockSize, cacheSize }) {\n  if (blockSize === null) {\n    return source;\n  }\n  return new BlockedSource(source, { blockSize, cacheSize });\n}\n\nexport function makeFetchSource(url, { headers = {}, credentials, maxRanges = 0, allowFullFile = false, ...blockOptions } = {}) {\n  const client = new FetchClient(url, credentials);\n  const source = new RemoteSource(client, headers, maxRanges, allowFullFile);\n  return maybeWrapInBlockedSource(source, blockOptions);\n}\n\nexport function makeXHRSource(url, { headers = {}, maxRanges = 0, allowFullFile = false, ...blockOptions } = {}) {\n  const client = new XHRClient(url);\n  const source = new RemoteSource(client, headers, maxRanges, allowFullFile);\n  return maybeWrapInBlockedSource(source, blockOptions);\n}\n\nexport function makeHttpSource(url, { headers = {}, maxRanges = 0, allowFullFile = false, ...blockOptions } = {}) {\n  const client = new HttpClient(url);\n  const source = new RemoteSource(client, headers, maxRanges, allowFullFile);\n  return maybeWrapInBlockedSource(source, blockOptions);\n}\n\n/**\n *\n * @param {string} url\n * @param {object} options\n */\nexport function makeRemoteSource(url, { forceXHR = false, ...clientOptions } = {}) {\n  if (typeof fetch === 'function' && !forceXHR) {\n    return makeFetchSource(url, clientOptions);\n  }\n  if (typeof XMLHttpRequest !== 'undefined') {\n    return makeXHRSource(url, clientOptions);\n  }\n  return makeHttpSource(url, clientOptions);\n}\n","export function assign(target, source) {\n  for (const key in source) {\n    if (source.hasOwnProperty(key)) {\n      target[key] = source[key];\n    }\n  }\n}\n\nexport function chunk(iterable, length) {\n  const results = [];\n  const lengthOfIterable = iterable.length;\n  for (let i = 0; i < lengthOfIterable; i += length) {\n    const chunked = [];\n    for (let ci = i; ci < i + length; ci++) {\n      chunked.push(iterable[ci]);\n    }\n    results.push(chunked);\n  }\n  return results;\n}\n\nexport function endsWith(string, expectedEnding) {\n  if (string.length < expectedEnding.length) {\n    return false;\n  }\n  const actualEnding = string.substr(string.length - expectedEnding.length);\n  return actualEnding === expectedEnding;\n}\n\nexport function forEach(iterable, func) {\n  const { length } = iterable;\n  for (let i = 0; i < length; i++) {\n    func(iterable[i], i);\n  }\n}\n\nexport function invert(oldObj) {\n  const newObj = {};\n  for (const key in oldObj) {\n    if (oldObj.hasOwnProperty(key)) {\n      const value = oldObj[key];\n      newObj[value] = key;\n    }\n  }\n  return newObj;\n}\n\nexport function range(n) {\n  const results = [];\n  for (let i = 0; i < n; i++) {\n    results.push(i);\n  }\n  return results;\n}\n\nexport function times(numTimes, func) {\n  const results = [];\n  for (let i = 0; i < numTimes; i++) {\n    results.push(func(i));\n  }\n  return results;\n}\n\nexport function toArray(iterable) {\n  const results = [];\n  const { length } = iterable;\n  for (let i = 0; i < length; i++) {\n    results.push(iterable[i]);\n  }\n  return results;\n}\n\nexport function toArrayRecursively(input) {\n  if (input.length) {\n    return toArray(input).map(toArrayRecursively);\n  }\n  return input;\n}\n\n// copied from https://github.com/academia-de-codigo/parse-content-range-header/blob/master/index.js\nexport function parseContentRange(headerValue) {\n  if (!headerValue) {\n    return null;\n  }\n\n  if (typeof headerValue !== 'string') {\n    throw new Error('invalid argument');\n  }\n\n  const parseInt = (number) => Number.parseInt(number, 10);\n\n  // Check for presence of unit\n  let matches = headerValue.match(/^(\\w*) /);\n  const unit = matches && matches[1];\n\n  // check for start-end/size header format\n  matches = headerValue.match(/(\\d+)-(\\d+)\\/(\\d+|\\*)/);\n  if (matches) {\n    return {\n      unit,\n      first: parseInt(matches[1]),\n      last: parseInt(matches[2]),\n      length: matches[3] === '*' ? null : parseInt(matches[3]),\n    };\n  }\n\n  // check for size header format\n  matches = headerValue.match(/(\\d+|\\*)/);\n  if (matches) {\n    return {\n      unit,\n      first: null,\n      last: null,\n      length: matches[1] === '*' ? null : parseInt(matches[1]),\n    };\n  }\n\n  return null;\n}\n\n/*\n * Promisified wrapper around 'setTimeout' to allow 'await'\n */\nexport async function wait(milliseconds) {\n  return new Promise((resolve) => setTimeout(resolve, milliseconds));\n}\n\nexport function zip(a, b) {\n  const A = Array.isArray(a) ? a : Array.from(a);\n  const B = Array.isArray(b) ? b : Array.from(b);\n  return A.map((k, i) => [k, B[i]]);\n}\n\n// Based on https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Error\nexport class AbortError extends Error {\n  constructor(params) {\n    // Pass remaining arguments (including vendor specific ones) to parent constructor\n    super(params);\n\n    // Maintains proper stack trace for where our error was thrown (only available on V8)\n    if (Error.captureStackTrace) {\n      Error.captureStackTrace(this, AbortError);\n    }\n\n    this.name = 'AbortError';\n  }\n}\n\nexport class CustomAggregateError extends Error {\n  constructor(errors, message) {\n    super(message);\n    this.errors = errors;\n    this.message = message;\n    this.name = 'AggregateError';\n  }\n}\n\nexport const AggregateError = CustomAggregateError;\n","export default class QuickLRU extends Map {\n\tconstructor(options = {}) {\n\t\tsuper();\n\n\t\tif (!(options.maxSize && options.maxSize > 0)) {\n\t\t\tthrow new TypeError('`maxSize` must be a number greater than 0');\n\t\t}\n\n\t\tif (typeof options.maxAge === 'number' && options.maxAge === 0) {\n\t\t\tthrow new TypeError('`maxAge` must be a number greater than 0');\n\t\t}\n\n\t\t// TODO: Use private class fields when ESLint supports them.\n\t\tthis.maxSize = options.maxSize;\n\t\tthis.maxAge = options.maxAge || Number.POSITIVE_INFINITY;\n\t\tthis.onEviction = options.onEviction;\n\t\tthis.cache = new Map();\n\t\tthis.oldCache = new Map();\n\t\tthis._size = 0;\n\t}\n\n\t// TODO: Use private class methods when targeting Node.js 16.\n\t_emitEvictions(cache) {\n\t\tif (typeof this.onEviction !== 'function') {\n\t\t\treturn;\n\t\t}\n\n\t\tfor (const [key, item] of cache) {\n\t\t\tthis.onEviction(key, item.value);\n\t\t}\n\t}\n\n\t_deleteIfExpired(key, item) {\n\t\tif (typeof item.expiry === 'number' && item.expiry <= Date.now()) {\n\t\t\tif (typeof this.onEviction === 'function') {\n\t\t\t\tthis.onEviction(key, item.value);\n\t\t\t}\n\n\t\t\treturn this.delete(key);\n\t\t}\n\n\t\treturn false;\n\t}\n\n\t_getOrDeleteIfExpired(key, item) {\n\t\tconst deleted = this._deleteIfExpired(key, item);\n\t\tif (deleted === false) {\n\t\t\treturn item.value;\n\t\t}\n\t}\n\n\t_getItemValue(key, item) {\n\t\treturn item.expiry ? this._getOrDeleteIfExpired(key, item) : item.value;\n\t}\n\n\t_peek(key, cache) {\n\t\tconst item = cache.get(key);\n\n\t\treturn this._getItemValue(key, item);\n\t}\n\n\t_set(key, value) {\n\t\tthis.cache.set(key, value);\n\t\tthis._size++;\n\n\t\tif (this._size >= this.maxSize) {\n\t\t\tthis._size = 0;\n\t\t\tthis._emitEvictions(this.oldCache);\n\t\t\tthis.oldCache = this.cache;\n\t\t\tthis.cache = new Map();\n\t\t}\n\t}\n\n\t_moveToRecent(key, item) {\n\t\tthis.oldCache.delete(key);\n\t\tthis._set(key, item);\n\t}\n\n\t* _entriesAscending() {\n\t\tfor (const item of this.oldCache) {\n\t\t\tconst [key, value] = item;\n\t\t\tif (!this.cache.has(key)) {\n\t\t\t\tconst deleted = this._deleteIfExpired(key, value);\n\t\t\t\tif (deleted === false) {\n\t\t\t\t\tyield item;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tfor (const item of this.cache) {\n\t\t\tconst [key, value] = item;\n\t\t\tconst deleted = this._deleteIfExpired(key, value);\n\t\t\tif (deleted === false) {\n\t\t\t\tyield item;\n\t\t\t}\n\t\t}\n\t}\n\n\tget(key) {\n\t\tif (this.cache.has(key)) {\n\t\t\tconst item = this.cache.get(key);\n\n\t\t\treturn this._getItemValue(key, item);\n\t\t}\n\n\t\tif (this.oldCache.has(key)) {\n\t\t\tconst item = this.oldCache.get(key);\n\t\t\tif (this._deleteIfExpired(key, item) === false) {\n\t\t\t\tthis._moveToRecent(key, item);\n\t\t\t\treturn item.value;\n\t\t\t}\n\t\t}\n\t}\n\n\tset(key, value, {maxAge = this.maxAge} = {}) {\n\t\tconst expiry =\n\t\t\ttypeof maxAge === 'number' && maxAge !== Number.POSITIVE_INFINITY ?\n\t\t\t\tDate.now() + maxAge :\n\t\t\t\tundefined;\n\t\tif (this.cache.has(key)) {\n\t\t\tthis.cache.set(key, {\n\t\t\t\tvalue,\n\t\t\t\texpiry\n\t\t\t});\n\t\t} else {\n\t\t\tthis._set(key, {value, expiry});\n\t\t}\n\t}\n\n\thas(key) {\n\t\tif (this.cache.has(key)) {\n\t\t\treturn !this._deleteIfExpired(key, this.cache.get(key));\n\t\t}\n\n\t\tif (this.oldCache.has(key)) {\n\t\t\treturn !this._deleteIfExpired(key, this.oldCache.get(key));\n\t\t}\n\n\t\treturn false;\n\t}\n\n\tpeek(key) {\n\t\tif (this.cache.has(key)) {\n\t\t\treturn this._peek(key, this.cache);\n\t\t}\n\n\t\tif (this.oldCache.has(key)) {\n\t\t\treturn this._peek(key, this.oldCache);\n\t\t}\n\t}\n\n\tdelete(key) {\n\t\tconst deleted = this.cache.delete(key);\n\t\tif (deleted) {\n\t\t\tthis._size--;\n\t\t}\n\n\t\treturn this.oldCache.delete(key) || deleted;\n\t}\n\n\tclear() {\n\t\tthis.cache.clear();\n\t\tthis.oldCache.clear();\n\t\tthis._size = 0;\n\t}\n\n\tresize(newSize) {\n\t\tif (!(newSize && newSize > 0)) {\n\t\t\tthrow new TypeError('`maxSize` must be a number greater than 0');\n\t\t}\n\n\t\tconst items = [...this._entriesAscending()];\n\t\tconst removeCount = items.length - newSize;\n\t\tif (removeCount < 0) {\n\t\t\tthis.cache = new Map(items);\n\t\t\tthis.oldCache = new Map();\n\t\t\tthis._size = items.length;\n\t\t} else {\n\t\t\tif (removeCount > 0) {\n\t\t\t\tthis._emitEvictions(items.slice(0, removeCount));\n\t\t\t}\n\n\t\t\tthis.oldCache = new Map(items.slice(removeCount));\n\t\t\tthis.cache = new Map();\n\t\t\tthis._size = 0;\n\t\t}\n\n\t\tthis.maxSize = newSize;\n\t}\n\n\t* keys() {\n\t\tfor (const [key] of this) {\n\t\t\tyield key;\n\t\t}\n\t}\n\n\t* values() {\n\t\tfor (const [, value] of this) {\n\t\t\tyield value;\n\t\t}\n\t}\n\n\t* [Symbol.iterator]() {\n\t\tfor (const item of this.cache) {\n\t\t\tconst [key, value] = item;\n\t\t\tconst deleted = this._deleteIfExpired(key, value);\n\t\t\tif (deleted === false) {\n\t\t\t\tyield [key, value.value];\n\t\t\t}\n\t\t}\n\n\t\tfor (const item of this.oldCache) {\n\t\t\tconst [key, value] = item;\n\t\t\tif (!this.cache.has(key)) {\n\t\t\t\tconst deleted = this._deleteIfExpired(key, value);\n\t\t\t\tif (deleted === false) {\n\t\t\t\t\tyield [key, value.value];\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\t* entriesDescending() {\n\t\tlet items = [...this.cache];\n\t\tfor (let i = items.length - 1; i >= 0; --i) {\n\t\t\tconst item = items[i];\n\t\t\tconst [key, value] = item;\n\t\t\tconst deleted = this._deleteIfExpired(key, value);\n\t\t\tif (deleted === false) {\n\t\t\t\tyield [key, value.value];\n\t\t\t}\n\t\t}\n\n\t\titems = [...this.oldCache];\n\t\tfor (let i = items.length - 1; i >= 0; --i) {\n\t\t\tconst item = items[i];\n\t\t\tconst [key, value] = item;\n\t\t\tif (!this.cache.has(key)) {\n\t\t\t\tconst deleted = this._deleteIfExpired(key, value);\n\t\t\t\tif (deleted === false) {\n\t\t\t\t\tyield [key, value.value];\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\t* entriesAscending() {\n\t\tfor (const [key, value] of this._entriesAscending()) {\n\t\t\tyield [key, value.value];\n\t\t}\n\t}\n\n\tget size() {\n\t\tif (!this._size) {\n\t\t\treturn this.oldCache.size;\n\t\t}\n\n\t\tlet oldCacheSize = 0;\n\t\tfor (const key of this.oldCache.keys()) {\n\t\t\tif (!this.cache.has(key)) {\n\t\t\t\toldCacheSize++;\n\t\t\t}\n\t\t}\n\n\t\treturn Math.min(this._size + oldCacheSize, this.maxSize);\n\t}\n\n\tentries() {\n\t\treturn this.entriesAscending();\n\t}\n\n\tforEach(callbackFunction, thisArgument = this) {\n\t\tfor (const [key, value] of this.entriesAscending()) {\n\t\t\tcallbackFunction.call(thisArgument, value, key, this);\n\t\t}\n\t}\n\n\tget [Symbol.toStringTag]() {\n\t\treturn JSON.stringify([...this.entriesAscending()]);\n\t}\n}\n"],"names":[],"sourceRoot":""}